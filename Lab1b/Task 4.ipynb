{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy.random as random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit, ParameterGrid\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import activations, optimizers, regularizers, losses, initializers\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Gfe3jBkmxiVs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 - Assignment Part 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def mackey_glass(t, mg_dict, beta=0.2, gamma=0.1, n=10, r=25):\n",
    "    if t == 0:\n",
    "        return 1.5\n",
    "    elif t < 0:\n",
    "        return 0\n",
    "\n",
    "    if mg_dict.get(t):\n",
    "        return mg_dict.get(t)\n",
    "\n",
    "    t_prev = t - 1\n",
    "\n",
    "    if not mg_dict.get(t_prev):\n",
    "        mg_dict[t_prev] = mackey_glass(t_prev, mg_dict)\n",
    "\n",
    "    mg_t = mg_dict.get(t_prev)\n",
    "\n",
    "    if not mg_dict.get(t_prev - r):\n",
    "        mg_dict[t_prev - r] = mackey_glass(t_prev - r, mg_dict)\n",
    "\n",
    "    mg_tr = mg_dict.get(t_prev - r)\n",
    "\n",
    "    return mg_t + (beta * mg_tr) / (1 + mg_tr ** n) - gamma * mg_t\n",
    "\n",
    "\n",
    "mg_dict = {}\n",
    "input = []\n",
    "output = []\n",
    "for t in range(300, 1500):\n",
    "    input.append([mackey_glass(t - 20, mg_dict), mackey_glass(t - 15, mg_dict), mackey_glass(t - 10, mg_dict),\n",
    "                  mackey_glass(t - 5, mg_dict), mackey_glass(t, mg_dict)])\n",
    "    output.append(mackey_glass(t + 5, mg_dict))\n",
    "\n",
    "input = np.array(input)\n",
    "output = np.array(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mg_dict.keys(), mg_dict.values())\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1YOs166rxiV1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "outputId": "c30251d2-6ae3-40b7-bed7-21f0e138542a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# consecutive blocks of the time series: train -> val -> test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(input, output, test_size=200, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def create_model(hidden_layer_nodes=[5, 6], input_shape=5, output_shape=1, learning_rate=0.1, momentum=0.5,\n",
    "                 activation=activations.sigmoid, final_activation=activations.linear,\n",
    "                 kernel_initializer=initializers.GlorotNormal(),\n",
    "                 bias_initializer=initializers.Zeros(),\n",
    "                 regularizer=regularizers.L1(0.0001)):\n",
    "    model = Sequential()\n",
    "    for i, nodes in enumerate(hidden_layer_nodes):\n",
    "        if i == 0:\n",
    "            print(\"New input layer:\", \"input_shape\", input_shape, \"nodes\", nodes)\n",
    "            model.add(Dense(nodes,\n",
    "                            input_dim=input_shape,\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            bias_initializer=bias_initializer,\n",
    "                            #choose L1 because the weights are not equally important\n",
    "                            kernel_regularizer=regularizer,\n",
    "                            bias_regularizer=regularizer))\n",
    "        else:\n",
    "            print(\"New hidden layer:\", \"nodes\", nodes)\n",
    "            model.add(Dense(nodes,\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            bias_initializer=bias_initializer,\n",
    "                            kernel_regularizer=regularizer,\n",
    "                            bias_regularizer=regularizer))\n",
    "\n",
    "    print(\"New output layer:\", \"output_shape\", output_shape)\n",
    "    model.add(Dense(output_shape,\n",
    "                    activation=final_activation,\n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    bias_initializer=bias_initializer,\n",
    "                    kernel_regularizer=regularizer,\n",
    "                    bias_regularizer=regularizer))\n",
    "\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    model.compile(loss=losses.mean_squared_error, optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input layer: input_shape 5 nodes 9\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 0.1639 - mse: 0.1224 - val_loss: 0.0976 - val_mse: 0.0561\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1307 - mse: 0.0892 - val_loss: 0.0966 - val_mse: 0.0552\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1302 - mse: 0.0888 - val_loss: 0.0964 - val_mse: 0.0551\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1296 - mse: 0.0883 - val_loss: 0.0964 - val_mse: 0.0552\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1292 - mse: 0.0880 - val_loss: 0.0968 - val_mse: 0.0558\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1284 - mse: 0.0874 - val_loss: 0.0949 - val_mse: 0.0540\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1279 - mse: 0.0871 - val_loss: 0.0947 - val_mse: 0.0539\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1273 - mse: 0.0865 - val_loss: 0.0950 - val_mse: 0.0543\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1268 - mse: 0.0862 - val_loss: 0.0953 - val_mse: 0.0547\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1264 - mse: 0.0859 - val_loss: 0.0939 - val_mse: 0.0535\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1260 - mse: 0.0856 - val_loss: 0.0929 - val_mse: 0.0526\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1253 - mse: 0.0850 - val_loss: 0.0954 - val_mse: 0.0552\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1249 - mse: 0.0848 - val_loss: 0.0936 - val_mse: 0.0535\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1243 - mse: 0.0842 - val_loss: 0.0919 - val_mse: 0.0519\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1238 - mse: 0.0838 - val_loss: 0.0938 - val_mse: 0.0539\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1236 - mse: 0.0837 - val_loss: 0.0912 - val_mse: 0.0514\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1230 - mse: 0.0833 - val_loss: 0.0916 - val_mse: 0.0519\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1228 - mse: 0.0831 - val_loss: 0.0908 - val_mse: 0.0512\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1218 - mse: 0.0823 - val_loss: 0.0912 - val_mse: 0.0516\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1217 - mse: 0.0822 - val_loss: 0.0914 - val_mse: 0.0519\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1213 - mse: 0.0819 - val_loss: 0.0895 - val_mse: 0.0501\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.0815 - val_loss: 0.0890 - val_mse: 0.0498\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1202 - mse: 0.0810 - val_loss: 0.0896 - val_mse: 0.0505\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1201 - mse: 0.0810 - val_loss: 0.0889 - val_mse: 0.0498\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1192 - mse: 0.0802 - val_loss: 0.0880 - val_mse: 0.0491\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1191 - mse: 0.0801 - val_loss: 0.0890 - val_mse: 0.0502\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1186 - mse: 0.0798 - val_loss: 0.0876 - val_mse: 0.0489\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1177 - mse: 0.0790 - val_loss: 0.0894 - val_mse: 0.0507\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1176 - mse: 0.0790 - val_loss: 0.0875 - val_mse: 0.0489\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1171 - mse: 0.0786 - val_loss: 0.0885 - val_mse: 0.0500\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1166 - mse: 0.0782 - val_loss: 0.0864 - val_mse: 0.0480\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1162 - mse: 0.0779 - val_loss: 0.0866 - val_mse: 0.0483\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.0774 - val_loss: 0.0862 - val_mse: 0.0480\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1152 - mse: 0.0771 - val_loss: 0.0870 - val_mse: 0.0489\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1146 - mse: 0.0764 - val_loss: 0.0871 - val_mse: 0.0491\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1141 - mse: 0.0761 - val_loss: 0.0844 - val_mse: 0.0464\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1135 - mse: 0.0756 - val_loss: 0.0867 - val_mse: 0.0488\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1133 - mse: 0.0754 - val_loss: 0.0856 - val_mse: 0.0477\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1131 - mse: 0.0753 - val_loss: 0.0837 - val_mse: 0.0459\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1125 - mse: 0.0747 - val_loss: 0.0832 - val_mse: 0.0455\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1120 - mse: 0.0743 - val_loss: 0.0834 - val_mse: 0.0458\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1115 - mse: 0.0738 - val_loss: 0.0848 - val_mse: 0.0472\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1110 - mse: 0.0734 - val_loss: 0.0845 - val_mse: 0.0470\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1108 - mse: 0.0732 - val_loss: 0.0821 - val_mse: 0.0446\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1101 - mse: 0.0727 - val_loss: 0.0815 - val_mse: 0.0440\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1097 - mse: 0.0723 - val_loss: 0.0818 - val_mse: 0.0444\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1092 - mse: 0.0718 - val_loss: 0.0808 - val_mse: 0.0434\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1085 - mse: 0.0711 - val_loss: 0.0805 - val_mse: 0.0431\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1082 - mse: 0.0709 - val_loss: 0.0818 - val_mse: 0.0445\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1078 - mse: 0.0705 - val_loss: 0.0802 - val_mse: 0.0429\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0700 - val_loss: 0.0802 - val_mse: 0.0430\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1067 - mse: 0.0695 - val_loss: 0.0793 - val_mse: 0.0421\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1062 - mse: 0.0691 - val_loss: 0.0790 - val_mse: 0.0418\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1056 - mse: 0.0685 - val_loss: 0.0793 - val_mse: 0.0422\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1052 - mse: 0.0681 - val_loss: 0.0783 - val_mse: 0.0412\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1051 - mse: 0.0680 - val_loss: 0.0788 - val_mse: 0.0417\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1043 - mse: 0.0673 - val_loss: 0.0776 - val_mse: 0.0405\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1040 - mse: 0.0669 - val_loss: 0.0775 - val_mse: 0.0405\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1033 - mse: 0.0663 - val_loss: 0.0772 - val_mse: 0.0402\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1028 - mse: 0.0658 - val_loss: 0.0768 - val_mse: 0.0399\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1023 - mse: 0.0653 - val_loss: 0.0766 - val_mse: 0.0397\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1016 - mse: 0.0646 - val_loss: 0.0761 - val_mse: 0.0391\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1013 - mse: 0.0643 - val_loss: 0.0762 - val_mse: 0.0393\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1006 - mse: 0.0637 - val_loss: 0.0756 - val_mse: 0.0387\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.0633 - val_loss: 0.0755 - val_mse: 0.0386\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0996 - mse: 0.0626 - val_loss: 0.0765 - val_mse: 0.0396\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0991 - mse: 0.0622 - val_loss: 0.0749 - val_mse: 0.0380\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0984 - mse: 0.0614 - val_loss: 0.0746 - val_mse: 0.0376\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0979 - mse: 0.0610 - val_loss: 0.0746 - val_mse: 0.0376\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0973 - mse: 0.0603 - val_loss: 0.0732 - val_mse: 0.0362\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0969 - mse: 0.0600 - val_loss: 0.0730 - val_mse: 0.0360\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0963 - mse: 0.0593 - val_loss: 0.0730 - val_mse: 0.0361\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0955 - mse: 0.0585 - val_loss: 0.0742 - val_mse: 0.0372\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0952 - mse: 0.0582 - val_loss: 0.0728 - val_mse: 0.0358\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0945 - mse: 0.0575 - val_loss: 0.0738 - val_mse: 0.0368\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0941 - mse: 0.0571 - val_loss: 0.0715 - val_mse: 0.0344\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0565 - val_loss: 0.0714 - val_mse: 0.0344\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0558 - val_loss: 0.0706 - val_mse: 0.0335\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0922 - mse: 0.0551 - val_loss: 0.0703 - val_mse: 0.0332\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0916 - mse: 0.0545 - val_loss: 0.0705 - val_mse: 0.0334\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0910 - mse: 0.0538 - val_loss: 0.0698 - val_mse: 0.0326\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0904 - mse: 0.0532 - val_loss: 0.0700 - val_mse: 0.0328\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0898 - mse: 0.0526 - val_loss: 0.0692 - val_mse: 0.0320\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0893 - mse: 0.0521 - val_loss: 0.0695 - val_mse: 0.0323\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0886 - mse: 0.0514 - val_loss: 0.0685 - val_mse: 0.0312\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0879 - mse: 0.0506 - val_loss: 0.0690 - val_mse: 0.0317\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0875 - mse: 0.0502 - val_loss: 0.0676 - val_mse: 0.0302\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0868 - mse: 0.0494 - val_loss: 0.0673 - val_mse: 0.0300\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0862 - mse: 0.0488 - val_loss: 0.0666 - val_mse: 0.0292\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0855 - mse: 0.0480 - val_loss: 0.0683 - val_mse: 0.0309\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0851 - mse: 0.0476 - val_loss: 0.0669 - val_mse: 0.0294\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0843 - mse: 0.0468 - val_loss: 0.0658 - val_mse: 0.0283\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0836 - mse: 0.0461 - val_loss: 0.0655 - val_mse: 0.0280\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0832 - mse: 0.0456 - val_loss: 0.0651 - val_mse: 0.0275\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0824 - mse: 0.0448 - val_loss: 0.0647 - val_mse: 0.0271\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0818 - mse: 0.0442 - val_loss: 0.0643 - val_mse: 0.0267\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0811 - mse: 0.0435 - val_loss: 0.0646 - val_mse: 0.0270\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0805 - mse: 0.0428 - val_loss: 0.0637 - val_mse: 0.0260\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0801 - mse: 0.0424 - val_loss: 0.0632 - val_mse: 0.0255\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0795 - mse: 0.0418 - val_loss: 0.0632 - val_mse: 0.0254\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0789 - mse: 0.0411 - val_loss: 0.0625 - val_mse: 0.0248\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0783 - mse: 0.0405 - val_loss: 0.0626 - val_mse: 0.0248\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0777 - mse: 0.0399 - val_loss: 0.0623 - val_mse: 0.0245\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0394 - val_loss: 0.0617 - val_mse: 0.0238\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0764 - mse: 0.0385 - val_loss: 0.0614 - val_mse: 0.0235\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0760 - mse: 0.0381 - val_loss: 0.0614 - val_mse: 0.0235\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0756 - mse: 0.0376 - val_loss: 0.0611 - val_mse: 0.0231\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0750 - mse: 0.0370 - val_loss: 0.0609 - val_mse: 0.0229\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0744 - mse: 0.0364 - val_loss: 0.0604 - val_mse: 0.0223\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0740 - mse: 0.0359 - val_loss: 0.0603 - val_mse: 0.0222\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0734 - mse: 0.0353 - val_loss: 0.0598 - val_mse: 0.0217\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0730 - mse: 0.0349 - val_loss: 0.0597 - val_mse: 0.0215\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0724 - mse: 0.0343 - val_loss: 0.0597 - val_mse: 0.0215\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0720 - mse: 0.0338 - val_loss: 0.0605 - val_mse: 0.0223\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0716 - mse: 0.0334 - val_loss: 0.0593 - val_mse: 0.0211\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0711 - mse: 0.0329 - val_loss: 0.0593 - val_mse: 0.0210\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0706 - mse: 0.0324 - val_loss: 0.0588 - val_mse: 0.0205\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0701 - mse: 0.0318 - val_loss: 0.0583 - val_mse: 0.0200\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0696 - mse: 0.0313 - val_loss: 0.0590 - val_mse: 0.0207\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0695 - mse: 0.0312 - val_loss: 0.0582 - val_mse: 0.0199\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0691 - mse: 0.0308 - val_loss: 0.0580 - val_mse: 0.0197\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0686 - mse: 0.0302 - val_loss: 0.0583 - val_mse: 0.0200\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0684 - mse: 0.0300 - val_loss: 0.0574 - val_mse: 0.0191\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0679 - mse: 0.0295 - val_loss: 0.0574 - val_mse: 0.0190\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0675 - mse: 0.0291 - val_loss: 0.0575 - val_mse: 0.0191\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0674 - mse: 0.0290 - val_loss: 0.0573 - val_mse: 0.0188\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0669 - mse: 0.0284 - val_loss: 0.0569 - val_mse: 0.0184\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0666 - mse: 0.0281 - val_loss: 0.0574 - val_mse: 0.0190\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0664 - mse: 0.0280 - val_loss: 0.0570 - val_mse: 0.0185\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0660 - mse: 0.0276 - val_loss: 0.0568 - val_mse: 0.0184\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0657 - mse: 0.0272 - val_loss: 0.0580 - val_mse: 0.0196\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0655 - mse: 0.0271 - val_loss: 0.0563 - val_mse: 0.0179\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0651 - mse: 0.0267 - val_loss: 0.0561 - val_mse: 0.0177\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0649 - mse: 0.0265 - val_loss: 0.0564 - val_mse: 0.0179\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0262 - val_loss: 0.0559 - val_mse: 0.0175\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0644 - mse: 0.0259 - val_loss: 0.0559 - val_mse: 0.0175\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0257 - val_loss: 0.0559 - val_mse: 0.0175\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0255 - val_loss: 0.0564 - val_mse: 0.0179\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0637 - mse: 0.0253 - val_loss: 0.0556 - val_mse: 0.0172\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0636 - mse: 0.0252 - val_loss: 0.0555 - val_mse: 0.0171\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0633 - mse: 0.0249 - val_loss: 0.0557 - val_mse: 0.0173\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0632 - mse: 0.0248 - val_loss: 0.0554 - val_mse: 0.0170\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0629 - mse: 0.0245 - val_loss: 0.0555 - val_mse: 0.0171\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0628 - mse: 0.0244 - val_loss: 0.0558 - val_mse: 0.0175\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0626 - mse: 0.0243 - val_loss: 0.0553 - val_mse: 0.0170\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0623 - mse: 0.0240 - val_loss: 0.0553 - val_mse: 0.0170\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0622 - mse: 0.0239 - val_loss: 0.0551 - val_mse: 0.0168\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0620 - mse: 0.0237 - val_loss: 0.0549 - val_mse: 0.0166\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0618 - mse: 0.0236 - val_loss: 0.0551 - val_mse: 0.0168\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0617 - mse: 0.0234 - val_loss: 0.0548 - val_mse: 0.0166\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0614 - mse: 0.0232 - val_loss: 0.0549 - val_mse: 0.0168\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0614 - mse: 0.0232 - val_loss: 0.0546 - val_mse: 0.0165\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0612 - mse: 0.0231 - val_loss: 0.0546 - val_mse: 0.0165\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0610 - mse: 0.0229 - val_loss: 0.0547 - val_mse: 0.0166\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0610 - mse: 0.0229 - val_loss: 0.0544 - val_mse: 0.0164\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0608 - mse: 0.0227 - val_loss: 0.0546 - val_mse: 0.0166\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0606 - mse: 0.0225 - val_loss: 0.0551 - val_mse: 0.0171\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0606 - mse: 0.0226 - val_loss: 0.0543 - val_mse: 0.0163\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0604 - mse: 0.0224 - val_loss: 0.0542 - val_mse: 0.0163\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0603 - mse: 0.0224 - val_loss: 0.0541 - val_mse: 0.0162\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0601 - mse: 0.0222 - val_loss: 0.0543 - val_mse: 0.0164\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0601 - mse: 0.0222 - val_loss: 0.0543 - val_mse: 0.0164\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0598 - mse: 0.0220 - val_loss: 0.0541 - val_mse: 0.0163\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0598 - mse: 0.0220 - val_loss: 0.0542 - val_mse: 0.0165\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0597 - mse: 0.0220 - val_loss: 0.0539 - val_mse: 0.0162\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0218 - val_loss: 0.0542 - val_mse: 0.0165\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0218 - val_loss: 0.0540 - val_mse: 0.0163\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0593 - mse: 0.0217 - val_loss: 0.0541 - val_mse: 0.0165\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0592 - mse: 0.0216 - val_loss: 0.0537 - val_mse: 0.0161\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0592 - mse: 0.0216 - val_loss: 0.0535 - val_mse: 0.0160\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0590 - mse: 0.0215 - val_loss: 0.0539 - val_mse: 0.0165\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0589 - mse: 0.0215 - val_loss: 0.0534 - val_mse: 0.0160\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0588 - mse: 0.0214 - val_loss: 0.0533 - val_mse: 0.0159\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0588 - mse: 0.0214 - val_loss: 0.0533 - val_mse: 0.0159\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0585 - mse: 0.0212 - val_loss: 0.0533 - val_mse: 0.0160\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0585 - mse: 0.0212 - val_loss: 0.0531 - val_mse: 0.0158\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0583 - mse: 0.0211 - val_loss: 0.0530 - val_mse: 0.0158\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0583 - mse: 0.0211 - val_loss: 0.0531 - val_mse: 0.0159\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0581 - mse: 0.0210 - val_loss: 0.0533 - val_mse: 0.0161\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0581 - mse: 0.0210 - val_loss: 0.0528 - val_mse: 0.0158\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0581 - mse: 0.0210 - val_loss: 0.0528 - val_mse: 0.0157\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0209 - val_loss: 0.0528 - val_mse: 0.0159\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0210 - val_loss: 0.0527 - val_mse: 0.0157\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0578 - mse: 0.0208 - val_loss: 0.0530 - val_mse: 0.0161\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0577 - mse: 0.0208 - val_loss: 0.0526 - val_mse: 0.0158\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0575 - mse: 0.0206 - val_loss: 0.0525 - val_mse: 0.0157\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0575 - mse: 0.0207 - val_loss: 0.0524 - val_mse: 0.0156\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0574 - mse: 0.0207 - val_loss: 0.0526 - val_mse: 0.0159\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0205 - val_loss: 0.0525 - val_mse: 0.0159\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0206 - val_loss: 0.0523 - val_mse: 0.0157\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0570 - mse: 0.0204 - val_loss: 0.0521 - val_mse: 0.0156\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0570 - mse: 0.0205 - val_loss: 0.0527 - val_mse: 0.0162\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0204 - val_loss: 0.0520 - val_mse: 0.0156\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0203 - val_loss: 0.0519 - val_mse: 0.0155\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0203 - val_loss: 0.0522 - val_mse: 0.0158\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0566 - mse: 0.0202 - val_loss: 0.0518 - val_mse: 0.0155\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0565 - mse: 0.0202 - val_loss: 0.0517 - val_mse: 0.0155\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0201 - val_loss: 0.0517 - val_mse: 0.0154\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0202 - val_loss: 0.0516 - val_mse: 0.0154\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0202 - val_loss: 0.0517 - val_mse: 0.0156\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0562 - mse: 0.0201 - val_loss: 0.0519 - val_mse: 0.0158\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0562 - mse: 0.0202 - val_loss: 0.0515 - val_mse: 0.0155\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0561 - mse: 0.0201 - val_loss: 0.0514 - val_mse: 0.0154\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0560 - mse: 0.0200 - val_loss: 0.0514 - val_mse: 0.0154\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0199 - val_loss: 0.0513 - val_mse: 0.0154\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0200 - val_loss: 0.0516 - val_mse: 0.0158\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0199 - val_loss: 0.0511 - val_mse: 0.0153\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0199 - val_loss: 0.0513 - val_mse: 0.0155\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0198 - val_loss: 0.0512 - val_mse: 0.0155\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0555 - mse: 0.0198 - val_loss: 0.0509 - val_mse: 0.0152\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0554 - mse: 0.0198 - val_loss: 0.0509 - val_mse: 0.0153\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0554 - mse: 0.0198 - val_loss: 0.0508 - val_mse: 0.0152\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0198 - val_loss: 0.0508 - val_mse: 0.0153\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0552 - mse: 0.0197 - val_loss: 0.0507 - val_mse: 0.0152\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0551 - mse: 0.0196 - val_loss: 0.0506 - val_mse: 0.0152\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0550 - mse: 0.0197 - val_loss: 0.0506 - val_mse: 0.0152\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0550 - mse: 0.0197 - val_loss: 0.0505 - val_mse: 0.0152\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0195 - val_loss: 0.0511 - val_mse: 0.0159\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0196 - val_loss: 0.0503 - val_mse: 0.0151\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0195 - val_loss: 0.0502 - val_mse: 0.0151\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0195 - val_loss: 0.0504 - val_mse: 0.0153\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0195 - val_loss: 0.0502 - val_mse: 0.0151\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0545 - mse: 0.0195 - val_loss: 0.0502 - val_mse: 0.0152\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0545 - mse: 0.0195 - val_loss: 0.0500 - val_mse: 0.0150\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0544 - mse: 0.0194 - val_loss: 0.0499 - val_mse: 0.0150\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0543 - mse: 0.0194 - val_loss: 0.0500 - val_mse: 0.0151\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0193 - val_loss: 0.0498 - val_mse: 0.0150\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0193 - val_loss: 0.0498 - val_mse: 0.0150\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0192 - val_loss: 0.0497 - val_mse: 0.0150\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0539 - mse: 0.0193 - val_loss: 0.0496 - val_mse: 0.0149\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0538 - mse: 0.0192 - val_loss: 0.0496 - val_mse: 0.0150\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0538 - mse: 0.0193 - val_loss: 0.0495 - val_mse: 0.0149\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0537 - mse: 0.0192 - val_loss: 0.0494 - val_mse: 0.0149\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0192 - val_loss: 0.0494 - val_mse: 0.0149\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0192 - val_loss: 0.0494 - val_mse: 0.0150\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0192 - val_loss: 0.0495 - val_mse: 0.0152\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0534 - mse: 0.0190 - val_loss: 0.0497 - val_mse: 0.0154\n",
      "Epoch 237: early stopping\n"
     ]
    }
   ],
   "source": [
    "#lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9)\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='val_mse', mode='min', patience=10, min_delta=0.0001, verbose=1, restore_best_weights=0)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=10, callbacks=es)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def grid_search(param_dict, _X_train, _y_train, _X_val, _y_val):\n",
    "    param_grids = list(ParameterGrid(param_dict))\n",
    "    print(len(param_grids))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_mse', mode='min', patience=20, min_delta=0.0001, verbose=1, restore_best_weights=0)\n",
    "    models = []\n",
    "    histories = []\n",
    "\n",
    "    for params in param_grids:\n",
    "        print(params)\n",
    "        model = create_model(**params)\n",
    "        history = model.fit(_X_train, _y_train, validation_data=(_X_val, _y_val), epochs=500, batch_size=10, callbacks=es)\n",
    "        models.append(model)\n",
    "        histories.append(history.history)\n",
    "\n",
    "    final_val_mses = np.around([history['val_mse'][-1] for history in histories], 4)\n",
    "    final_train_mses = np.around([history['mse'][-1] for history in histories], 4)\n",
    "    used_epochs = [len(history['val_mse']) for history in histories]\n",
    "    eval_grid = zip(param_grids, models, histories, final_train_mses, final_val_mses, used_epochs)\n",
    "    eval_grid = sorted(eval_grid, key=lambda x: x[4])\n",
    "\n",
    "    for i, (param, model, history, final_train_mse, final_val_mse, epoch) in enumerate(eval_grid):\n",
    "        print(i, final_train_mse, final_val_mse, epoch, param)\n",
    "\n",
    "    return eval_grid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find best hidden layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "{'hidden_layer_nodes': [3, 2]}\n",
      "New input layer: input_shape 5 nodes 3\n",
      "New hidden layer: nodes 2\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.0980 - mse: 0.0930 - val_loss: 0.0580 - val_mse: 0.0530\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0896 - val_loss: 0.0644 - val_mse: 0.0594\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0896 - val_loss: 0.0630 - val_mse: 0.0580\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0892 - val_loss: 0.0661 - val_mse: 0.0610\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0896 - val_loss: 0.0733 - val_mse: 0.0683\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0895 - val_loss: 0.0608 - val_mse: 0.0558\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0959 - mse: 0.0909 - val_loss: 0.0604 - val_mse: 0.0553\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0896 - val_loss: 0.0764 - val_mse: 0.0714\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0967 - mse: 0.0916 - val_loss: 0.0579 - val_mse: 0.0529\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0956 - mse: 0.0905 - val_loss: 0.0583 - val_mse: 0.0532\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0950 - mse: 0.0900 - val_loss: 0.0583 - val_mse: 0.0533\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0939 - mse: 0.0889 - val_loss: 0.0589 - val_mse: 0.0539\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0966 - mse: 0.0916 - val_loss: 0.0571 - val_mse: 0.0521\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0934 - mse: 0.0884 - val_loss: 0.0583 - val_mse: 0.0533\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0961 - mse: 0.0911 - val_loss: 0.0602 - val_mse: 0.0552\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0936 - mse: 0.0886 - val_loss: 0.0571 - val_mse: 0.0521\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0935 - mse: 0.0885 - val_loss: 0.0645 - val_mse: 0.0595\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0938 - mse: 0.0888 - val_loss: 0.0988 - val_mse: 0.0938\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0957 - mse: 0.0907 - val_loss: 0.0577 - val_mse: 0.0527\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0930 - mse: 0.0880 - val_loss: 0.0623 - val_mse: 0.0573\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0918 - mse: 0.0868 - val_loss: 0.0602 - val_mse: 0.0553\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0890 - val_loss: 0.0571 - val_mse: 0.0521\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0943 - mse: 0.0893 - val_loss: 0.0605 - val_mse: 0.0556\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0894 - val_loss: 0.0571 - val_mse: 0.0521\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0963 - mse: 0.0913 - val_loss: 0.0583 - val_mse: 0.0533\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0949 - mse: 0.0899 - val_loss: 0.0569 - val_mse: 0.0520\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0941 - mse: 0.0892 - val_loss: 0.0576 - val_mse: 0.0527\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0886 - val_loss: 0.0635 - val_mse: 0.0586\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0897 - val_loss: 0.0581 - val_mse: 0.0531\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0952 - mse: 0.0902 - val_loss: 0.0599 - val_mse: 0.0549\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0938 - mse: 0.0888 - val_loss: 0.0686 - val_mse: 0.0636\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0942 - mse: 0.0893 - val_loss: 0.0581 - val_mse: 0.0532\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0939 - mse: 0.0889 - val_loss: 0.0676 - val_mse: 0.0626\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0950 - mse: 0.0901 - val_loss: 0.0573 - val_mse: 0.0523\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0934 - mse: 0.0885 - val_loss: 0.0643 - val_mse: 0.0594\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0938 - mse: 0.0889 - val_loss: 0.0570 - val_mse: 0.0521\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0880 - val_loss: 0.0682 - val_mse: 0.0632\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0880 - val_loss: 0.0641 - val_mse: 0.0592\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0891 - val_loss: 0.0587 - val_mse: 0.0538\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0945 - mse: 0.0895 - val_loss: 0.0924 - val_mse: 0.0875\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0935 - mse: 0.0886 - val_loss: 0.0616 - val_mse: 0.0567\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0903 - val_loss: 0.0574 - val_mse: 0.0525\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0939 - mse: 0.0890 - val_loss: 0.0576 - val_mse: 0.0527\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0974 - mse: 0.0926 - val_loss: 0.0633 - val_mse: 0.0584\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0897 - val_loss: 0.0610 - val_mse: 0.0561\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0932 - mse: 0.0883 - val_loss: 0.0602 - val_mse: 0.0553\n",
      "Epoch 46: early stopping\n",
      "{'hidden_layer_nodes': [3, 4]}\n",
      "New input layer: input_shape 5 nodes 3\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.5215 - mse: 0.5132 - val_loss: 0.0665 - val_mse: 0.0581\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0997 - mse: 0.0913 - val_loss: 0.0587 - val_mse: 0.0503\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0909 - val_loss: 0.0664 - val_mse: 0.0581\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0996 - mse: 0.0913 - val_loss: 0.0608 - val_mse: 0.0524\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1010 - mse: 0.0926 - val_loss: 0.0599 - val_mse: 0.0516\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.0928 - val_loss: 0.0601 - val_mse: 0.0518\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1009 - mse: 0.0926 - val_loss: 0.0608 - val_mse: 0.0525\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0994 - mse: 0.0910 - val_loss: 0.0591 - val_mse: 0.0508\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1000 - mse: 0.0916 - val_loss: 0.0728 - val_mse: 0.0645\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0984 - mse: 0.0901 - val_loss: 0.0591 - val_mse: 0.0508\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1006 - mse: 0.0923 - val_loss: 0.0592 - val_mse: 0.0509\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1023 - mse: 0.0940 - val_loss: 0.0591 - val_mse: 0.0508\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1003 - mse: 0.0920 - val_loss: 0.0604 - val_mse: 0.0521\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.0928 - val_loss: 0.0593 - val_mse: 0.0510\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0983 - mse: 0.0900 - val_loss: 0.0772 - val_mse: 0.0689\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0915 - val_loss: 0.0624 - val_mse: 0.0542\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.0919 - val_loss: 0.0962 - val_mse: 0.0879\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1018 - mse: 0.0936 - val_loss: 0.0608 - val_mse: 0.0525\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0983 - mse: 0.0900 - val_loss: 0.0629 - val_mse: 0.0547\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0984 - mse: 0.0901 - val_loss: 0.0731 - val_mse: 0.0648\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0999 - mse: 0.0916 - val_loss: 0.0599 - val_mse: 0.0516\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0974 - mse: 0.0891 - val_loss: 0.0597 - val_mse: 0.0514\n",
      "Epoch 22: early stopping\n",
      "{'hidden_layer_nodes': [3, 6]}\n",
      "New input layer: input_shape 5 nodes 3\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.2825 - mse: 1.2728 - val_loss: 0.0714 - val_mse: 0.0617\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1061 - mse: 0.0964 - val_loss: 0.0757 - val_mse: 0.0660\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1057 - mse: 0.0960 - val_loss: 0.0689 - val_mse: 0.0593\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.0978 - val_loss: 0.0656 - val_mse: 0.0559\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1037 - mse: 0.0940 - val_loss: 0.0635 - val_mse: 0.0538\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1043 - mse: 0.0947 - val_loss: 0.0631 - val_mse: 0.0534\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1006 - mse: 0.0909 - val_loss: 0.0632 - val_mse: 0.0536\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1008 - mse: 0.0912 - val_loss: 0.0628 - val_mse: 0.0532\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0988 - mse: 0.0891 - val_loss: 0.0629 - val_mse: 0.0532\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1031 - mse: 0.0935 - val_loss: 0.0761 - val_mse: 0.0665\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1016 - mse: 0.0920 - val_loss: 0.0661 - val_mse: 0.0565\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0902 - val_loss: 0.0627 - val_mse: 0.0531\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1032 - mse: 0.0936 - val_loss: 0.0625 - val_mse: 0.0529\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0993 - mse: 0.0897 - val_loss: 0.0670 - val_mse: 0.0574\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.0915 - val_loss: 0.0648 - val_mse: 0.0552\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.0905 - val_loss: 0.0789 - val_mse: 0.0693\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0999 - mse: 0.0903 - val_loss: 0.0648 - val_mse: 0.0552\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0975 - mse: 0.0879 - val_loss: 0.0610 - val_mse: 0.0514\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0977 - mse: 0.0881 - val_loss: 0.0607 - val_mse: 0.0511\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0827 - val_loss: 0.0600 - val_mse: 0.0504\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0821 - val_loss: 0.0604 - val_mse: 0.0507\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0848 - mse: 0.0752 - val_loss: 0.0556 - val_mse: 0.0459\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0704 - val_loss: 0.0539 - val_mse: 0.0443\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0671 - val_loss: 0.0523 - val_mse: 0.0426\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0621 - val_loss: 0.0636 - val_mse: 0.0539\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0625 - val_loss: 0.0710 - val_mse: 0.0613\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0579 - val_loss: 0.0511 - val_mse: 0.0413\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0566 - val_loss: 0.0491 - val_mse: 0.0394\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0565 - val_loss: 0.0481 - val_mse: 0.0383\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0525 - val_loss: 0.0485 - val_mse: 0.0388\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0619 - mse: 0.0522 - val_loss: 0.0640 - val_mse: 0.0542\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0500 - val_loss: 0.0460 - val_mse: 0.0362\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0482 - val_loss: 0.0465 - val_mse: 0.0368\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0484 - val_loss: 0.0466 - val_mse: 0.0369\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0466 - val_loss: 0.0448 - val_mse: 0.0351\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0457 - val_loss: 0.0430 - val_mse: 0.0333\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0445 - val_loss: 0.0450 - val_mse: 0.0353\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0445 - val_loss: 0.0458 - val_mse: 0.0361\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0429 - val_loss: 0.0577 - val_mse: 0.0481\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0431 - val_loss: 0.0414 - val_mse: 0.0318\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0419 - val_loss: 0.0423 - val_mse: 0.0327\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0414 - val_loss: 0.0431 - val_mse: 0.0335\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0409 - val_loss: 0.0399 - val_mse: 0.0303\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0392 - val_loss: 0.0396 - val_mse: 0.0299\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0493 - mse: 0.0397 - val_loss: 0.0388 - val_mse: 0.0292\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0393 - val_loss: 0.0385 - val_mse: 0.0289\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0382 - val_loss: 0.0435 - val_mse: 0.0339\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0467 - mse: 0.0370 - val_loss: 0.0387 - val_mse: 0.0291\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0379 - val_loss: 0.0667 - val_mse: 0.0571\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0368 - val_loss: 0.0397 - val_mse: 0.0301\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0447 - mse: 0.0352 - val_loss: 0.0379 - val_mse: 0.0283\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0353 - val_loss: 0.0415 - val_mse: 0.0320\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0347 - val_loss: 0.0446 - val_mse: 0.0350\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0342 - val_loss: 0.0367 - val_mse: 0.0271\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0335 - val_loss: 0.0362 - val_mse: 0.0266\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0424 - mse: 0.0328 - val_loss: 0.0353 - val_mse: 0.0257\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0312 - val_loss: 0.0361 - val_mse: 0.0265\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0304 - val_loss: 0.0346 - val_mse: 0.0250\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0297 - val_loss: 0.0342 - val_mse: 0.0246\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0292 - val_loss: 0.0392 - val_mse: 0.0296\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0291 - val_loss: 0.0358 - val_mse: 0.0262\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0283 - val_loss: 0.0433 - val_mse: 0.0337\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0283 - val_loss: 0.0347 - val_mse: 0.0252\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0371 - mse: 0.0276 - val_loss: 0.0330 - val_mse: 0.0235\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0269 - val_loss: 0.0324 - val_mse: 0.0228\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0361 - mse: 0.0266 - val_loss: 0.0323 - val_mse: 0.0228\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0255 - val_loss: 0.0319 - val_mse: 0.0224\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0249 - val_loss: 0.0324 - val_mse: 0.0229\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0339 - mse: 0.0243 - val_loss: 0.0402 - val_mse: 0.0307\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0247 - val_loss: 0.0338 - val_mse: 0.0243\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0230 - val_loss: 0.0311 - val_mse: 0.0215\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0236 - val_loss: 0.0320 - val_mse: 0.0225\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0235 - val_loss: 0.0314 - val_mse: 0.0219\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0228 - val_loss: 0.0435 - val_mse: 0.0341\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0225 - val_loss: 0.0336 - val_mse: 0.0241\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0220 - val_loss: 0.0315 - val_mse: 0.0220\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0216 - val_loss: 0.0324 - val_mse: 0.0229\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0209 - val_loss: 0.0294 - val_mse: 0.0199\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0211 - val_loss: 0.0291 - val_mse: 0.0196\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0208 - val_loss: 0.0312 - val_mse: 0.0218\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0300 - mse: 0.0205 - val_loss: 0.0291 - val_mse: 0.0196\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0200 - val_loss: 0.0287 - val_mse: 0.0192\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0201 - val_loss: 0.0296 - val_mse: 0.0202\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0198 - val_loss: 0.0290 - val_mse: 0.0196\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0193 - val_loss: 0.0306 - val_mse: 0.0212\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0194 - val_loss: 0.0283 - val_mse: 0.0189\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0282 - mse: 0.0188 - val_loss: 0.0278 - val_mse: 0.0184\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0188 - val_loss: 0.0279 - val_mse: 0.0186\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0191 - val_loss: 0.0284 - val_mse: 0.0190\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0184 - val_loss: 0.0279 - val_mse: 0.0185\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0182 - val_loss: 0.0294 - val_mse: 0.0201\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0183 - val_loss: 0.0271 - val_mse: 0.0178\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0180 - val_loss: 0.0269 - val_mse: 0.0176\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0175 - val_loss: 0.0268 - val_mse: 0.0175\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0177 - val_loss: 0.0284 - val_mse: 0.0191\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0182 - val_loss: 0.0294 - val_mse: 0.0201\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0173 - val_loss: 0.0298 - val_mse: 0.0205\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0170 - val_loss: 0.0265 - val_mse: 0.0173\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0168 - val_loss: 0.0291 - val_mse: 0.0198\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0169 - val_loss: 0.0262 - val_mse: 0.0170\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0161 - val_loss: 0.0291 - val_mse: 0.0199\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0166 - val_loss: 0.0273 - val_mse: 0.0181\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0172 - val_loss: 0.0294 - val_mse: 0.0202\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0163 - val_loss: 0.0259 - val_mse: 0.0167\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0164 - val_loss: 0.0259 - val_mse: 0.0167\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0160 - val_loss: 0.0261 - val_mse: 0.0170\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0160 - val_loss: 0.0256 - val_mse: 0.0165\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0167 - val_loss: 0.0260 - val_mse: 0.0169\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0157 - val_loss: 0.0270 - val_mse: 0.0178\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0160 - val_loss: 0.0253 - val_mse: 0.0162\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0156 - val_loss: 0.0270 - val_mse: 0.0179\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0155 - val_loss: 0.0251 - val_mse: 0.0160\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0151 - val_loss: 0.0249 - val_mse: 0.0158\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0156 - val_loss: 0.0252 - val_mse: 0.0161\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0150 - val_loss: 0.0249 - val_mse: 0.0158\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0155 - val_loss: 0.0253 - val_mse: 0.0162\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0157 - val_loss: 0.0250 - val_mse: 0.0159\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0154 - val_loss: 0.0250 - val_mse: 0.0160\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0150 - val_loss: 0.0254 - val_mse: 0.0164\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0148 - val_loss: 0.0247 - val_mse: 0.0157\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0146 - val_loss: 0.0274 - val_mse: 0.0184\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0150 - val_loss: 0.0254 - val_mse: 0.0164\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0148 - val_loss: 0.0244 - val_mse: 0.0154\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0144 - val_loss: 0.0245 - val_mse: 0.0156\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0147 - val_loss: 0.0252 - val_mse: 0.0163\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0143 - val_loss: 0.0244 - val_mse: 0.0155\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0144 - val_loss: 0.0255 - val_mse: 0.0165\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0143 - val_loss: 0.0241 - val_mse: 0.0152\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0144 - val_loss: 0.0245 - val_mse: 0.0156\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0145 - val_loss: 0.0243 - val_mse: 0.0154\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0143 - val_loss: 0.0246 - val_mse: 0.0157\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0146 - val_loss: 0.0239 - val_mse: 0.0151\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0140 - val_loss: 0.0241 - val_mse: 0.0152\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0143 - val_loss: 0.0256 - val_mse: 0.0167\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0140 - val_loss: 0.0234 - val_mse: 0.0146\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0134 - val_loss: 0.0236 - val_mse: 0.0148\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0141 - val_loss: 0.0236 - val_mse: 0.0148\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0141 - val_loss: 0.0248 - val_mse: 0.0160\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0137 - val_loss: 0.0234 - val_mse: 0.0146\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0138 - val_loss: 0.0235 - val_mse: 0.0147\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0139 - val_loss: 0.0257 - val_mse: 0.0170\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0134 - val_loss: 0.0228 - val_mse: 0.0141\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0135 - val_loss: 0.0264 - val_mse: 0.0176\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0134 - val_loss: 0.0230 - val_mse: 0.0143\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0134 - val_loss: 0.0258 - val_mse: 0.0171\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0132 - val_loss: 0.0268 - val_mse: 0.0181\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0135 - val_loss: 0.0257 - val_mse: 0.0170\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0136 - val_loss: 0.0229 - val_mse: 0.0142\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0134 - val_loss: 0.0244 - val_mse: 0.0157\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0136 - val_loss: 0.0227 - val_mse: 0.0140\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0129 - val_loss: 0.0256 - val_mse: 0.0169\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0134 - val_loss: 0.0226 - val_mse: 0.0139\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0133 - val_loss: 0.0226 - val_mse: 0.0140\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0130 - val_loss: 0.0226 - val_mse: 0.0139\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0130 - val_loss: 0.0228 - val_mse: 0.0142\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0134 - val_loss: 0.0247 - val_mse: 0.0161\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0129 - val_loss: 0.0241 - val_mse: 0.0155\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0130 - val_loss: 0.0222 - val_mse: 0.0136\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0127 - val_loss: 0.0225 - val_mse: 0.0139\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0127 - val_loss: 0.0220 - val_mse: 0.0134\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0127 - val_loss: 0.0224 - val_mse: 0.0139\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0127 - val_loss: 0.0222 - val_mse: 0.0137\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0121 - val_loss: 0.0227 - val_mse: 0.0142\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0125 - val_loss: 0.0223 - val_mse: 0.0138\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0132 - val_loss: 0.0219 - val_mse: 0.0134\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0129 - val_loss: 0.0220 - val_mse: 0.0135\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0124 - val_loss: 0.0244 - val_mse: 0.0159\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0125 - val_loss: 0.0234 - val_mse: 0.0149\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0121 - val_loss: 0.0222 - val_mse: 0.0137\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0121 - val_loss: 0.0234 - val_mse: 0.0149\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0122 - val_loss: 0.0215 - val_mse: 0.0130\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0125 - val_loss: 0.0214 - val_mse: 0.0130\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0121 - val_loss: 0.0214 - val_mse: 0.0130\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0122 - val_loss: 0.0214 - val_mse: 0.0130\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0121 - val_loss: 0.0217 - val_mse: 0.0133\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0119 - val_loss: 0.0214 - val_mse: 0.0130\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0121 - val_loss: 0.0213 - val_mse: 0.0129\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0123 - val_loss: 0.0211 - val_mse: 0.0127\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0119 - val_loss: 0.0217 - val_mse: 0.0134\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0120 - val_loss: 0.0211 - val_mse: 0.0127\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0123 - val_loss: 0.0208 - val_mse: 0.0124\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0118 - val_loss: 0.0208 - val_mse: 0.0125\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0117 - val_loss: 0.0209 - val_mse: 0.0126\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0120 - val_loss: 0.0208 - val_mse: 0.0125\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0114 - val_loss: 0.0206 - val_mse: 0.0123\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0116 - val_loss: 0.0206 - val_mse: 0.0123\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0120 - val_loss: 0.0207 - val_mse: 0.0124\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0114 - val_loss: 0.0210 - val_mse: 0.0128\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0113 - val_loss: 0.0214 - val_mse: 0.0131\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0117 - val_loss: 0.0203 - val_mse: 0.0120\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0116 - val_loss: 0.0204 - val_mse: 0.0122\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0118 - val_loss: 0.0208 - val_mse: 0.0126\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0114 - val_loss: 0.0208 - val_mse: 0.0126\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0114 - val_loss: 0.0201 - val_mse: 0.0119\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0112 - val_loss: 0.0201 - val_mse: 0.0119\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0115 - val_loss: 0.0207 - val_mse: 0.0125\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0111 - val_loss: 0.0203 - val_mse: 0.0121\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0112 - val_loss: 0.0209 - val_mse: 0.0127\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0111 - val_loss: 0.0205 - val_mse: 0.0124\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0109 - val_loss: 0.0203 - val_mse: 0.0122\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0109 - val_loss: 0.0198 - val_mse: 0.0117\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0107 - val_loss: 0.0201 - val_mse: 0.0120\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0108 - val_loss: 0.0197 - val_mse: 0.0116\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0107 - val_loss: 0.0198 - val_mse: 0.0117\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0107 - val_loss: 0.0207 - val_mse: 0.0126\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0107 - val_loss: 0.0195 - val_mse: 0.0114\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0106 - val_loss: 0.0198 - val_mse: 0.0117\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0106 - val_loss: 0.0208 - val_mse: 0.0127\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0105 - val_loss: 0.0194 - val_mse: 0.0113\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0111 - val_loss: 0.0192 - val_mse: 0.0112\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0107 - val_loss: 0.0210 - val_mse: 0.0129\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0113 - val_loss: 0.0193 - val_mse: 0.0113\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0103 - val_loss: 0.0196 - val_mse: 0.0116\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0108 - val_loss: 0.0194 - val_mse: 0.0114\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0108 - val_loss: 0.0205 - val_mse: 0.0125\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0105 - val_loss: 0.0190 - val_mse: 0.0110\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0106 - val_loss: 0.0229 - val_mse: 0.0149\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0103 - val_loss: 0.0194 - val_mse: 0.0114\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0103 - val_loss: 0.0188 - val_mse: 0.0109\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0102 - val_loss: 0.0199 - val_mse: 0.0119\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0100 - val_loss: 0.0190 - val_mse: 0.0110\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0100 - val_loss: 0.0193 - val_mse: 0.0114\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0099 - val_loss: 0.0185 - val_mse: 0.0106\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0102 - val_loss: 0.0199 - val_mse: 0.0120\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0097 - val_loss: 0.0194 - val_mse: 0.0115\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0101 - val_loss: 0.0191 - val_mse: 0.0112\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0099 - val_loss: 0.0209 - val_mse: 0.0130\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0098 - val_loss: 0.0187 - val_mse: 0.0108\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0097 - val_loss: 0.0192 - val_mse: 0.0113\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0098 - val_loss: 0.0182 - val_mse: 0.0104\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0097 - val_loss: 0.0180 - val_mse: 0.0102\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0098 - val_loss: 0.0186 - val_mse: 0.0108\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0095 - val_loss: 0.0183 - val_mse: 0.0105\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0093 - val_loss: 0.0190 - val_mse: 0.0111\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0094 - val_loss: 0.0186 - val_mse: 0.0108\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0094 - val_loss: 0.0181 - val_mse: 0.0103\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0094 - val_loss: 0.0180 - val_mse: 0.0102\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0096 - val_loss: 0.0177 - val_mse: 0.0099\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0092 - val_loss: 0.0184 - val_mse: 0.0106\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0092 - val_loss: 0.0184 - val_mse: 0.0106\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0092 - val_loss: 0.0180 - val_mse: 0.0102\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0091 - val_loss: 0.0183 - val_mse: 0.0105\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0091 - val_loss: 0.0190 - val_mse: 0.0113\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0092 - val_loss: 0.0213 - val_mse: 0.0135\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0092 - val_loss: 0.0185 - val_mse: 0.0107\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0091 - val_loss: 0.0173 - val_mse: 0.0096\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0088 - val_loss: 0.0174 - val_mse: 0.0096\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0090 - val_loss: 0.0185 - val_mse: 0.0108\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0089 - val_loss: 0.0186 - val_mse: 0.0109\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0089 - val_loss: 0.0175 - val_mse: 0.0098\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0087 - val_loss: 0.0170 - val_mse: 0.0093\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0088 - val_loss: 0.0176 - val_mse: 0.0099\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0087 - val_loss: 0.0175 - val_mse: 0.0098\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0087 - val_loss: 0.0169 - val_mse: 0.0092\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0087 - val_loss: 0.0169 - val_mse: 0.0092\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0085 - val_loss: 0.0171 - val_mse: 0.0094\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0083 - val_loss: 0.0216 - val_mse: 0.0139\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0085 - val_loss: 0.0169 - val_mse: 0.0093\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0082 - val_loss: 0.0167 - val_mse: 0.0091\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0083 - val_loss: 0.0176 - val_mse: 0.0100\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0087 - val_loss: 0.0165 - val_mse: 0.0088\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0081 - val_loss: 0.0206 - val_mse: 0.0130\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0084 - val_loss: 0.0167 - val_mse: 0.0091\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0080 - val_loss: 0.0171 - val_mse: 0.0095\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0082 - val_loss: 0.0174 - val_mse: 0.0098\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0082 - val_loss: 0.0165 - val_mse: 0.0089\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0080 - val_loss: 0.0170 - val_mse: 0.0094\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0079 - val_loss: 0.0162 - val_mse: 0.0086\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0081 - val_loss: 0.0162 - val_mse: 0.0086\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0078 - val_loss: 0.0160 - val_mse: 0.0084\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0079 - val_loss: 0.0171 - val_mse: 0.0095\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0079 - val_loss: 0.0185 - val_mse: 0.0109\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0077 - val_loss: 0.0174 - val_mse: 0.0098\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0078 - val_loss: 0.0164 - val_mse: 0.0088\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0078 - val_loss: 0.0157 - val_mse: 0.0082\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0076 - val_loss: 0.0163 - val_mse: 0.0088\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0077 - val_loss: 0.0156 - val_mse: 0.0081\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0077 - val_loss: 0.0164 - val_mse: 0.0089\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0076 - val_loss: 0.0158 - val_mse: 0.0083\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0072 - val_loss: 0.0157 - val_mse: 0.0082\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0076 - val_loss: 0.0157 - val_mse: 0.0082\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0078 - val_loss: 0.0156 - val_mse: 0.0081\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0073 - val_loss: 0.0168 - val_mse: 0.0093\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0072 - val_loss: 0.0154 - val_mse: 0.0079\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0072 - val_loss: 0.0155 - val_mse: 0.0080\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0074 - val_loss: 0.0152 - val_mse: 0.0077\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0075 - val_loss: 0.0150 - val_mse: 0.0075\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0074 - val_loss: 0.0156 - val_mse: 0.0081\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0071 - val_loss: 0.0152 - val_mse: 0.0077\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0069 - val_loss: 0.0149 - val_mse: 0.0074\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0069 - val_loss: 0.0158 - val_mse: 0.0083\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0071 - val_loss: 0.0161 - val_mse: 0.0086\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0070 - val_loss: 0.0148 - val_mse: 0.0073\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0070 - val_loss: 0.0164 - val_mse: 0.0089\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0070 - val_loss: 0.0157 - val_mse: 0.0083\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0068 - val_loss: 0.0162 - val_mse: 0.0087\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0070 - val_loss: 0.0145 - val_mse: 0.0071\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0068 - val_loss: 0.0149 - val_mse: 0.0075\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0067 - val_loss: 0.0147 - val_mse: 0.0072\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0067 - val_loss: 0.0160 - val_mse: 0.0086\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0065 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0066 - val_loss: 0.0164 - val_mse: 0.0089\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0067 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0065 - val_loss: 0.0145 - val_mse: 0.0071\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0063 - val_loss: 0.0141 - val_mse: 0.0067\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0068 - val_loss: 0.0153 - val_mse: 0.0079\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0064 - val_loss: 0.0140 - val_mse: 0.0066\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0064 - val_loss: 0.0138 - val_mse: 0.0064\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0067 - val_loss: 0.0151 - val_mse: 0.0077\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0063 - val_loss: 0.0137 - val_mse: 0.0064\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0063 - val_loss: 0.0139 - val_mse: 0.0065\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0062 - val_loss: 0.0139 - val_mse: 0.0066\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0059 - val_loss: 0.0137 - val_mse: 0.0064\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0061 - val_loss: 0.0137 - val_mse: 0.0064\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0060 - val_loss: 0.0134 - val_mse: 0.0061\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0060 - val_loss: 0.0148 - val_mse: 0.0075\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0061 - val_loss: 0.0155 - val_mse: 0.0082\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0060 - val_loss: 0.0136 - val_mse: 0.0063\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0060 - val_loss: 0.0143 - val_mse: 0.0070\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0059 - val_loss: 0.0132 - val_mse: 0.0059\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0058 - val_loss: 0.0133 - val_mse: 0.0060\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0059 - val_loss: 0.0141 - val_mse: 0.0068\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0056 - val_loss: 0.0137 - val_mse: 0.0064\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0058 - val_loss: 0.0137 - val_mse: 0.0064\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0058 - val_loss: 0.0150 - val_mse: 0.0077\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0057 - val_loss: 0.0167 - val_mse: 0.0094\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0057 - val_loss: 0.0148 - val_mse: 0.0075\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0056 - val_loss: 0.0133 - val_mse: 0.0060\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0056 - val_loss: 0.0139 - val_mse: 0.0067\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0055 - val_loss: 0.0132 - val_mse: 0.0060\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0055 - val_loss: 0.0128 - val_mse: 0.0055\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0056 - val_loss: 0.0129 - val_mse: 0.0056\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0053 - val_loss: 0.0128 - val_mse: 0.0055\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0053 - val_loss: 0.0138 - val_mse: 0.0066\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0054 - val_loss: 0.0126 - val_mse: 0.0054\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0055 - val_loss: 0.0125 - val_mse: 0.0053\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0052 - val_loss: 0.0130 - val_mse: 0.0058\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0053 - val_loss: 0.0124 - val_mse: 0.0052\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0124 - val_mse: 0.0052\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0126 - val_mse: 0.0054\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0125 - val_mse: 0.0053\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0050\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0122 - val_mse: 0.0050\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0136 - val_mse: 0.0064\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0129 - val_mse: 0.0057\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0051 - val_loss: 0.0139 - val_mse: 0.0067\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0052 - val_loss: 0.0124 - val_mse: 0.0053\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0049 - val_loss: 0.0127 - val_mse: 0.0056\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0049 - val_loss: 0.0120 - val_mse: 0.0048\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0048 - val_loss: 0.0122 - val_mse: 0.0051\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0050 - val_loss: 0.0119 - val_mse: 0.0047\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0048 - val_loss: 0.0119 - val_mse: 0.0048\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0048 - val_loss: 0.0117 - val_mse: 0.0046\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0048 - val_loss: 0.0119 - val_mse: 0.0048\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0046 - val_loss: 0.0118 - val_mse: 0.0047\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0049 - val_loss: 0.0117 - val_mse: 0.0046\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0048 - val_loss: 0.0125 - val_mse: 0.0054\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0049 - val_loss: 0.0118 - val_mse: 0.0047\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0047 - val_loss: 0.0142 - val_mse: 0.0071\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0045 - val_loss: 0.0115 - val_mse: 0.0044\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0046 - val_loss: 0.0121 - val_mse: 0.0050\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0048 - val_loss: 0.0117 - val_mse: 0.0047\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0048 - val_loss: 0.0119 - val_mse: 0.0048\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0047 - val_loss: 0.0116 - val_mse: 0.0045\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0045 - val_loss: 0.0125 - val_mse: 0.0054\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0046 - val_loss: 0.0113 - val_mse: 0.0043\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0047 - val_loss: 0.0121 - val_mse: 0.0050\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0043 - val_loss: 0.0112 - val_mse: 0.0042\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0044 - val_loss: 0.0117 - val_mse: 0.0046\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0045 - val_loss: 0.0115 - val_mse: 0.0045\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0047 - val_loss: 0.0113 - val_mse: 0.0042\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0044 - val_loss: 0.0116 - val_mse: 0.0046\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0043 - val_loss: 0.0113 - val_mse: 0.0043\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0044 - val_loss: 0.0117 - val_mse: 0.0046\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0045 - val_loss: 0.0114 - val_mse: 0.0044\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0044 - val_loss: 0.0114 - val_mse: 0.0044\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0042 - val_loss: 0.0127 - val_mse: 0.0057\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0042 - val_loss: 0.0142 - val_mse: 0.0072\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0044 - val_loss: 0.0117 - val_mse: 0.0047\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0042 - val_loss: 0.0119 - val_mse: 0.0050\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0043 - val_loss: 0.0109 - val_mse: 0.0039\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0041 - val_loss: 0.0115 - val_mse: 0.0045\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0041 - val_loss: 0.0111 - val_mse: 0.0041\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0042 - val_loss: 0.0137 - val_mse: 0.0067\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0043 - val_loss: 0.0129 - val_mse: 0.0059\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0041 - val_loss: 0.0109 - val_mse: 0.0040\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0043 - val_loss: 0.0108 - val_mse: 0.0039\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0041 - val_loss: 0.0110 - val_mse: 0.0041\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0042 - val_loss: 0.0107 - val_mse: 0.0038\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0111 - val_mse: 0.0042\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0042 - val_loss: 0.0109 - val_mse: 0.0040\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0041 - val_loss: 0.0106 - val_mse: 0.0037\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0114 - val_mse: 0.0045\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0116 - val_mse: 0.0047\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0111 - val_mse: 0.0042\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0110 - val_mse: 0.0041\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0041 - val_loss: 0.0116 - val_mse: 0.0047\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0041 - val_loss: 0.0105 - val_mse: 0.0036\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0119 - val_mse: 0.0050\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0110 - val_mse: 0.0041\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0040 - val_loss: 0.0107 - val_mse: 0.0038\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0039 - val_loss: 0.0104 - val_mse: 0.0035\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0037 - val_loss: 0.0104 - val_mse: 0.0035\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0103 - val_mse: 0.0034\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0039 - val_loss: 0.0104 - val_mse: 0.0035\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0041 - val_loss: 0.0106 - val_mse: 0.0038\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0102 - val_mse: 0.0034\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0108 - val_mse: 0.0040\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0040 - val_loss: 0.0105 - val_mse: 0.0037\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0109 - val_mse: 0.0041\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0104 - val_mse: 0.0036\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0037 - val_loss: 0.0110 - val_mse: 0.0042\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0037 - val_loss: 0.0101 - val_mse: 0.0033\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0101 - val_mse: 0.0033\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0102 - val_mse: 0.0034\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0037 - val_loss: 0.0100 - val_mse: 0.0033\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0039 - val_loss: 0.0103 - val_mse: 0.0035\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0038 - val_loss: 0.0107 - val_mse: 0.0039\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0036 - val_loss: 0.0100 - val_mse: 0.0032\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0038 - val_loss: 0.0131 - val_mse: 0.0063\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0037 - val_loss: 0.0104 - val_mse: 0.0037\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0036 - val_loss: 0.0100 - val_mse: 0.0032\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0037 - val_loss: 0.0100 - val_mse: 0.0032\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0036 - val_loss: 0.0099 - val_mse: 0.0031\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0038 - val_loss: 0.0098 - val_mse: 0.0031\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0036 - val_loss: 0.0099 - val_mse: 0.0032\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0036 - val_loss: 0.0099 - val_mse: 0.0032\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0100 - val_mse: 0.0033\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0036 - val_loss: 0.0098 - val_mse: 0.0031\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0036 - val_loss: 0.0098 - val_mse: 0.0031\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0098 - val_mse: 0.0031\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0114 - val_mse: 0.0047\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0097 - val_mse: 0.0031\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0105 - val_mse: 0.0038\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0034 - val_loss: 0.0113 - val_mse: 0.0046\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0100 - val_mse: 0.0033\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0034 - val_loss: 0.0098 - val_mse: 0.0031\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0035 - val_loss: 0.0113 - val_mse: 0.0046\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0035 - val_loss: 0.0097 - val_mse: 0.0031\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0034 - val_loss: 0.0097 - val_mse: 0.0031\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0033 - val_loss: 0.0100 - val_mse: 0.0034\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0035 - val_loss: 0.0098 - val_mse: 0.0032\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0034 - val_loss: 0.0099 - val_mse: 0.0032\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0033 - val_loss: 0.0100 - val_mse: 0.0034\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0034 - val_loss: 0.0095 - val_mse: 0.0029\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0033 - val_loss: 0.0099 - val_mse: 0.0032\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0033 - val_loss: 0.0098 - val_mse: 0.0032\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0095 - val_mse: 0.0029\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0095 - val_mse: 0.0029\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0033 - val_loss: 0.0098 - val_mse: 0.0032\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0033 - val_loss: 0.0097 - val_mse: 0.0031\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0034 - val_loss: 0.0099 - val_mse: 0.0033\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0031 - val_loss: 0.0094 - val_mse: 0.0028\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0093 - val_mse: 0.0027\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0093 - val_mse: 0.0028\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0120 - val_mse: 0.0054\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0033 - val_loss: 0.0112 - val_mse: 0.0046\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0033 - val_loss: 0.0102 - val_mse: 0.0036\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0032 - val_loss: 0.0093 - val_mse: 0.0027\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0032 - val_loss: 0.0098 - val_mse: 0.0033\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0033 - val_loss: 0.0103 - val_mse: 0.0038\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0032 - val_loss: 0.0092 - val_mse: 0.0026\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0032 - val_loss: 0.0100 - val_mse: 0.0034\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0032 - val_loss: 0.0093 - val_mse: 0.0028\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0031 - val_loss: 0.0092 - val_mse: 0.0027\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0030 - val_loss: 0.0098 - val_mse: 0.0033\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0030 - val_loss: 0.0092 - val_mse: 0.0027\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0032 - val_loss: 0.0101 - val_mse: 0.0036\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0030 - val_loss: 0.0091 - val_mse: 0.0026\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0031 - val_loss: 0.0094 - val_mse: 0.0029\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0031 - val_loss: 0.0091 - val_mse: 0.0026\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0031 - val_loss: 0.0091 - val_mse: 0.0026\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0091 - val_mse: 0.0027\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0091 - val_mse: 0.0027\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0030 - val_loss: 0.0091 - val_mse: 0.0026\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0124 - val_mse: 0.0060\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0029 - val_loss: 0.0101 - val_mse: 0.0036\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0031 - val_loss: 0.0102 - val_mse: 0.0037\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0032 - val_loss: 0.0090 - val_mse: 0.0025\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0031 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0090 - val_mse: 0.0025\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0031 - val_loss: 0.0095 - val_mse: 0.0031\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0031 - val_loss: 0.0093 - val_mse: 0.0029\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0105 - val_mse: 0.0041\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0092 - val_mse: 0.0028\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0091 - val_mse: 0.0027\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0029 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0030 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0030 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0088 - val_mse: 0.0024\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0088 - val_mse: 0.0024\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0029 - val_loss: 0.0089 - val_mse: 0.0025\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0028 - val_loss: 0.0091 - val_mse: 0.0027\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0028 - val_loss: 0.0090 - val_mse: 0.0026\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0028 - val_loss: 0.0087 - val_mse: 0.0024\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0027 - val_loss: 0.0088 - val_mse: 0.0024\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0028 - val_loss: 0.0087 - val_mse: 0.0024\n",
      "{'hidden_layer_nodes': [4, 2]}\n",
      "New input layer: input_shape 5 nodes 4\n",
      "New hidden layer: nodes 2\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.4623 - mse: 1.4544 - val_loss: 0.0635 - val_mse: 0.0556\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.0923 - val_loss: 0.0618 - val_mse: 0.0539\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0999 - mse: 0.0919 - val_loss: 0.0622 - val_mse: 0.0543\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0997 - mse: 0.0918 - val_loss: 0.0618 - val_mse: 0.0538\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0972 - mse: 0.0892 - val_loss: 0.0629 - val_mse: 0.0550\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0987 - mse: 0.0907 - val_loss: 0.0630 - val_mse: 0.0550\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.0922 - val_loss: 0.0646 - val_mse: 0.0567\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0884 - val_loss: 0.0632 - val_mse: 0.0553\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1004 - mse: 0.0925 - val_loss: 0.0637 - val_mse: 0.0557\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0971 - mse: 0.0892 - val_loss: 0.0647 - val_mse: 0.0568\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0988 - mse: 0.0908 - val_loss: 0.0604 - val_mse: 0.0525\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0974 - mse: 0.0894 - val_loss: 0.0719 - val_mse: 0.0640\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0976 - mse: 0.0897 - val_loss: 0.0605 - val_mse: 0.0525\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0885 - val_loss: 0.1108 - val_mse: 0.1029\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0972 - mse: 0.0893 - val_loss: 0.0788 - val_mse: 0.0708\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0902 - val_loss: 0.0627 - val_mse: 0.0548\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0991 - mse: 0.0912 - val_loss: 0.0645 - val_mse: 0.0565\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0884 - val_loss: 0.0616 - val_mse: 0.0536\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0987 - mse: 0.0907 - val_loss: 0.0651 - val_mse: 0.0571\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0981 - mse: 0.0901 - val_loss: 0.0610 - val_mse: 0.0530\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0969 - mse: 0.0890 - val_loss: 0.0626 - val_mse: 0.0546\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0969 - mse: 0.0890 - val_loss: 0.0617 - val_mse: 0.0538\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0971 - mse: 0.0892 - val_loss: 0.0616 - val_mse: 0.0537\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0971 - mse: 0.0892 - val_loss: 0.0605 - val_mse: 0.0526\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0970 - mse: 0.0890 - val_loss: 0.0628 - val_mse: 0.0549\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0979 - mse: 0.0900 - val_loss: 0.0718 - val_mse: 0.0639\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1003 - mse: 0.0924 - val_loss: 0.0777 - val_mse: 0.0698\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0960 - mse: 0.0881 - val_loss: 0.0639 - val_mse: 0.0560\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0987 - mse: 0.0908 - val_loss: 0.0771 - val_mse: 0.0692\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0968 - mse: 0.0889 - val_loss: 0.0616 - val_mse: 0.0537\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0967 - mse: 0.0889 - val_loss: 0.0661 - val_mse: 0.0582\n",
      "Epoch 31: early stopping\n",
      "{'hidden_layer_nodes': [4, 4]}\n",
      "New input layer: input_shape 5 nodes 4\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.3181 - mse: 1.3056 - val_loss: 0.0569 - val_mse: 0.0444\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0362 - val_loss: 0.0407 - val_mse: 0.0281\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0310 - val_loss: 0.0343 - val_mse: 0.0217\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0294 - val_loss: 0.0392 - val_mse: 0.0266\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0296 - val_loss: 0.0340 - val_mse: 0.0215\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0291 - val_loss: 0.0344 - val_mse: 0.0218\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0281 - val_loss: 0.0356 - val_mse: 0.0230\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0270 - val_loss: 0.0335 - val_mse: 0.0210\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0266 - val_loss: 0.0321 - val_mse: 0.0196\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0259 - val_loss: 0.0359 - val_mse: 0.0234\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0242 - val_loss: 0.0321 - val_mse: 0.0196\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0242 - val_loss: 0.0316 - val_mse: 0.0191\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0240 - val_loss: 0.0310 - val_mse: 0.0185\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0354 - mse: 0.0229 - val_loss: 0.0311 - val_mse: 0.0186\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0238 - val_loss: 0.0308 - val_mse: 0.0183\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0231 - val_loss: 0.0307 - val_mse: 0.0182\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0230 - val_loss: 0.0308 - val_mse: 0.0183\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0224 - val_loss: 0.0329 - val_mse: 0.0204\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0233 - val_loss: 0.0307 - val_mse: 0.0183\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0225 - val_loss: 0.0353 - val_mse: 0.0228\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0354 - mse: 0.0230 - val_loss: 0.0340 - val_mse: 0.0216\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0222 - val_loss: 0.0307 - val_mse: 0.0183\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0340 - mse: 0.0216 - val_loss: 0.0305 - val_mse: 0.0180\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0222 - val_loss: 0.0308 - val_mse: 0.0183\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0225 - val_loss: 0.0313 - val_mse: 0.0188\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0215 - val_loss: 0.0305 - val_mse: 0.0181\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0214 - val_loss: 0.0309 - val_mse: 0.0184\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0221 - val_loss: 0.0315 - val_mse: 0.0190\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0213 - val_loss: 0.0301 - val_mse: 0.0177\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0344 - mse: 0.0220 - val_loss: 0.0305 - val_mse: 0.0181\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0217 - val_loss: 0.0331 - val_mse: 0.0206\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0220 - val_loss: 0.0302 - val_mse: 0.0178\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0213 - val_loss: 0.0305 - val_mse: 0.0181\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0335 - mse: 0.0211 - val_loss: 0.0337 - val_mse: 0.0214\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0214 - val_loss: 0.0360 - val_mse: 0.0236\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0206 - val_loss: 0.0331 - val_mse: 0.0207\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0209 - val_loss: 0.0296 - val_mse: 0.0172\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0200 - val_loss: 0.0324 - val_mse: 0.0200\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0214 - val_loss: 0.0294 - val_mse: 0.0170\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0202 - val_loss: 0.0293 - val_mse: 0.0169\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0209 - val_loss: 0.0298 - val_mse: 0.0174\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0206 - val_loss: 0.0292 - val_mse: 0.0169\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0207 - val_loss: 0.0302 - val_mse: 0.0178\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0203 - val_loss: 0.0291 - val_mse: 0.0168\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0200 - val_loss: 0.0306 - val_mse: 0.0183\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0198 - val_loss: 0.0289 - val_mse: 0.0166\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0204 - val_loss: 0.0321 - val_mse: 0.0198\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0209 - val_loss: 0.0320 - val_mse: 0.0197\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0198 - val_loss: 0.0348 - val_mse: 0.0225\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0200 - val_loss: 0.0293 - val_mse: 0.0170\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0202 - val_loss: 0.0289 - val_mse: 0.0167\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0194 - val_loss: 0.0287 - val_mse: 0.0165\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0195 - val_loss: 0.0285 - val_mse: 0.0163\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0197 - val_loss: 0.0285 - val_mse: 0.0163\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0199 - val_loss: 0.0371 - val_mse: 0.0249\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0195 - val_loss: 0.0283 - val_mse: 0.0161\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0192 - val_loss: 0.0282 - val_mse: 0.0160\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0192 - val_loss: 0.0332 - val_mse: 0.0210\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0194 - val_loss: 0.0285 - val_mse: 0.0163\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0192 - val_loss: 0.0293 - val_mse: 0.0171\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0191 - val_loss: 0.0281 - val_mse: 0.0159\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0312 - mse: 0.0190 - val_loss: 0.0279 - val_mse: 0.0157\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0195 - val_loss: 0.0298 - val_mse: 0.0177\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0185 - val_loss: 0.0331 - val_mse: 0.0209\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0311 - mse: 0.0189 - val_loss: 0.0290 - val_mse: 0.0168\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0187 - val_loss: 0.0279 - val_mse: 0.0157\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0199 - val_loss: 0.0325 - val_mse: 0.0204\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0189 - val_loss: 0.0277 - val_mse: 0.0156\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0185 - val_loss: 0.0282 - val_mse: 0.0160\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0195 - val_loss: 0.0276 - val_mse: 0.0155\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0183 - val_loss: 0.0280 - val_mse: 0.0159\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0187 - val_loss: 0.0290 - val_mse: 0.0169\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0192 - val_loss: 0.0275 - val_mse: 0.0154\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0184 - val_loss: 0.0273 - val_mse: 0.0152\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0187 - val_loss: 0.0289 - val_mse: 0.0169\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0177 - val_loss: 0.0357 - val_mse: 0.0236\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0187 - val_loss: 0.0274 - val_mse: 0.0154\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0185 - val_loss: 0.0273 - val_mse: 0.0153\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0186 - val_loss: 0.0298 - val_mse: 0.0178\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0186 - val_loss: 0.0291 - val_mse: 0.0171\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0176 - val_loss: 0.0268 - val_mse: 0.0148\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0182 - val_loss: 0.0268 - val_mse: 0.0149\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0176 - val_loss: 0.0278 - val_mse: 0.0158\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0177 - val_loss: 0.0292 - val_mse: 0.0173\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0178 - val_loss: 0.0269 - val_mse: 0.0149\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0170 - val_loss: 0.0278 - val_mse: 0.0159\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0174 - val_loss: 0.0266 - val_mse: 0.0147\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0174 - val_loss: 0.0272 - val_mse: 0.0152\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0175 - val_loss: 0.0263 - val_mse: 0.0144\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0175 - val_loss: 0.0260 - val_mse: 0.0141\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0295 - mse: 0.0176 - val_loss: 0.0271 - val_mse: 0.0152\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0170 - val_loss: 0.0260 - val_mse: 0.0141\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0290 - mse: 0.0171 - val_loss: 0.0332 - val_mse: 0.0213\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0175 - val_loss: 0.0264 - val_mse: 0.0145\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0177 - val_loss: 0.0262 - val_mse: 0.0143\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0300 - mse: 0.0181 - val_loss: 0.0282 - val_mse: 0.0163\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0171 - val_loss: 0.0258 - val_mse: 0.0139\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0168 - val_loss: 0.0257 - val_mse: 0.0138\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0171 - val_loss: 0.0315 - val_mse: 0.0196\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0168 - val_loss: 0.0416 - val_mse: 0.0297\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0167 - val_loss: 0.0287 - val_mse: 0.0169\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0166 - val_loss: 0.0255 - val_mse: 0.0136\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0166 - val_loss: 0.0262 - val_mse: 0.0144\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0162 - val_loss: 0.0254 - val_mse: 0.0136\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0159 - val_loss: 0.0269 - val_mse: 0.0151\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0283 - mse: 0.0165 - val_loss: 0.0255 - val_mse: 0.0137\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0163 - val_loss: 0.0261 - val_mse: 0.0143\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0160 - val_loss: 0.0266 - val_mse: 0.0149\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0167 - val_loss: 0.0258 - val_mse: 0.0141\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0161 - val_loss: 0.0251 - val_mse: 0.0134\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0161 - val_loss: 0.0249 - val_mse: 0.0132\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0161 - val_loss: 0.0250 - val_mse: 0.0132\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0161 - val_loss: 0.0266 - val_mse: 0.0148\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0163 - val_loss: 0.0248 - val_mse: 0.0130\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0161 - val_loss: 0.0248 - val_mse: 0.0131\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0153 - val_loss: 0.0262 - val_mse: 0.0145\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0158 - val_loss: 0.0246 - val_mse: 0.0130\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0159 - val_loss: 0.0260 - val_mse: 0.0143\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0157 - val_loss: 0.0257 - val_mse: 0.0140\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0153 - val_loss: 0.0281 - val_mse: 0.0165\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0158 - val_loss: 0.0265 - val_mse: 0.0148\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0159 - val_loss: 0.0290 - val_mse: 0.0173\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0152 - val_loss: 0.0243 - val_mse: 0.0126\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0154 - val_loss: 0.0257 - val_mse: 0.0140\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0150 - val_loss: 0.0251 - val_mse: 0.0134\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0150 - val_loss: 0.0240 - val_mse: 0.0123\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0152 - val_loss: 0.0241 - val_mse: 0.0125\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0151 - val_loss: 0.0252 - val_mse: 0.0136\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0148 - val_loss: 0.0239 - val_mse: 0.0123\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0145 - val_loss: 0.0240 - val_mse: 0.0124\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0146 - val_loss: 0.0240 - val_mse: 0.0124\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0147 - val_loss: 0.0246 - val_mse: 0.0130\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0144 - val_loss: 0.0246 - val_mse: 0.0130\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0147 - val_loss: 0.0237 - val_mse: 0.0121\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0144 - val_loss: 0.0247 - val_mse: 0.0131\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0146 - val_loss: 0.0237 - val_mse: 0.0121\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0145 - val_loss: 0.0247 - val_mse: 0.0131\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0146 - val_loss: 0.0240 - val_mse: 0.0124\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0141 - val_loss: 0.0241 - val_mse: 0.0125\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0145 - val_loss: 0.0235 - val_mse: 0.0120\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0141 - val_loss: 0.0233 - val_mse: 0.0118\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0139 - val_loss: 0.0234 - val_mse: 0.0119\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0135 - val_loss: 0.0263 - val_mse: 0.0148\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0139 - val_loss: 0.0238 - val_mse: 0.0123\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0137 - val_loss: 0.0238 - val_mse: 0.0123\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0136 - val_loss: 0.0234 - val_mse: 0.0119\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0137 - val_loss: 0.0245 - val_mse: 0.0130\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0134 - val_loss: 0.0229 - val_mse: 0.0114\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0140 - val_loss: 0.0229 - val_mse: 0.0114\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0134 - val_loss: 0.0232 - val_mse: 0.0117\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0131 - val_loss: 0.0227 - val_mse: 0.0112\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0136 - val_loss: 0.0235 - val_mse: 0.0121\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0129 - val_loss: 0.0269 - val_mse: 0.0154\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0134 - val_loss: 0.0240 - val_mse: 0.0125\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0132 - val_loss: 0.0230 - val_mse: 0.0115\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0127 - val_loss: 0.0233 - val_mse: 0.0119\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0127 - val_loss: 0.0231 - val_mse: 0.0116\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0126 - val_loss: 0.0232 - val_mse: 0.0118\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0126 - val_loss: 0.0223 - val_mse: 0.0109\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0123 - val_loss: 0.0230 - val_mse: 0.0116\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0125 - val_loss: 0.0225 - val_mse: 0.0111\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0123 - val_loss: 0.0222 - val_mse: 0.0108\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0124 - val_loss: 0.0230 - val_mse: 0.0116\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0122 - val_loss: 0.0273 - val_mse: 0.0159\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0126 - val_loss: 0.0227 - val_mse: 0.0114\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0124 - val_loss: 0.0243 - val_mse: 0.0130\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0117 - val_loss: 0.0217 - val_mse: 0.0104\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0120 - val_loss: 0.0222 - val_mse: 0.0109\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0119 - val_loss: 0.0217 - val_mse: 0.0103\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0118 - val_loss: 0.0219 - val_mse: 0.0106\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0116 - val_loss: 0.0219 - val_mse: 0.0106\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0118 - val_loss: 0.0217 - val_mse: 0.0104\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0115 - val_loss: 0.0223 - val_mse: 0.0110\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0112 - val_loss: 0.0222 - val_mse: 0.0109\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0114 - val_loss: 0.0228 - val_mse: 0.0116\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0115 - val_loss: 0.0216 - val_mse: 0.0103\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0114 - val_loss: 0.0219 - val_mse: 0.0106\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0111 - val_loss: 0.0211 - val_mse: 0.0099\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0107 - val_loss: 0.0211 - val_mse: 0.0098\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0111 - val_loss: 0.0261 - val_mse: 0.0149\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0108 - val_loss: 0.0215 - val_mse: 0.0103\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0105 - val_loss: 0.0210 - val_mse: 0.0098\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0110 - val_loss: 0.0220 - val_mse: 0.0108\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0108 - val_loss: 0.0208 - val_mse: 0.0097\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0104 - val_loss: 0.0223 - val_mse: 0.0111\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0104 - val_loss: 0.0233 - val_mse: 0.0121\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0107 - val_loss: 0.0241 - val_mse: 0.0129\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0101 - val_loss: 0.0214 - val_mse: 0.0102\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0103 - val_loss: 0.0205 - val_mse: 0.0093\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0101 - val_loss: 0.0205 - val_mse: 0.0093\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0104 - val_loss: 0.0217 - val_mse: 0.0106\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0100 - val_loss: 0.0209 - val_mse: 0.0098\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0100 - val_loss: 0.0226 - val_mse: 0.0114\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0096 - val_loss: 0.0225 - val_mse: 0.0114\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0095 - val_loss: 0.0206 - val_mse: 0.0095\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0095 - val_loss: 0.0204 - val_mse: 0.0093\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0095 - val_loss: 0.0204 - val_mse: 0.0093\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0095 - val_loss: 0.0200 - val_mse: 0.0090\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0093 - val_loss: 0.0198 - val_mse: 0.0087\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0093 - val_loss: 0.0212 - val_mse: 0.0102\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0090 - val_loss: 0.0231 - val_mse: 0.0121\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0088 - val_loss: 0.0197 - val_mse: 0.0087\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0089 - val_loss: 0.0215 - val_mse: 0.0105\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0089 - val_loss: 0.0200 - val_mse: 0.0090\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0085 - val_loss: 0.0209 - val_mse: 0.0099\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0084 - val_loss: 0.0194 - val_mse: 0.0084\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0086 - val_loss: 0.0195 - val_mse: 0.0086\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0087 - val_loss: 0.0193 - val_mse: 0.0084\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0084 - val_loss: 0.0192 - val_mse: 0.0082\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0081 - val_loss: 0.0192 - val_mse: 0.0083\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0084 - val_loss: 0.0246 - val_mse: 0.0137\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0080 - val_loss: 0.0192 - val_mse: 0.0084\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0082 - val_loss: 0.0189 - val_mse: 0.0081\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0080 - val_loss: 0.0191 - val_mse: 0.0082\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0080 - val_loss: 0.0193 - val_mse: 0.0085\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0077 - val_loss: 0.0202 - val_mse: 0.0094\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0079 - val_loss: 0.0188 - val_mse: 0.0079\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0080 - val_loss: 0.0190 - val_mse: 0.0082\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0076 - val_loss: 0.0188 - val_mse: 0.0080\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0076 - val_loss: 0.0211 - val_mse: 0.0103\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0074 - val_loss: 0.0200 - val_mse: 0.0092\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0072 - val_loss: 0.0191 - val_mse: 0.0083\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0073 - val_loss: 0.0185 - val_mse: 0.0077\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0072 - val_loss: 0.0183 - val_mse: 0.0075\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0073 - val_loss: 0.0183 - val_mse: 0.0075\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0072 - val_loss: 0.0183 - val_mse: 0.0075\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0071 - val_loss: 0.0187 - val_mse: 0.0079\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0070 - val_loss: 0.0185 - val_mse: 0.0077\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0072 - val_loss: 0.0182 - val_mse: 0.0074\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0069 - val_loss: 0.0192 - val_mse: 0.0084\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0067 - val_loss: 0.0184 - val_mse: 0.0077\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0067 - val_loss: 0.0181 - val_mse: 0.0074\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0067 - val_loss: 0.0197 - val_mse: 0.0090\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0066 - val_loss: 0.0189 - val_mse: 0.0082\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0066 - val_loss: 0.0183 - val_mse: 0.0076\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0066 - val_loss: 0.0177 - val_mse: 0.0070\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0063 - val_loss: 0.0182 - val_mse: 0.0075\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0064 - val_loss: 0.0179 - val_mse: 0.0072\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0064 - val_loss: 0.0177 - val_mse: 0.0070\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0063 - val_loss: 0.0190 - val_mse: 0.0083\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0062 - val_loss: 0.0182 - val_mse: 0.0075\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0062 - val_loss: 0.0177 - val_mse: 0.0070\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0061 - val_loss: 0.0178 - val_mse: 0.0072\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0062 - val_loss: 0.0180 - val_mse: 0.0073\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0062 - val_loss: 0.0178 - val_mse: 0.0071\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0060 - val_loss: 0.0178 - val_mse: 0.0072\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0062 - val_loss: 0.0174 - val_mse: 0.0067\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0060 - val_loss: 0.0183 - val_mse: 0.0077\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0061 - val_loss: 0.0174 - val_mse: 0.0068\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0061 - val_loss: 0.0175 - val_mse: 0.0069\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0058 - val_loss: 0.0174 - val_mse: 0.0068\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0058 - val_loss: 0.0194 - val_mse: 0.0088\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0057 - val_loss: 0.0173 - val_mse: 0.0067\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0056 - val_loss: 0.0172 - val_mse: 0.0067\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0057 - val_loss: 0.0170 - val_mse: 0.0064\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0054 - val_loss: 0.0173 - val_mse: 0.0068\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0054 - val_loss: 0.0171 - val_mse: 0.0065\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0054 - val_loss: 0.0169 - val_mse: 0.0063\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0055 - val_loss: 0.0169 - val_mse: 0.0064\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0054 - val_loss: 0.0175 - val_mse: 0.0070\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0054 - val_loss: 0.0177 - val_mse: 0.0071\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0053 - val_loss: 0.0168 - val_mse: 0.0062\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0054 - val_loss: 0.0176 - val_mse: 0.0071\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0052 - val_loss: 0.0180 - val_mse: 0.0075\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0054 - val_loss: 0.0173 - val_mse: 0.0068\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0051 - val_loss: 0.0167 - val_mse: 0.0062\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0052 - val_loss: 0.0166 - val_mse: 0.0061\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0052 - val_loss: 0.0170 - val_mse: 0.0065\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0050 - val_loss: 0.0165 - val_mse: 0.0060\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0051 - val_loss: 0.0167 - val_mse: 0.0062\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0051 - val_loss: 0.0168 - val_mse: 0.0063\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0049 - val_loss: 0.0175 - val_mse: 0.0071\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0052 - val_loss: 0.0163 - val_mse: 0.0058\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0049 - val_loss: 0.0175 - val_mse: 0.0071\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0049 - val_loss: 0.0162 - val_mse: 0.0058\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0052 - val_loss: 0.0163 - val_mse: 0.0059\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0050 - val_loss: 0.0164 - val_mse: 0.0059\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0049 - val_loss: 0.0176 - val_mse: 0.0072\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0050 - val_loss: 0.0174 - val_mse: 0.0069\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0047 - val_loss: 0.0168 - val_mse: 0.0064\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0047 - val_loss: 0.0161 - val_mse: 0.0056\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0050 - val_loss: 0.0160 - val_mse: 0.0056\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0046 - val_loss: 0.0161 - val_mse: 0.0057\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0046 - val_loss: 0.0160 - val_mse: 0.0056\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0164 - val_mse: 0.0060\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0046 - val_loss: 0.0168 - val_mse: 0.0064\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0049 - val_loss: 0.0159 - val_mse: 0.0055\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0161 - val_mse: 0.0057\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0159 - val_mse: 0.0056\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0164 - val_mse: 0.0060\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0047 - val_loss: 0.0160 - val_mse: 0.0056\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0046 - val_loss: 0.0157 - val_mse: 0.0053\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0046 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0045 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0045 - val_loss: 0.0155 - val_mse: 0.0052\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0044 - val_loss: 0.0155 - val_mse: 0.0052\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0044 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0045 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0044 - val_loss: 0.0154 - val_mse: 0.0051\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0154 - val_mse: 0.0051\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0158 - val_mse: 0.0055\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0043 - val_loss: 0.0172 - val_mse: 0.0069\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0153 - val_mse: 0.0050\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0153 - val_mse: 0.0050\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0043 - val_loss: 0.0153 - val_mse: 0.0050\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0041 - val_loss: 0.0155 - val_mse: 0.0052\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0043 - val_loss: 0.0152 - val_mse: 0.0049\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0041 - val_loss: 0.0157 - val_mse: 0.0055\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0040 - val_loss: 0.0153 - val_mse: 0.0050\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0041 - val_loss: 0.0150 - val_mse: 0.0047\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0150 - val_mse: 0.0048\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0042 - val_loss: 0.0159 - val_mse: 0.0057\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0041 - val_loss: 0.0149 - val_mse: 0.0047\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0040 - val_loss: 0.0152 - val_mse: 0.0049\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0040 - val_loss: 0.0149 - val_mse: 0.0047\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0041 - val_loss: 0.0149 - val_mse: 0.0046\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0039 - val_loss: 0.0148 - val_mse: 0.0046\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0040 - val_loss: 0.0148 - val_mse: 0.0046\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0039 - val_loss: 0.0148 - val_mse: 0.0045\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0039 - val_loss: 0.0148 - val_mse: 0.0045\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0039 - val_loss: 0.0151 - val_mse: 0.0049\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0039 - val_loss: 0.0157 - val_mse: 0.0054\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0041 - val_loss: 0.0147 - val_mse: 0.0044\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0038 - val_loss: 0.0158 - val_mse: 0.0056\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0040 - val_loss: 0.0166 - val_mse: 0.0064\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0038 - val_loss: 0.0147 - val_mse: 0.0045\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0039 - val_loss: 0.0149 - val_mse: 0.0048\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0038 - val_loss: 0.0148 - val_mse: 0.0046\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0037 - val_loss: 0.0154 - val_mse: 0.0052\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0037 - val_loss: 0.0150 - val_mse: 0.0049\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0038 - val_loss: 0.0147 - val_mse: 0.0046\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0038 - val_loss: 0.0162 - val_mse: 0.0061\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0038 - val_loss: 0.0145 - val_mse: 0.0043\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0162 - val_mse: 0.0061\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0035 - val_loss: 0.0143 - val_mse: 0.0042\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0143 - val_mse: 0.0042\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0037 - val_loss: 0.0142 - val_mse: 0.0041\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0142 - val_mse: 0.0041\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0156 - val_mse: 0.0055\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0036 - val_loss: 0.0148 - val_mse: 0.0047\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0035 - val_loss: 0.0151 - val_mse: 0.0050\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0037 - val_loss: 0.0142 - val_mse: 0.0041\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0143 - val_mse: 0.0042\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0035 - val_loss: 0.0144 - val_mse: 0.0043\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0036 - val_loss: 0.0140 - val_mse: 0.0039\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0034 - val_loss: 0.0141 - val_mse: 0.0040\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0035 - val_loss: 0.0141 - val_mse: 0.0040\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0035 - val_loss: 0.0140 - val_mse: 0.0040\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0034 - val_loss: 0.0141 - val_mse: 0.0040\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0033 - val_loss: 0.0141 - val_mse: 0.0040\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0034 - val_loss: 0.0139 - val_mse: 0.0038\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0035 - val_loss: 0.0140 - val_mse: 0.0040\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0034 - val_loss: 0.0147 - val_mse: 0.0046\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0034 - val_loss: 0.0138 - val_mse: 0.0038\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0034 - val_loss: 0.0138 - val_mse: 0.0037\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0034 - val_loss: 0.0138 - val_mse: 0.0038\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0034 - val_loss: 0.0137 - val_mse: 0.0037\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0035 - val_loss: 0.0137 - val_mse: 0.0037\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0032 - val_loss: 0.0138 - val_mse: 0.0038\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0033 - val_loss: 0.0137 - val_mse: 0.0036\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0033 - val_loss: 0.0138 - val_mse: 0.0038\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0032 - val_loss: 0.0138 - val_mse: 0.0038\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0032 - val_loss: 0.0136 - val_mse: 0.0036\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0032 - val_loss: 0.0136 - val_mse: 0.0036\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0033 - val_loss: 0.0135 - val_mse: 0.0036\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0032 - val_loss: 0.0145 - val_mse: 0.0046\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0032 - val_loss: 0.0145 - val_mse: 0.0045\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0033 - val_loss: 0.0136 - val_mse: 0.0037\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0031 - val_loss: 0.0140 - val_mse: 0.0041\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0140 - val_mse: 0.0041\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0032 - val_loss: 0.0140 - val_mse: 0.0040\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0030 - val_loss: 0.0145 - val_mse: 0.0045\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0134 - val_mse: 0.0034\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0031 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0031 - val_loss: 0.0139 - val_mse: 0.0040\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0032 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0032 - val_loss: 0.0138 - val_mse: 0.0039\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0031 - val_loss: 0.0134 - val_mse: 0.0035\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0132 - val_mse: 0.0033\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0134 - val_mse: 0.0035\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0031 - val_loss: 0.0131 - val_mse: 0.0032\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0031 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0131 - val_mse: 0.0032\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0155 - val_mse: 0.0056\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0140 - val_mse: 0.0042\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0030 - val_loss: 0.0136 - val_mse: 0.0037\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0030 - val_loss: 0.0130 - val_mse: 0.0032\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0133 - val_mse: 0.0034\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0030 - val_loss: 0.0131 - val_mse: 0.0033\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0031 - val_loss: 0.0135 - val_mse: 0.0037\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0134 - val_mse: 0.0036\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0131 - val_mse: 0.0033\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0030 - val_loss: 0.0131 - val_mse: 0.0033\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0028 - val_loss: 0.0129 - val_mse: 0.0032\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0132 - val_mse: 0.0034\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0028 - val_loss: 0.0128 - val_mse: 0.0030\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0028 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0028 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0027 - val_loss: 0.0134 - val_mse: 0.0037\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0028 - val_loss: 0.0128 - val_mse: 0.0031\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0029 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0027 - val_loss: 0.0127 - val_mse: 0.0029\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0029 - val_loss: 0.0129 - val_mse: 0.0031\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0027 - val_loss: 0.0128 - val_mse: 0.0031\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0132 - val_mse: 0.0034\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0029 - val_loss: 0.0130 - val_mse: 0.0033\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0028 - val_loss: 0.0128 - val_mse: 0.0030\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0126 - val_mse: 0.0029\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0028 - val_loss: 0.0127 - val_mse: 0.0030\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0126 - val_mse: 0.0029\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0028 - val_loss: 0.0125 - val_mse: 0.0028\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0028 - val_loss: 0.0125 - val_mse: 0.0029\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0127 - val_mse: 0.0030\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0026 - val_loss: 0.0140 - val_mse: 0.0043\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0125 - val_mse: 0.0028\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0125 - val_mse: 0.0028\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0026 - val_loss: 0.0126 - val_mse: 0.0030\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0027 - val_loss: 0.0128 - val_mse: 0.0032\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0027 - val_loss: 0.0130 - val_mse: 0.0033\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0027 - val_loss: 0.0129 - val_mse: 0.0033\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0027 - val_loss: 0.0130 - val_mse: 0.0034\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0026 - val_loss: 0.0128 - val_mse: 0.0031\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0026 - val_loss: 0.0126 - val_mse: 0.0030\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0026 - val_loss: 0.0123 - val_mse: 0.0027\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0025 - val_loss: 0.0124 - val_mse: 0.0028\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0026 - val_loss: 0.0123 - val_mse: 0.0027\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0026 - val_loss: 0.0123 - val_mse: 0.0027\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0027 - val_loss: 0.0137 - val_mse: 0.0041\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0025 - val_loss: 0.0127 - val_mse: 0.0031\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0026 - val_loss: 0.0123 - val_mse: 0.0027\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0027 - val_loss: 0.0124 - val_mse: 0.0028\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0025 - val_loss: 0.0122 - val_mse: 0.0027\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0026 - val_loss: 0.0122 - val_mse: 0.0026\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0025 - val_loss: 0.0124 - val_mse: 0.0028\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0025 - val_loss: 0.0128 - val_mse: 0.0032\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0026 - val_loss: 0.0125 - val_mse: 0.0029\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0025 - val_loss: 0.0121 - val_mse: 0.0026\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0024 - val_loss: 0.0122 - val_mse: 0.0027\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0027 - val_loss: 0.0125 - val_mse: 0.0030\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0027 - val_loss: 0.0122 - val_mse: 0.0027\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0025 - val_loss: 0.0123 - val_mse: 0.0027\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0121 - val_mse: 0.0026\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0120 - val_mse: 0.0025\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0120 - val_mse: 0.0025\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0120 - val_mse: 0.0025\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0120 - val_mse: 0.0025\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0123 - val_mse: 0.0028\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0025 - val_loss: 0.0123 - val_mse: 0.0029\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0025 - val_loss: 0.0123 - val_mse: 0.0028\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0025 - val_loss: 0.0136 - val_mse: 0.0042\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0024\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0024\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0025\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0121 - val_mse: 0.0027\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0024\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0025\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0118 - val_mse: 0.0024\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0119 - val_mse: 0.0025\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0129 - val_mse: 0.0035\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0024 - val_loss: 0.0117 - val_mse: 0.0023\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0023 - val_loss: 0.0117 - val_mse: 0.0023\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0022 - val_loss: 0.0126 - val_mse: 0.0032\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0023 - val_loss: 0.0117 - val_mse: 0.0023\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0023 - val_loss: 0.0119 - val_mse: 0.0025\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0023 - val_loss: 0.0118 - val_mse: 0.0024\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0024 - val_loss: 0.0117 - val_mse: 0.0023\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0023 - val_loss: 0.0120 - val_mse: 0.0026\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0023 - val_loss: 0.0119 - val_mse: 0.0026\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0024 - val_loss: 0.0135 - val_mse: 0.0041\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0023 - val_loss: 0.0116 - val_mse: 0.0023\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0022 - val_loss: 0.0118 - val_mse: 0.0024\n",
      "Epoch 476: early stopping\n",
      "{'hidden_layer_nodes': [4, 6]}\n",
      "New input layer: input_shape 5 nodes 4\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.6577 - mse: 0.6425 - val_loss: 0.0590 - val_mse: 0.0438\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0398 - val_loss: 0.0568 - val_mse: 0.0415\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0494 - mse: 0.0341 - val_loss: 0.0440 - val_mse: 0.0287\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0267 - val_loss: 0.0450 - val_mse: 0.0297\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0242 - val_loss: 0.0435 - val_mse: 0.0282\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0206 - val_loss: 0.0598 - val_mse: 0.0445\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0200 - val_loss: 0.0350 - val_mse: 0.0198\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0193 - val_loss: 0.0496 - val_mse: 0.0343\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0193 - val_loss: 0.0383 - val_mse: 0.0230\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0177 - val_loss: 0.0371 - val_mse: 0.0218\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0166 - val_loss: 0.0454 - val_mse: 0.0302\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0176 - val_loss: 0.0331 - val_mse: 0.0178\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0164 - val_loss: 0.0414 - val_mse: 0.0262\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0163 - val_loss: 0.0324 - val_mse: 0.0171\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0177 - val_loss: 0.0399 - val_mse: 0.0247\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0153 - val_loss: 0.0328 - val_mse: 0.0176\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0164 - val_loss: 0.0354 - val_mse: 0.0202\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0158 - val_loss: 0.0319 - val_mse: 0.0167\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0169 - val_loss: 0.0392 - val_mse: 0.0240\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0168 - val_loss: 0.0341 - val_mse: 0.0189\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0151 - val_loss: 0.0353 - val_mse: 0.0201\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0161 - val_loss: 0.0367 - val_mse: 0.0215\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0311 - mse: 0.0160 - val_loss: 0.0309 - val_mse: 0.0157\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0153 - val_loss: 0.0392 - val_mse: 0.0240\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0145 - val_loss: 0.0342 - val_mse: 0.0191\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0154 - val_loss: 0.0588 - val_mse: 0.0437\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0157 - val_loss: 0.0324 - val_mse: 0.0173\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0142 - val_loss: 0.0307 - val_mse: 0.0156\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0300 - mse: 0.0149 - val_loss: 0.0302 - val_mse: 0.0151\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0146 - val_loss: 0.0306 - val_mse: 0.0155\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0145 - val_loss: 0.0304 - val_mse: 0.0153\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0301 - mse: 0.0150 - val_loss: 0.0364 - val_mse: 0.0214\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0141 - val_loss: 0.0301 - val_mse: 0.0151\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0154 - val_loss: 0.0307 - val_mse: 0.0157\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0148 - val_loss: 0.0302 - val_mse: 0.0151\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0135 - val_loss: 0.0298 - val_mse: 0.0148\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0137 - val_loss: 0.0391 - val_mse: 0.0241\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0137 - val_loss: 0.0294 - val_mse: 0.0145\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0138 - val_loss: 0.0289 - val_mse: 0.0139\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0129 - val_loss: 0.0363 - val_mse: 0.0213\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0139 - val_loss: 0.0352 - val_mse: 0.0202\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0130 - val_loss: 0.0362 - val_mse: 0.0212\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0126 - val_loss: 0.0307 - val_mse: 0.0157\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 0.0122 - val_loss: 0.0412 - val_mse: 0.0262\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0113 - val_loss: 0.0294 - val_mse: 0.0145\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0115 - val_loss: 0.0273 - val_mse: 0.0124\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0112 - val_loss: 0.0276 - val_mse: 0.0127\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0109 - val_loss: 0.0395 - val_mse: 0.0246\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0105 - val_loss: 0.0325 - val_mse: 0.0176\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0100 - val_loss: 0.0278 - val_mse: 0.0130\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0108 - val_loss: 0.0381 - val_mse: 0.0232\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0107 - val_loss: 0.0268 - val_mse: 0.0120\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0097 - val_loss: 0.0279 - val_mse: 0.0131\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0093 - val_loss: 0.0302 - val_mse: 0.0154\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0098 - val_loss: 0.0275 - val_mse: 0.0127\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0096 - val_loss: 0.0268 - val_mse: 0.0120\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0093 - val_loss: 0.0273 - val_mse: 0.0125\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0096 - val_loss: 0.0266 - val_mse: 0.0118\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0090 - val_loss: 0.0260 - val_mse: 0.0113\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0096 - val_loss: 0.0271 - val_mse: 0.0123\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0098 - val_loss: 0.0273 - val_mse: 0.0125\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0096 - val_loss: 0.0272 - val_mse: 0.0125\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0099 - val_loss: 0.0256 - val_mse: 0.0109\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0086 - val_loss: 0.0261 - val_mse: 0.0113\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0091 - val_loss: 0.0256 - val_mse: 0.0108\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0090 - val_loss: 0.0282 - val_mse: 0.0134\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0092 - val_loss: 0.0275 - val_mse: 0.0128\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0094 - val_loss: 0.0274 - val_mse: 0.0126\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0097 - val_loss: 0.0257 - val_mse: 0.0110\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0090 - val_loss: 0.0259 - val_mse: 0.0112\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0087 - val_loss: 0.0257 - val_mse: 0.0110\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0093 - val_loss: 0.0276 - val_mse: 0.0129\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0085 - val_loss: 0.0263 - val_mse: 0.0116\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0089 - val_loss: 0.0257 - val_mse: 0.0110\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0091 - val_loss: 0.0284 - val_mse: 0.0137\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0093 - val_loss: 0.0312 - val_mse: 0.0166\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0084 - val_loss: 0.0259 - val_mse: 0.0112\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0089 - val_loss: 0.0250 - val_mse: 0.0104\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0084 - val_loss: 0.0320 - val_mse: 0.0174\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0086 - val_loss: 0.0249 - val_mse: 0.0103\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0086 - val_loss: 0.0292 - val_mse: 0.0146\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0088 - val_loss: 0.0260 - val_mse: 0.0114\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0083 - val_loss: 0.0257 - val_mse: 0.0111\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0087 - val_loss: 0.0259 - val_mse: 0.0113\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0083 - val_loss: 0.0282 - val_mse: 0.0136\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0082 - val_loss: 0.0257 - val_mse: 0.0112\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0089 - val_loss: 0.0251 - val_mse: 0.0105\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0087 - val_loss: 0.0255 - val_mse: 0.0109\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0080 - val_loss: 0.0265 - val_mse: 0.0119\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0082 - val_loss: 0.0253 - val_mse: 0.0107\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0082 - val_loss: 0.0251 - val_mse: 0.0106\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0084 - val_loss: 0.0245 - val_mse: 0.0100\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0081 - val_loss: 0.0243 - val_mse: 0.0098\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0082 - val_loss: 0.0243 - val_mse: 0.0098\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0083 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0083 - val_loss: 0.0277 - val_mse: 0.0133\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0082 - val_loss: 0.0247 - val_mse: 0.0102\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0075 - val_loss: 0.0271 - val_mse: 0.0126\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0082 - val_loss: 0.0257 - val_mse: 0.0112\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0079 - val_loss: 0.0263 - val_mse: 0.0118\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0077 - val_loss: 0.0265 - val_mse: 0.0120\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0080 - val_loss: 0.0278 - val_mse: 0.0133\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0077 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0077 - val_loss: 0.0267 - val_mse: 0.0123\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0081 - val_loss: 0.0242 - val_mse: 0.0098\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0080 - val_loss: 0.0244 - val_mse: 0.0100\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0079 - val_loss: 0.0238 - val_mse: 0.0094\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0080 - val_loss: 0.0247 - val_mse: 0.0103\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0078 - val_loss: 0.0246 - val_mse: 0.0102\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0082 - val_loss: 0.0239 - val_mse: 0.0095\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0076 - val_loss: 0.0236 - val_mse: 0.0093\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0078 - val_loss: 0.0258 - val_mse: 0.0115\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0080 - val_loss: 0.0255 - val_mse: 0.0112\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0073 - val_loss: 0.0236 - val_mse: 0.0093\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0075 - val_loss: 0.0244 - val_mse: 0.0101\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0076 - val_loss: 0.0262 - val_mse: 0.0119\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0073 - val_loss: 0.0234 - val_mse: 0.0091\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0074 - val_loss: 0.0234 - val_mse: 0.0091\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0071 - val_loss: 0.0234 - val_mse: 0.0091\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0077 - val_loss: 0.0237 - val_mse: 0.0094\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0076 - val_loss: 0.0240 - val_mse: 0.0097\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0078 - val_loss: 0.0233 - val_mse: 0.0090\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0075 - val_loss: 0.0258 - val_mse: 0.0115\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0081 - val_loss: 0.0233 - val_mse: 0.0091\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0074 - val_loss: 0.0234 - val_mse: 0.0091\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0077 - val_loss: 0.0288 - val_mse: 0.0146\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0074 - val_loss: 0.0248 - val_mse: 0.0106\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0074 - val_loss: 0.0239 - val_mse: 0.0096\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0072 - val_loss: 0.0249 - val_mse: 0.0107\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0072 - val_loss: 0.0231 - val_mse: 0.0089\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0081 - val_loss: 0.0230 - val_mse: 0.0088\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0073 - val_loss: 0.0232 - val_mse: 0.0090\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0071 - val_loss: 0.0234 - val_mse: 0.0093\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0075 - val_loss: 0.0234 - val_mse: 0.0092\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0072 - val_loss: 0.0230 - val_mse: 0.0088\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0081 - val_loss: 0.0254 - val_mse: 0.0112\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0071 - val_loss: 0.0226 - val_mse: 0.0085\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0072 - val_loss: 0.0228 - val_mse: 0.0086\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0068 - val_loss: 0.0303 - val_mse: 0.0162\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0068 - val_loss: 0.0244 - val_mse: 0.0103\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0070 - val_loss: 0.0238 - val_mse: 0.0097\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0069 - val_loss: 0.0242 - val_mse: 0.0101\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0066 - val_loss: 0.0273 - val_mse: 0.0132\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0072 - val_loss: 0.0229 - val_mse: 0.0088\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0064 - val_loss: 0.0227 - val_mse: 0.0087\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0073 - val_loss: 0.0273 - val_mse: 0.0132\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0072 - val_loss: 0.0237 - val_mse: 0.0097\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0070 - val_loss: 0.0228 - val_mse: 0.0087\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0073 - val_loss: 0.0225 - val_mse: 0.0085\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0069 - val_loss: 0.0233 - val_mse: 0.0093\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0067 - val_loss: 0.0224 - val_mse: 0.0083\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0070 - val_loss: 0.0223 - val_mse: 0.0083\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0068 - val_loss: 0.0221 - val_mse: 0.0081\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0065 - val_loss: 0.0222 - val_mse: 0.0082\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0065 - val_loss: 0.0224 - val_mse: 0.0084\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0067 - val_loss: 0.0239 - val_mse: 0.0099\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0066 - val_loss: 0.0225 - val_mse: 0.0085\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0068 - val_loss: 0.0232 - val_mse: 0.0092\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0068 - val_loss: 0.0223 - val_mse: 0.0083\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0063 - val_loss: 0.0251 - val_mse: 0.0111\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0070 - val_loss: 0.0220 - val_mse: 0.0081\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0061 - val_loss: 0.0224 - val_mse: 0.0085\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0072 - val_loss: 0.0244 - val_mse: 0.0105\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0065 - val_loss: 0.0231 - val_mse: 0.0092\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0068 - val_loss: 0.0218 - val_mse: 0.0079\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0067 - val_loss: 0.0218 - val_mse: 0.0079\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0069 - val_loss: 0.0217 - val_mse: 0.0078\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0068 - val_loss: 0.0265 - val_mse: 0.0126\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0060 - val_loss: 0.0218 - val_mse: 0.0079\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0068 - val_loss: 0.0240 - val_mse: 0.0102\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0067 - val_loss: 0.0216 - val_mse: 0.0077\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0065 - val_loss: 0.0224 - val_mse: 0.0085\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0071 - val_loss: 0.0252 - val_mse: 0.0113\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0067 - val_loss: 0.0281 - val_mse: 0.0143\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0063 - val_loss: 0.0277 - val_mse: 0.0139\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0067 - val_loss: 0.0234 - val_mse: 0.0096\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0062 - val_loss: 0.0214 - val_mse: 0.0077\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0064 - val_loss: 0.0224 - val_mse: 0.0087\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0065 - val_loss: 0.0251 - val_mse: 0.0113\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0062 - val_loss: 0.0261 - val_mse: 0.0123\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0235 - val_mse: 0.0097\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0061 - val_loss: 0.0250 - val_mse: 0.0113\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0062 - val_loss: 0.0212 - val_mse: 0.0075\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0062 - val_loss: 0.0230 - val_mse: 0.0092\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0069 - val_loss: 0.0250 - val_mse: 0.0112\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0214 - val_mse: 0.0077\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0066 - val_loss: 0.0216 - val_mse: 0.0079\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0064 - val_loss: 0.0213 - val_mse: 0.0077\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0211 - val_mse: 0.0074\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0063 - val_loss: 0.0211 - val_mse: 0.0075\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0061 - val_loss: 0.0232 - val_mse: 0.0095\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0061 - val_loss: 0.0223 - val_mse: 0.0087\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0066 - val_loss: 0.0212 - val_mse: 0.0075\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0209 - val_mse: 0.0073\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0061 - val_loss: 0.0209 - val_mse: 0.0073\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0065 - val_loss: 0.0209 - val_mse: 0.0073\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0063 - val_loss: 0.0223 - val_mse: 0.0087\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0211 - val_mse: 0.0075\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0059 - val_loss: 0.0227 - val_mse: 0.0091\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0058 - val_loss: 0.0210 - val_mse: 0.0075\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0058 - val_loss: 0.0208 - val_mse: 0.0072\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0059 - val_loss: 0.0219 - val_mse: 0.0083\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0063 - val_loss: 0.0211 - val_mse: 0.0075\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0256 - val_mse: 0.0121\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0062 - val_loss: 0.0212 - val_mse: 0.0077\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0059 - val_loss: 0.0207 - val_mse: 0.0072\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0055 - val_loss: 0.0232 - val_mse: 0.0097\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0059 - val_loss: 0.0207 - val_mse: 0.0072\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0061 - val_loss: 0.0207 - val_mse: 0.0073\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0059 - val_loss: 0.0207 - val_mse: 0.0073\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0207 - val_mse: 0.0073\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0249 - val_mse: 0.0115\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0059 - val_loss: 0.0212 - val_mse: 0.0078\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0064 - val_loss: 0.0233 - val_mse: 0.0099\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0206 - val_mse: 0.0071\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0207 - val_mse: 0.0073\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0218 - val_mse: 0.0084\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0217 - val_mse: 0.0083\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0061 - val_loss: 0.0201 - val_mse: 0.0068\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0058 - val_loss: 0.0207 - val_mse: 0.0074\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0057 - val_loss: 0.0209 - val_mse: 0.0076\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0056 - val_loss: 0.0201 - val_mse: 0.0067\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0060 - val_loss: 0.0217 - val_mse: 0.0084\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0058 - val_loss: 0.0201 - val_mse: 0.0068\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0056 - val_loss: 0.0213 - val_mse: 0.0079\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0057 - val_loss: 0.0211 - val_mse: 0.0078\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0061 - val_loss: 0.0212 - val_mse: 0.0079\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0058 - val_loss: 0.0202 - val_mse: 0.0069\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0061 - val_loss: 0.0220 - val_mse: 0.0087\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0055 - val_loss: 0.0201 - val_mse: 0.0069\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0055 - val_loss: 0.0198 - val_mse: 0.0066\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0056 - val_loss: 0.0211 - val_mse: 0.0078\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0053 - val_loss: 0.0211 - val_mse: 0.0079\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0053 - val_loss: 0.0240 - val_mse: 0.0108\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0055 - val_loss: 0.0198 - val_mse: 0.0065\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0056 - val_loss: 0.0242 - val_mse: 0.0110\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0053 - val_loss: 0.0200 - val_mse: 0.0068\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0056 - val_loss: 0.0205 - val_mse: 0.0073\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0056 - val_loss: 0.0202 - val_mse: 0.0070\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0055 - val_loss: 0.0236 - val_mse: 0.0104\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0058 - val_loss: 0.0223 - val_mse: 0.0091\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0055 - val_loss: 0.0196 - val_mse: 0.0064\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0060 - val_loss: 0.0235 - val_mse: 0.0104\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0055 - val_loss: 0.0196 - val_mse: 0.0064\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0052 - val_loss: 0.0196 - val_mse: 0.0065\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0051 - val_loss: 0.0194 - val_mse: 0.0063\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0056 - val_loss: 0.0194 - val_mse: 0.0063\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0055 - val_loss: 0.0208 - val_mse: 0.0077\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0057 - val_loss: 0.0213 - val_mse: 0.0082\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0051 - val_loss: 0.0197 - val_mse: 0.0066\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0054 - val_loss: 0.0194 - val_mse: 0.0063\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0059 - val_loss: 0.0225 - val_mse: 0.0095\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0053 - val_loss: 0.0194 - val_mse: 0.0064\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0054 - val_loss: 0.0192 - val_mse: 0.0061\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0053 - val_loss: 0.0192 - val_mse: 0.0061\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0053 - val_loss: 0.0195 - val_mse: 0.0065\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0053 - val_loss: 0.0193 - val_mse: 0.0063\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0055 - val_loss: 0.0191 - val_mse: 0.0061\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0053 - val_loss: 0.0205 - val_mse: 0.0076\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0053 - val_loss: 0.0193 - val_mse: 0.0064\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0050 - val_loss: 0.0190 - val_mse: 0.0060\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0051 - val_loss: 0.0193 - val_mse: 0.0063\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0056 - val_loss: 0.0206 - val_mse: 0.0076\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0053 - val_loss: 0.0190 - val_mse: 0.0061\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0053 - val_loss: 0.0189 - val_mse: 0.0060\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0052 - val_loss: 0.0213 - val_mse: 0.0084\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0049 - val_loss: 0.0202 - val_mse: 0.0073\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0051 - val_loss: 0.0194 - val_mse: 0.0065\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0049 - val_loss: 0.0194 - val_mse: 0.0065\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0052 - val_loss: 0.0203 - val_mse: 0.0074\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0052 - val_loss: 0.0186 - val_mse: 0.0057\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0047 - val_loss: 0.0190 - val_mse: 0.0061\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0051 - val_loss: 0.0240 - val_mse: 0.0111\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0054 - val_loss: 0.0203 - val_mse: 0.0074\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0047 - val_loss: 0.0192 - val_mse: 0.0064\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0050 - val_loss: 0.0189 - val_mse: 0.0061\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0051 - val_loss: 0.0197 - val_mse: 0.0069\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0050 - val_loss: 0.0200 - val_mse: 0.0072\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0049 - val_loss: 0.0196 - val_mse: 0.0068\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0051 - val_loss: 0.0185 - val_mse: 0.0057\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0049 - val_loss: 0.0184 - val_mse: 0.0056\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0052 - val_loss: 0.0188 - val_mse: 0.0060\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0049 - val_loss: 0.0188 - val_mse: 0.0061\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0050 - val_loss: 0.0197 - val_mse: 0.0070\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0051 - val_loss: 0.0185 - val_mse: 0.0058\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0049 - val_loss: 0.0182 - val_mse: 0.0055\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0046 - val_loss: 0.0193 - val_mse: 0.0065\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0048 - val_loss: 0.0184 - val_mse: 0.0057\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0047 - val_loss: 0.0182 - val_mse: 0.0055\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0050 - val_loss: 0.0182 - val_mse: 0.0055\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0051 - val_loss: 0.0191 - val_mse: 0.0064\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0048 - val_loss: 0.0191 - val_mse: 0.0065\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0044 - val_loss: 0.0185 - val_mse: 0.0058\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0048 - val_loss: 0.0185 - val_mse: 0.0058\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0050 - val_loss: 0.0181 - val_mse: 0.0054\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0048 - val_loss: 0.0180 - val_mse: 0.0054\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0047 - val_loss: 0.0179 - val_mse: 0.0053\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0048 - val_loss: 0.0179 - val_mse: 0.0053\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0045 - val_loss: 0.0187 - val_mse: 0.0061\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0051 - val_loss: 0.0178 - val_mse: 0.0052\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0050 - val_loss: 0.0219 - val_mse: 0.0093\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0048 - val_loss: 0.0185 - val_mse: 0.0059\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0046 - val_loss: 0.0195 - val_mse: 0.0069\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0046 - val_loss: 0.0182 - val_mse: 0.0056\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0047 - val_loss: 0.0188 - val_mse: 0.0063\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0047 - val_loss: 0.0182 - val_mse: 0.0056\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0045 - val_loss: 0.0183 - val_mse: 0.0057\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0043 - val_loss: 0.0213 - val_mse: 0.0088\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0048 - val_loss: 0.0177 - val_mse: 0.0052\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0047 - val_loss: 0.0192 - val_mse: 0.0067\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0048 - val_loss: 0.0185 - val_mse: 0.0060\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0046 - val_loss: 0.0176 - val_mse: 0.0051\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0047 - val_loss: 0.0176 - val_mse: 0.0051\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0042 - val_loss: 0.0175 - val_mse: 0.0050\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0048 - val_loss: 0.0199 - val_mse: 0.0074\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0045 - val_loss: 0.0183 - val_mse: 0.0058\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0044 - val_loss: 0.0183 - val_mse: 0.0059\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0044 - val_loss: 0.0190 - val_mse: 0.0065\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0047 - val_loss: 0.0173 - val_mse: 0.0048\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0045 - val_loss: 0.0179 - val_mse: 0.0054\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0043 - val_loss: 0.0173 - val_mse: 0.0048\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0046 - val_loss: 0.0177 - val_mse: 0.0053\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0043 - val_loss: 0.0176 - val_mse: 0.0051\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0047 - val_loss: 0.0217 - val_mse: 0.0093\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0042 - val_loss: 0.0172 - val_mse: 0.0048\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0042 - val_loss: 0.0182 - val_mse: 0.0058\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0043 - val_loss: 0.0172 - val_mse: 0.0048\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0044 - val_loss: 0.0171 - val_mse: 0.0047\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0042 - val_loss: 0.0174 - val_mse: 0.0050\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0045 - val_loss: 0.0171 - val_mse: 0.0047\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0042 - val_loss: 0.0179 - val_mse: 0.0056\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0044 - val_loss: 0.0209 - val_mse: 0.0085\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0043 - val_loss: 0.0235 - val_mse: 0.0112\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0041 - val_loss: 0.0193 - val_mse: 0.0070\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0046 - val_loss: 0.0191 - val_mse: 0.0068\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0042 - val_loss: 0.0170 - val_mse: 0.0047\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0043 - val_loss: 0.0172 - val_mse: 0.0049\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0043 - val_loss: 0.0171 - val_mse: 0.0048\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0042 - val_loss: 0.0175 - val_mse: 0.0052\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0041 - val_loss: 0.0204 - val_mse: 0.0082\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0045 - val_loss: 0.0171 - val_mse: 0.0049\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0045 - val_loss: 0.0170 - val_mse: 0.0048\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0041 - val_loss: 0.0169 - val_mse: 0.0046\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0043 - val_loss: 0.0167 - val_mse: 0.0044\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0169 - val_mse: 0.0046\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0041 - val_loss: 0.0171 - val_mse: 0.0049\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0042 - val_loss: 0.0175 - val_mse: 0.0053\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0040 - val_loss: 0.0172 - val_mse: 0.0049\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0173 - val_mse: 0.0051\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0186 - val_mse: 0.0064\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0040 - val_loss: 0.0165 - val_mse: 0.0043\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0192 - val_mse: 0.0070\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0040 - val_loss: 0.0172 - val_mse: 0.0050\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0165 - val_mse: 0.0044\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0042 - val_loss: 0.0170 - val_mse: 0.0049\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0038 - val_loss: 0.0167 - val_mse: 0.0045\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0038 - val_loss: 0.0172 - val_mse: 0.0050\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0041 - val_loss: 0.0166 - val_mse: 0.0045\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0043 - val_loss: 0.0166 - val_mse: 0.0044\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0038 - val_loss: 0.0167 - val_mse: 0.0046\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0039 - val_loss: 0.0166 - val_mse: 0.0045\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0037 - val_loss: 0.0220 - val_mse: 0.0099\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0038 - val_loss: 0.0164 - val_mse: 0.0043\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0040 - val_loss: 0.0167 - val_mse: 0.0046\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0037 - val_loss: 0.0175 - val_mse: 0.0054\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0038 - val_loss: 0.0166 - val_mse: 0.0045\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0040 - val_loss: 0.0166 - val_mse: 0.0045\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0036 - val_loss: 0.0171 - val_mse: 0.0051\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0041 - val_loss: 0.0165 - val_mse: 0.0045\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0036 - val_loss: 0.0172 - val_mse: 0.0051\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0041 - val_loss: 0.0163 - val_mse: 0.0043\n",
      "Epoch 371: early stopping\n",
      "{'hidden_layer_nodes': [5, 2]}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 2\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.5250 - mse: 0.5139 - val_loss: 0.0659 - val_mse: 0.0548\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1015 - mse: 0.0904 - val_loss: 0.0854 - val_mse: 0.0743\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1006 - mse: 0.0896 - val_loss: 0.0662 - val_mse: 0.0551\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1003 - mse: 0.0893 - val_loss: 0.0633 - val_mse: 0.0522\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.0890 - val_loss: 0.0636 - val_mse: 0.0526\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0993 - mse: 0.0882 - val_loss: 0.0678 - val_mse: 0.0567\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0884 - val_loss: 0.0648 - val_mse: 0.0538\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0885 - val_loss: 0.0637 - val_mse: 0.0527\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1000 - mse: 0.0889 - val_loss: 0.0632 - val_mse: 0.0521\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0989 - mse: 0.0879 - val_loss: 0.0632 - val_mse: 0.0522\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0884 - val_loss: 0.0682 - val_mse: 0.0572\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0989 - mse: 0.0879 - val_loss: 0.0637 - val_mse: 0.0527\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0884 - val_loss: 0.0676 - val_mse: 0.0566\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1007 - mse: 0.0897 - val_loss: 0.0646 - val_mse: 0.0536\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0990 - mse: 0.0880 - val_loss: 0.0654 - val_mse: 0.0544\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0991 - mse: 0.0881 - val_loss: 0.0635 - val_mse: 0.0525\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0884 - val_loss: 0.0682 - val_mse: 0.0572\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1009 - mse: 0.0900 - val_loss: 0.0647 - val_mse: 0.0537\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0991 - mse: 0.0882 - val_loss: 0.0644 - val_mse: 0.0534\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0872 - val_loss: 0.0700 - val_mse: 0.0590\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0872 - val_loss: 0.0691 - val_mse: 0.0582\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0986 - mse: 0.0877 - val_loss: 0.0654 - val_mse: 0.0544\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0994 - mse: 0.0885 - val_loss: 0.0666 - val_mse: 0.0557\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0988 - mse: 0.0878 - val_loss: 0.0631 - val_mse: 0.0521\n",
      "Epoch 24: early stopping\n",
      "{'hidden_layer_nodes': [5, 4]}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.3142 - mse: 0.2997 - val_loss: 0.0594 - val_mse: 0.0449\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0528 - val_loss: 0.0388 - val_mse: 0.0242\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0293 - val_loss: 0.0344 - val_mse: 0.0199\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0224 - val_loss: 0.0335 - val_mse: 0.0190\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0197 - val_loss: 0.0352 - val_mse: 0.0207\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0331 - mse: 0.0187 - val_loss: 0.0327 - val_mse: 0.0183\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0321 - mse: 0.0177 - val_loss: 0.0323 - val_mse: 0.0179\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0173 - val_loss: 0.0319 - val_mse: 0.0175\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0172 - val_loss: 0.0308 - val_mse: 0.0164\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0167 - val_loss: 0.0306 - val_mse: 0.0163\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0163 - val_loss: 0.0303 - val_mse: 0.0160\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0160 - val_loss: 0.0310 - val_mse: 0.0167\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0168 - val_loss: 0.0298 - val_mse: 0.0155\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0156 - val_loss: 0.0299 - val_mse: 0.0156\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0150 - val_loss: 0.0319 - val_mse: 0.0176\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0148 - val_loss: 0.0299 - val_mse: 0.0157\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0148 - val_loss: 0.0299 - val_mse: 0.0157\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0146 - val_loss: 0.0297 - val_mse: 0.0155\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0141 - val_loss: 0.0292 - val_mse: 0.0149\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0144 - val_loss: 0.0285 - val_mse: 0.0142\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0140 - val_loss: 0.0279 - val_mse: 0.0137\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0142 - val_loss: 0.0278 - val_mse: 0.0136\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0139 - val_loss: 0.0295 - val_mse: 0.0153\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0133 - val_loss: 0.0292 - val_mse: 0.0151\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0128 - val_loss: 0.0274 - val_mse: 0.0133\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0129 - val_loss: 0.0271 - val_mse: 0.0130\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0126 - val_loss: 0.0268 - val_mse: 0.0127\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0132 - val_loss: 0.0271 - val_mse: 0.0130\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0125 - val_loss: 0.0274 - val_mse: 0.0133\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0124 - val_loss: 0.0278 - val_mse: 0.0138\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0122 - val_loss: 0.0275 - val_mse: 0.0135\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0120 - val_loss: 0.0263 - val_mse: 0.0123\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0116 - val_loss: 0.0270 - val_mse: 0.0129\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0122 - val_loss: 0.0259 - val_mse: 0.0119\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0115 - val_loss: 0.0256 - val_mse: 0.0116\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0121 - val_loss: 0.0258 - val_mse: 0.0118\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0115 - val_loss: 0.0254 - val_mse: 0.0113\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0118 - val_loss: 0.0266 - val_mse: 0.0126\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0112 - val_loss: 0.0250 - val_mse: 0.0110\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0107 - val_loss: 0.0257 - val_mse: 0.0117\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0110 - val_loss: 0.0253 - val_mse: 0.0113\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0110 - val_loss: 0.0293 - val_mse: 0.0153\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0107 - val_loss: 0.0271 - val_mse: 0.0131\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0106 - val_loss: 0.0284 - val_mse: 0.0144\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0106 - val_loss: 0.0274 - val_mse: 0.0134\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0243 - mse: 0.0104 - val_loss: 0.0247 - val_mse: 0.0107\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0100 - val_loss: 0.0244 - val_mse: 0.0104\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0243 - mse: 0.0103 - val_loss: 0.0245 - val_mse: 0.0105\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0099 - val_loss: 0.0255 - val_mse: 0.0115\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0101 - val_loss: 0.0240 - val_mse: 0.0101\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0102 - val_loss: 0.0241 - val_mse: 0.0101\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0100 - val_loss: 0.0273 - val_mse: 0.0134\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0098 - val_loss: 0.0244 - val_mse: 0.0105\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0098 - val_loss: 0.0235 - val_mse: 0.0096\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0097 - val_loss: 0.0238 - val_mse: 0.0099\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0101 - val_loss: 0.0250 - val_mse: 0.0111\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0094 - val_loss: 0.0242 - val_mse: 0.0103\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0096 - val_loss: 0.0233 - val_mse: 0.0094\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0092 - val_loss: 0.0233 - val_mse: 0.0094\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0232 - mse: 0.0093 - val_loss: 0.0230 - val_mse: 0.0091\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0095 - val_loss: 0.0231 - val_mse: 0.0092\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0092 - val_loss: 0.0236 - val_mse: 0.0097\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0088 - val_loss: 0.0231 - val_mse: 0.0093\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0087 - val_loss: 0.0226 - val_mse: 0.0087\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0092 - val_loss: 0.0226 - val_mse: 0.0087\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0087 - val_loss: 0.0225 - val_mse: 0.0087\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0088 - val_loss: 0.0226 - val_mse: 0.0088\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0085 - val_loss: 0.0223 - val_mse: 0.0084\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0085 - val_loss: 0.0227 - val_mse: 0.0089\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0082 - val_loss: 0.0219 - val_mse: 0.0081\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0085 - val_loss: 0.0224 - val_mse: 0.0086\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0084 - val_loss: 0.0269 - val_mse: 0.0131\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0081 - val_loss: 0.0217 - val_mse: 0.0079\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0082 - val_loss: 0.0216 - val_mse: 0.0078\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0079 - val_loss: 0.0214 - val_mse: 0.0076\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0077 - val_loss: 0.0250 - val_mse: 0.0112\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0080 - val_loss: 0.0214 - val_mse: 0.0076\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0075 - val_loss: 0.0215 - val_mse: 0.0078\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0072 - val_loss: 0.0210 - val_mse: 0.0073\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0076 - val_loss: 0.0213 - val_mse: 0.0075\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0078 - val_loss: 0.0212 - val_mse: 0.0074\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0213 - mse: 0.0076 - val_loss: 0.0222 - val_mse: 0.0084\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0073 - val_loss: 0.0208 - val_mse: 0.0070\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0075 - val_loss: 0.0208 - val_mse: 0.0071\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0071 - val_loss: 0.0210 - val_mse: 0.0073\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0073 - val_loss: 0.0207 - val_mse: 0.0069\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0069 - val_loss: 0.0212 - val_mse: 0.0075\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0071 - val_loss: 0.0227 - val_mse: 0.0090\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0069 - val_loss: 0.0207 - val_mse: 0.0070\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0068 - val_loss: 0.0200 - val_mse: 0.0063\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0068 - val_loss: 0.0203 - val_mse: 0.0067\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0066 - val_loss: 0.0199 - val_mse: 0.0062\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0064 - val_loss: 0.0200 - val_mse: 0.0063\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0065 - val_loss: 0.0206 - val_mse: 0.0070\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0063 - val_loss: 0.0196 - val_mse: 0.0059\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0060 - val_loss: 0.0212 - val_mse: 0.0076\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0062 - val_loss: 0.0198 - val_mse: 0.0062\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0235 - val_mse: 0.0099\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0201 - val_mse: 0.0065\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0193 - val_mse: 0.0057\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0063 - val_loss: 0.0195 - val_mse: 0.0059\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0065 - val_loss: 0.0205 - val_mse: 0.0069\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0205 - val_mse: 0.0069\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0200 - val_mse: 0.0065\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0189 - val_mse: 0.0054\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0056 - val_loss: 0.0200 - val_mse: 0.0064\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0058 - val_loss: 0.0207 - val_mse: 0.0072\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0191 - val_mse: 0.0055\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0058 - val_loss: 0.0187 - val_mse: 0.0051\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0230 - val_mse: 0.0095\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0195 - val_mse: 0.0060\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0055 - val_loss: 0.0184 - val_mse: 0.0049\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0055 - val_loss: 0.0186 - val_mse: 0.0051\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0055 - val_loss: 0.0198 - val_mse: 0.0063\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0054 - val_loss: 0.0199 - val_mse: 0.0064\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0056 - val_loss: 0.0182 - val_mse: 0.0047\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0052 - val_loss: 0.0182 - val_mse: 0.0048\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0049 - val_loss: 0.0183 - val_mse: 0.0049\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0198 - val_mse: 0.0063\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0052 - val_loss: 0.0195 - val_mse: 0.0061\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0055 - val_loss: 0.0185 - val_mse: 0.0051\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0053 - val_loss: 0.0180 - val_mse: 0.0046\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0178 - val_mse: 0.0044\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0178 - val_mse: 0.0044\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0050 - val_loss: 0.0182 - val_mse: 0.0048\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0052 - val_loss: 0.0189 - val_mse: 0.0055\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0049 - val_loss: 0.0177 - val_mse: 0.0043\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0052 - val_loss: 0.0177 - val_mse: 0.0044\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0181 - val_mse: 0.0048\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0050 - val_loss: 0.0175 - val_mse: 0.0042\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0049 - val_loss: 0.0178 - val_mse: 0.0045\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0051 - val_loss: 0.0177 - val_mse: 0.0044\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0051 - val_loss: 0.0176 - val_mse: 0.0043\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0049 - val_loss: 0.0174 - val_mse: 0.0041\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0049 - val_loss: 0.0174 - val_mse: 0.0041\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0051 - val_loss: 0.0173 - val_mse: 0.0041\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0050 - val_loss: 0.0174 - val_mse: 0.0042\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0049 - val_loss: 0.0192 - val_mse: 0.0059\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0051 - val_loss: 0.0191 - val_mse: 0.0059\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0049 - val_loss: 0.0172 - val_mse: 0.0040\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0046 - val_loss: 0.0174 - val_mse: 0.0042\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0049 - val_loss: 0.0199 - val_mse: 0.0067\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0050 - val_loss: 0.0171 - val_mse: 0.0039\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0046 - val_loss: 0.0183 - val_mse: 0.0051\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0051 - val_loss: 0.0175 - val_mse: 0.0043\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0045 - val_loss: 0.0175 - val_mse: 0.0043\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0048 - val_loss: 0.0177 - val_mse: 0.0045\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0049 - val_loss: 0.0177 - val_mse: 0.0045\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0047 - val_loss: 0.0172 - val_mse: 0.0041\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0046 - val_loss: 0.0172 - val_mse: 0.0041\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0047 - val_loss: 0.0174 - val_mse: 0.0042\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0044 - val_loss: 0.0168 - val_mse: 0.0037\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0045 - val_loss: 0.0170 - val_mse: 0.0039\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0047 - val_loss: 0.0169 - val_mse: 0.0038\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0046 - val_loss: 0.0168 - val_mse: 0.0037\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0045 - val_loss: 0.0167 - val_mse: 0.0036\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0045 - val_loss: 0.0175 - val_mse: 0.0044\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0046 - val_loss: 0.0183 - val_mse: 0.0052\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0171 - val_mse: 0.0041\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0043 - val_loss: 0.0175 - val_mse: 0.0044\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0047 - val_loss: 0.0183 - val_mse: 0.0052\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0172 - val_mse: 0.0042\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0045 - val_loss: 0.0188 - val_mse: 0.0057\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0043 - val_loss: 0.0166 - val_mse: 0.0036\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0043 - val_loss: 0.0183 - val_mse: 0.0053\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0169 - val_mse: 0.0039\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0046 - val_loss: 0.0196 - val_mse: 0.0066\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0042 - val_loss: 0.0171 - val_mse: 0.0041\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0043 - val_loss: 0.0168 - val_mse: 0.0038\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0042 - val_loss: 0.0185 - val_mse: 0.0055\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0044 - val_loss: 0.0181 - val_mse: 0.0052\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0045 - val_loss: 0.0165 - val_mse: 0.0035\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0045 - val_loss: 0.0167 - val_mse: 0.0038\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0042 - val_loss: 0.0164 - val_mse: 0.0034\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0043 - val_loss: 0.0164 - val_mse: 0.0034\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0041 - val_loss: 0.0175 - val_mse: 0.0046\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0043 - val_loss: 0.0200 - val_mse: 0.0071\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0045 - val_loss: 0.0163 - val_mse: 0.0034\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0043 - val_loss: 0.0163 - val_mse: 0.0034\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0041 - val_loss: 0.0166 - val_mse: 0.0037\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0041 - val_loss: 0.0165 - val_mse: 0.0037\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0041 - val_loss: 0.0163 - val_mse: 0.0034\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0165 - val_mse: 0.0037\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0040 - val_loss: 0.0169 - val_mse: 0.0041\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0040 - val_loss: 0.0163 - val_mse: 0.0035\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0043 - val_loss: 0.0162 - val_mse: 0.0033\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0042 - val_loss: 0.0162 - val_mse: 0.0033\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0043 - val_loss: 0.0161 - val_mse: 0.0033\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0169 - val_mse: 0.0040\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0163 - val_mse: 0.0035\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0161 - val_mse: 0.0033\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0044 - val_loss: 0.0163 - val_mse: 0.0035\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0040 - val_loss: 0.0161 - val_mse: 0.0033\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0161 - val_mse: 0.0033\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0043 - val_loss: 0.0175 - val_mse: 0.0047\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0040 - val_loss: 0.0165 - val_mse: 0.0038\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0042 - val_loss: 0.0165 - val_mse: 0.0037\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0041 - val_loss: 0.0160 - val_mse: 0.0032\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0040 - val_loss: 0.0178 - val_mse: 0.0050\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0042 - val_loss: 0.0169 - val_mse: 0.0042\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0043 - val_loss: 0.0169 - val_mse: 0.0042\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0040 - val_loss: 0.0159 - val_mse: 0.0032\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0039 - val_loss: 0.0159 - val_mse: 0.0032\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0040 - val_loss: 0.0163 - val_mse: 0.0036\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0039 - val_loss: 0.0195 - val_mse: 0.0068\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0038 - val_loss: 0.0158 - val_mse: 0.0031\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0041 - val_loss: 0.0159 - val_mse: 0.0032\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0039 - val_loss: 0.0171 - val_mse: 0.0045\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0038 - val_loss: 0.0157 - val_mse: 0.0031\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0039 - val_loss: 0.0161 - val_mse: 0.0034\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0039 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0037 - val_loss: 0.0157 - val_mse: 0.0031\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0041 - val_loss: 0.0157 - val_mse: 0.0031\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0038 - val_loss: 0.0172 - val_mse: 0.0046\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0040 - val_loss: 0.0167 - val_mse: 0.0041\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0038 - val_loss: 0.0162 - val_mse: 0.0036\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0039 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0039 - val_loss: 0.0162 - val_mse: 0.0037\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0038 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0035 - val_loss: 0.0161 - val_mse: 0.0035\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0039 - val_loss: 0.0160 - val_mse: 0.0035\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0039 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0038 - val_loss: 0.0163 - val_mse: 0.0038\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0038 - val_loss: 0.0163 - val_mse: 0.0038\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0036 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0037 - val_loss: 0.0157 - val_mse: 0.0032\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0037 - val_loss: 0.0155 - val_mse: 0.0031\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0037 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0035 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0037 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0039 - val_loss: 0.0161 - val_mse: 0.0037\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0036 - val_loss: 0.0168 - val_mse: 0.0043\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0036 - val_loss: 0.0157 - val_mse: 0.0032\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0041 - val_loss: 0.0160 - val_mse: 0.0036\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0038 - val_loss: 0.0155 - val_mse: 0.0031\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0036 - val_loss: 0.0155 - val_mse: 0.0031\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0038 - val_loss: 0.0155 - val_mse: 0.0031\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0035 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0035 - val_loss: 0.0172 - val_mse: 0.0048\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0037 - val_loss: 0.0157 - val_mse: 0.0033\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0038 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0037 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0036 - val_loss: 0.0173 - val_mse: 0.0049\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0035 - val_loss: 0.0166 - val_mse: 0.0042\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0037 - val_loss: 0.0156 - val_mse: 0.0032\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0034 - val_loss: 0.0161 - val_mse: 0.0038\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0036 - val_loss: 0.0152 - val_mse: 0.0028\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0034 - val_loss: 0.0153 - val_mse: 0.0030\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0037 - val_loss: 0.0154 - val_mse: 0.0031\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0034 - val_loss: 0.0162 - val_mse: 0.0039\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0036 - val_loss: 0.0161 - val_mse: 0.0038\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0035 - val_loss: 0.0175 - val_mse: 0.0052\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0034 - val_loss: 0.0154 - val_mse: 0.0031\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0036 - val_loss: 0.0156 - val_mse: 0.0033\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0037 - val_loss: 0.0157 - val_mse: 0.0034\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0032 - val_loss: 0.0150 - val_mse: 0.0028\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0036 - val_loss: 0.0157 - val_mse: 0.0034\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0034 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0035 - val_loss: 0.0150 - val_mse: 0.0028\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0033 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0034 - val_loss: 0.0175 - val_mse: 0.0052\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0035 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0034 - val_loss: 0.0181 - val_mse: 0.0059\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0037 - val_loss: 0.0169 - val_mse: 0.0047\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0036 - val_loss: 0.0150 - val_mse: 0.0028\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0034 - val_loss: 0.0155 - val_mse: 0.0033\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0035 - val_loss: 0.0149 - val_mse: 0.0027\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0034 - val_loss: 0.0150 - val_mse: 0.0028\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0032 - val_loss: 0.0150 - val_mse: 0.0028\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0032 - val_loss: 0.0151 - val_mse: 0.0029\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0034 - val_loss: 0.0149 - val_mse: 0.0027\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0034 - val_loss: 0.0156 - val_mse: 0.0034\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0036 - val_loss: 0.0153 - val_mse: 0.0032\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0034 - val_loss: 0.0165 - val_mse: 0.0043\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0035 - val_loss: 0.0149 - val_mse: 0.0028\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0032 - val_loss: 0.0149 - val_mse: 0.0027\n",
      "Epoch 276: early stopping\n",
      "{'hidden_layer_nodes': [5, 6]}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1249 - mse: 0.1093 - val_loss: 0.0803 - val_mse: 0.0646\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.0923 - val_loss: 0.0710 - val_mse: 0.0554\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0917 - val_loss: 0.0709 - val_mse: 0.0552\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1049 - mse: 0.0892 - val_loss: 0.0820 - val_mse: 0.0663\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1068 - mse: 0.0911 - val_loss: 0.0719 - val_mse: 0.0562\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1045 - mse: 0.0889 - val_loss: 0.0745 - val_mse: 0.0589\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1083 - mse: 0.0927 - val_loss: 0.0788 - val_mse: 0.0632\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0921 - val_loss: 0.0691 - val_mse: 0.0535\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.0889 - val_loss: 0.0712 - val_mse: 0.0556\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1007 - mse: 0.0852 - val_loss: 0.0764 - val_mse: 0.0609\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1045 - mse: 0.0889 - val_loss: 0.0649 - val_mse: 0.0494\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0989 - mse: 0.0834 - val_loss: 0.0825 - val_mse: 0.0670\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0781 - val_loss: 0.0628 - val_mse: 0.0472\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0902 - mse: 0.0747 - val_loss: 0.0813 - val_mse: 0.0658\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0873 - mse: 0.0718 - val_loss: 0.0624 - val_mse: 0.0469\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0671 - val_loss: 0.0594 - val_mse: 0.0439\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0793 - mse: 0.0638 - val_loss: 0.0744 - val_mse: 0.0590\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0602 - val_loss: 0.0559 - val_mse: 0.0404\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0576 - val_loss: 0.0894 - val_mse: 0.0739\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0568 - val_loss: 0.0549 - val_mse: 0.0394\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0533 - val_loss: 0.0559 - val_mse: 0.0404\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0511 - val_loss: 0.0576 - val_mse: 0.0421\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0499 - val_loss: 0.0495 - val_mse: 0.0340\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0630 - mse: 0.0475 - val_loss: 0.0512 - val_mse: 0.0357\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0443 - val_loss: 0.0476 - val_mse: 0.0322\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0422 - val_loss: 0.0500 - val_mse: 0.0345\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0407 - val_loss: 0.0488 - val_mse: 0.0333\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0390 - val_loss: 0.0472 - val_mse: 0.0318\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0372 - val_loss: 0.0460 - val_mse: 0.0306\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0358 - val_loss: 0.0437 - val_mse: 0.0283\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0507 - mse: 0.0352 - val_loss: 0.0428 - val_mse: 0.0274\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0334 - val_loss: 0.0428 - val_mse: 0.0274\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0472 - mse: 0.0318 - val_loss: 0.0445 - val_mse: 0.0291\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0464 - mse: 0.0310 - val_loss: 0.0408 - val_mse: 0.0254\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0296 - val_loss: 0.0414 - val_mse: 0.0260\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0284 - val_loss: 0.0398 - val_mse: 0.0244\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0280 - val_loss: 0.0391 - val_mse: 0.0237\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0277 - val_loss: 0.0417 - val_mse: 0.0262\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0265 - val_loss: 0.0390 - val_mse: 0.0236\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0261 - val_loss: 0.0373 - val_mse: 0.0219\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0254 - val_loss: 0.0369 - val_mse: 0.0215\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0246 - val_loss: 0.0384 - val_mse: 0.0230\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0243 - val_loss: 0.0416 - val_mse: 0.0263\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0237 - val_loss: 0.0371 - val_mse: 0.0217\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0234 - val_loss: 0.0405 - val_mse: 0.0251\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0229 - val_loss: 0.0351 - val_mse: 0.0197\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0227 - val_loss: 0.0387 - val_mse: 0.0234\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0216 - val_loss: 0.0354 - val_mse: 0.0200\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0220 - val_loss: 0.0348 - val_mse: 0.0194\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0215 - val_loss: 0.0340 - val_mse: 0.0187\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0213 - val_loss: 0.0348 - val_mse: 0.0195\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0215 - val_loss: 0.0348 - val_mse: 0.0195\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0211 - val_loss: 0.0352 - val_mse: 0.0199\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0209 - val_loss: 0.0333 - val_mse: 0.0179\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0204 - val_loss: 0.0336 - val_mse: 0.0183\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0212 - val_loss: 0.0325 - val_mse: 0.0172\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0205 - val_loss: 0.0325 - val_mse: 0.0172\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0200 - val_loss: 0.0327 - val_mse: 0.0174\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0198 - val_loss: 0.0343 - val_mse: 0.0190\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0196 - val_loss: 0.0331 - val_mse: 0.0178\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0198 - val_loss: 0.0318 - val_mse: 0.0166\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0193 - val_loss: 0.0325 - val_mse: 0.0172\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0193 - val_loss: 0.0317 - val_mse: 0.0164\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0191 - val_loss: 0.0317 - val_mse: 0.0164\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0190 - val_loss: 0.0346 - val_mse: 0.0194\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0196 - val_loss: 0.0313 - val_mse: 0.0161\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0188 - val_loss: 0.0327 - val_mse: 0.0175\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0188 - val_loss: 0.0313 - val_mse: 0.0161\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0340 - mse: 0.0188 - val_loss: 0.0309 - val_mse: 0.0157\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0184 - val_loss: 0.0314 - val_mse: 0.0162\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0184 - val_loss: 0.0306 - val_mse: 0.0154\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0183 - val_loss: 0.0325 - val_mse: 0.0173\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0334 - mse: 0.0182 - val_loss: 0.0319 - val_mse: 0.0167\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0176 - val_loss: 0.0307 - val_mse: 0.0156\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0334 - mse: 0.0182 - val_loss: 0.0311 - val_mse: 0.0159\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0178 - val_loss: 0.0323 - val_mse: 0.0171\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0179 - val_loss: 0.0300 - val_mse: 0.0148\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0175 - val_loss: 0.0299 - val_mse: 0.0148\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0176 - val_loss: 0.0301 - val_mse: 0.0150\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0177 - val_loss: 0.0299 - val_mse: 0.0147\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0174 - val_loss: 0.0297 - val_mse: 0.0146\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0178 - val_loss: 0.0301 - val_mse: 0.0150\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0174 - val_loss: 0.0298 - val_mse: 0.0147\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0172 - val_loss: 0.0318 - val_mse: 0.0167\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0173 - val_loss: 0.0303 - val_mse: 0.0152\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0171 - val_loss: 0.0328 - val_mse: 0.0177\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0175 - val_loss: 0.0295 - val_mse: 0.0145\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0169 - val_loss: 0.0293 - val_mse: 0.0142\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0166 - val_loss: 0.0291 - val_mse: 0.0140\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0165 - val_loss: 0.0292 - val_mse: 0.0141\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0165 - val_loss: 0.0294 - val_mse: 0.0144\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0163 - val_loss: 0.0293 - val_mse: 0.0142\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0167 - val_loss: 0.0289 - val_mse: 0.0138\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0164 - val_loss: 0.0289 - val_mse: 0.0138\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0160 - val_loss: 0.0287 - val_mse: 0.0136\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0163 - val_loss: 0.0288 - val_mse: 0.0138\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0158 - val_loss: 0.0286 - val_mse: 0.0136\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0162 - val_loss: 0.0289 - val_mse: 0.0139\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0161 - val_loss: 0.0284 - val_mse: 0.0134\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0156 - val_loss: 0.0289 - val_mse: 0.0139\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0157 - val_loss: 0.0285 - val_mse: 0.0135\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0156 - val_loss: 0.0293 - val_mse: 0.0143\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0156 - val_loss: 0.0285 - val_mse: 0.0135\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0153 - val_loss: 0.0303 - val_mse: 0.0153\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0153 - val_loss: 0.0281 - val_mse: 0.0132\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0150 - val_loss: 0.0281 - val_mse: 0.0132\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0149 - val_loss: 0.0286 - val_mse: 0.0136\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0152 - val_loss: 0.0303 - val_mse: 0.0154\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0153 - val_loss: 0.0285 - val_mse: 0.0136\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0149 - val_loss: 0.0281 - val_mse: 0.0132\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0150 - val_loss: 0.0280 - val_mse: 0.0131\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0148 - val_loss: 0.0282 - val_mse: 0.0133\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0149 - val_loss: 0.0280 - val_mse: 0.0131\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0145 - val_loss: 0.0279 - val_mse: 0.0130\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0141 - val_loss: 0.0294 - val_mse: 0.0145\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0142 - val_loss: 0.0288 - val_mse: 0.0139\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0147 - val_loss: 0.0294 - val_mse: 0.0145\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0142 - val_loss: 0.0299 - val_mse: 0.0150\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0144 - val_loss: 0.0279 - val_mse: 0.0130\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0143 - val_loss: 0.0276 - val_mse: 0.0127\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0150 - val_loss: 0.0275 - val_mse: 0.0127\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0141 - val_loss: 0.0277 - val_mse: 0.0129\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0141 - val_loss: 0.0279 - val_mse: 0.0131\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0137 - val_loss: 0.0289 - val_mse: 0.0140\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0139 - val_loss: 0.0276 - val_mse: 0.0127\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0138 - val_loss: 0.0302 - val_mse: 0.0153\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0137 - val_loss: 0.0275 - val_mse: 0.0127\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0138 - val_loss: 0.0272 - val_mse: 0.0124\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0137 - val_loss: 0.0275 - val_mse: 0.0126\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0136 - val_loss: 0.0271 - val_mse: 0.0123\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0136 - val_loss: 0.0268 - val_mse: 0.0120\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0133 - val_loss: 0.0292 - val_mse: 0.0144\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0133 - val_loss: 0.0268 - val_mse: 0.0120\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0137 - val_loss: 0.0269 - val_mse: 0.0121\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0283 - mse: 0.0135 - val_loss: 0.0267 - val_mse: 0.0119\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0137 - val_loss: 0.0291 - val_mse: 0.0144\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0131 - val_loss: 0.0273 - val_mse: 0.0125\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0131 - val_loss: 0.0266 - val_mse: 0.0119\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0132 - val_loss: 0.0298 - val_mse: 0.0151\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0134 - val_loss: 0.0266 - val_mse: 0.0119\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0132 - val_loss: 0.0266 - val_mse: 0.0119\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0130 - val_loss: 0.0274 - val_mse: 0.0127\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0132 - val_loss: 0.0268 - val_mse: 0.0121\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0130 - val_loss: 0.0275 - val_mse: 0.0128\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0127 - val_loss: 0.0269 - val_mse: 0.0122\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0127 - val_loss: 0.0275 - val_mse: 0.0128\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0128 - val_loss: 0.0282 - val_mse: 0.0135\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 0.0125 - val_loss: 0.0261 - val_mse: 0.0114\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0126 - val_loss: 0.0263 - val_mse: 0.0117\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0126 - val_loss: 0.0261 - val_mse: 0.0114\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0126 - val_loss: 0.0266 - val_mse: 0.0120\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0122 - val_loss: 0.0280 - val_mse: 0.0134\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0124 - val_loss: 0.0259 - val_mse: 0.0113\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0121 - val_loss: 0.0265 - val_mse: 0.0118\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0122 - val_loss: 0.0260 - val_mse: 0.0114\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0122 - val_loss: 0.0278 - val_mse: 0.0132\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0123 - val_loss: 0.0257 - val_mse: 0.0111\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0122 - val_loss: 0.0257 - val_mse: 0.0111\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0122 - val_loss: 0.0256 - val_mse: 0.0110\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0120 - val_loss: 0.0260 - val_mse: 0.0114\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0120 - val_loss: 0.0272 - val_mse: 0.0127\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0123 - val_loss: 0.0269 - val_mse: 0.0123\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0119 - val_loss: 0.0262 - val_mse: 0.0117\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0120 - val_loss: 0.0254 - val_mse: 0.0108\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0117 - val_loss: 0.0255 - val_mse: 0.0109\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0119 - val_loss: 0.0253 - val_mse: 0.0108\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0119 - val_loss: 0.0257 - val_mse: 0.0112\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0117 - val_loss: 0.0257 - val_mse: 0.0111\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0116 - val_loss: 0.0265 - val_mse: 0.0120\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0114 - val_loss: 0.0270 - val_mse: 0.0125\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0259 - mse: 0.0114 - val_loss: 0.0250 - val_mse: 0.0105\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0114 - val_loss: 0.0250 - val_mse: 0.0105\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0116 - val_loss: 0.0250 - val_mse: 0.0105\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0117 - val_loss: 0.0249 - val_mse: 0.0104\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0113 - val_loss: 0.0249 - val_mse: 0.0104\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0111 - val_loss: 0.0262 - val_mse: 0.0117\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0112 - val_loss: 0.0251 - val_mse: 0.0106\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0111 - val_loss: 0.0272 - val_mse: 0.0127\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0113 - val_loss: 0.0248 - val_mse: 0.0104\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0112 - val_loss: 0.0284 - val_mse: 0.0139\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0110 - val_loss: 0.0261 - val_mse: 0.0117\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0109 - val_loss: 0.0256 - val_mse: 0.0111\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0109 - val_loss: 0.0250 - val_mse: 0.0106\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0105 - val_loss: 0.0245 - val_mse: 0.0101\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0108 - val_loss: 0.0245 - val_mse: 0.0101\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0108 - val_loss: 0.0247 - val_mse: 0.0103\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0108 - val_loss: 0.0244 - val_mse: 0.0100\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0105 - val_loss: 0.0243 - val_mse: 0.0099\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0105 - val_loss: 0.0256 - val_mse: 0.0112\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0107 - val_loss: 0.0244 - val_mse: 0.0100\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0107 - val_loss: 0.0242 - val_mse: 0.0098\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0104 - val_loss: 0.0244 - val_mse: 0.0100\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0102 - val_loss: 0.0242 - val_mse: 0.0099\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0105 - val_loss: 0.0240 - val_mse: 0.0097\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0102 - val_loss: 0.0242 - val_mse: 0.0099\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0103 - val_loss: 0.0239 - val_mse: 0.0096\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0102 - val_loss: 0.0243 - val_mse: 0.0099\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0099 - val_loss: 0.0281 - val_mse: 0.0138\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0100 - val_loss: 0.0241 - val_mse: 0.0098\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0102 - val_loss: 0.0243 - val_mse: 0.0100\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0099 - val_loss: 0.0240 - val_mse: 0.0097\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0099 - val_loss: 0.0238 - val_mse: 0.0095\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0099 - val_loss: 0.0270 - val_mse: 0.0127\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0099 - val_loss: 0.0236 - val_mse: 0.0093\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0098 - val_loss: 0.0240 - val_mse: 0.0097\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0098 - val_loss: 0.0274 - val_mse: 0.0132\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0095 - val_loss: 0.0235 - val_mse: 0.0092\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0238 - mse: 0.0096 - val_loss: 0.0235 - val_mse: 0.0092\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0097 - val_loss: 0.0233 - val_mse: 0.0091\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0096 - val_loss: 0.0235 - val_mse: 0.0093\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0098 - val_loss: 0.0233 - val_mse: 0.0091\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0097 - val_loss: 0.0233 - val_mse: 0.0091\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0093 - val_loss: 0.0234 - val_mse: 0.0092\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0091 - val_loss: 0.0234 - val_mse: 0.0093\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0093 - val_loss: 0.0232 - val_mse: 0.0090\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0094 - val_loss: 0.0233 - val_mse: 0.0091\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0095 - val_loss: 0.0234 - val_mse: 0.0093\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0091 - val_loss: 0.0236 - val_mse: 0.0095\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0091 - val_loss: 0.0229 - val_mse: 0.0088\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0090 - val_loss: 0.0235 - val_mse: 0.0093\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0091 - val_loss: 0.0238 - val_mse: 0.0097\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0088 - val_loss: 0.0229 - val_mse: 0.0088\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0089 - val_loss: 0.0228 - val_mse: 0.0087\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0088 - val_loss: 0.0226 - val_mse: 0.0085\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0087 - val_loss: 0.0228 - val_mse: 0.0087\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0087 - val_loss: 0.0229 - val_mse: 0.0088\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0087 - val_loss: 0.0246 - val_mse: 0.0106\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 0.0089 - val_loss: 0.0226 - val_mse: 0.0086\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0087 - val_loss: 0.0239 - val_mse: 0.0098\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0085 - val_loss: 0.0224 - val_mse: 0.0083\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0083 - val_loss: 0.0224 - val_mse: 0.0083\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0084 - val_loss: 0.0226 - val_mse: 0.0085\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0081 - val_loss: 0.0222 - val_mse: 0.0082\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0083 - val_loss: 0.0223 - val_mse: 0.0083\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0081 - val_loss: 0.0222 - val_mse: 0.0081\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0082 - val_loss: 0.0224 - val_mse: 0.0084\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0081 - val_loss: 0.0221 - val_mse: 0.0081\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0081 - val_loss: 0.0220 - val_mse: 0.0080\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0080 - val_loss: 0.0220 - val_mse: 0.0080\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0080 - val_loss: 0.0226 - val_mse: 0.0086\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0079 - val_loss: 0.0223 - val_mse: 0.0083\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0080 - val_loss: 0.0226 - val_mse: 0.0086\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0079 - val_loss: 0.0218 - val_mse: 0.0079\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0078 - val_loss: 0.0223 - val_mse: 0.0084\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0080 - val_loss: 0.0218 - val_mse: 0.0078\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0077 - val_loss: 0.0218 - val_mse: 0.0079\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0077 - val_loss: 0.0216 - val_mse: 0.0077\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0075 - val_loss: 0.0226 - val_mse: 0.0087\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0076 - val_loss: 0.0217 - val_mse: 0.0078\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0077 - val_loss: 0.0214 - val_mse: 0.0075\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0075 - val_loss: 0.0214 - val_mse: 0.0075\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0075 - val_loss: 0.0213 - val_mse: 0.0075\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0074 - val_loss: 0.0213 - val_mse: 0.0075\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0072 - val_loss: 0.0212 - val_mse: 0.0074\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0074 - val_loss: 0.0215 - val_mse: 0.0076\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0073 - val_loss: 0.0217 - val_mse: 0.0079\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0073 - val_loss: 0.0211 - val_mse: 0.0073\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0072 - val_loss: 0.0218 - val_mse: 0.0080\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0071 - val_loss: 0.0210 - val_mse: 0.0072\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0071 - val_loss: 0.0212 - val_mse: 0.0074\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0071 - val_loss: 0.0218 - val_mse: 0.0080\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0072 - val_loss: 0.0215 - val_mse: 0.0077\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0070 - val_loss: 0.0208 - val_mse: 0.0070\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0068 - val_loss: 0.0219 - val_mse: 0.0081\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0069 - val_loss: 0.0207 - val_mse: 0.0069\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0068 - val_loss: 0.0212 - val_mse: 0.0075\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0068 - val_loss: 0.0215 - val_mse: 0.0077\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0067 - val_loss: 0.0209 - val_mse: 0.0072\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0066 - val_loss: 0.0205 - val_mse: 0.0068\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0068 - val_loss: 0.0207 - val_mse: 0.0070\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0213 - val_mse: 0.0076\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0220 - val_mse: 0.0083\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0064 - val_loss: 0.0203 - val_mse: 0.0066\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0203 - val_mse: 0.0066\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0064 - val_loss: 0.0204 - val_mse: 0.0067\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0065 - val_loss: 0.0201 - val_mse: 0.0065\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0064 - val_loss: 0.0203 - val_mse: 0.0066\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0063 - val_loss: 0.0206 - val_mse: 0.0070\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0063 - val_loss: 0.0199 - val_mse: 0.0063\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0061 - val_loss: 0.0199 - val_mse: 0.0063\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0207 - val_mse: 0.0071\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0200 - val_mse: 0.0064\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0062 - val_loss: 0.0205 - val_mse: 0.0069\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0061 - val_loss: 0.0203 - val_mse: 0.0068\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0060 - val_loss: 0.0196 - val_mse: 0.0060\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0059 - val_loss: 0.0206 - val_mse: 0.0070\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0059 - val_loss: 0.0200 - val_mse: 0.0064\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0058 - val_loss: 0.0197 - val_mse: 0.0061\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0058 - val_loss: 0.0202 - val_mse: 0.0066\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0194 - mse: 0.0059 - val_loss: 0.0194 - val_mse: 0.0058\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0057 - val_loss: 0.0195 - val_mse: 0.0060\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0194 - val_mse: 0.0059\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0057 - val_loss: 0.0200 - val_mse: 0.0065\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0056 - val_loss: 0.0192 - val_mse: 0.0057\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0056 - val_loss: 0.0192 - val_mse: 0.0057\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0055 - val_loss: 0.0194 - val_mse: 0.0060\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0055 - val_loss: 0.0192 - val_mse: 0.0057\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0054 - val_loss: 0.0191 - val_mse: 0.0057\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0054 - val_loss: 0.0194 - val_mse: 0.0060\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0054 - val_loss: 0.0190 - val_mse: 0.0055\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0054 - val_loss: 0.0200 - val_mse: 0.0066\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0054 - val_loss: 0.0190 - val_mse: 0.0055\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0053 - val_loss: 0.0191 - val_mse: 0.0057\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0052 - val_loss: 0.0188 - val_mse: 0.0054\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0052 - val_loss: 0.0190 - val_mse: 0.0056\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0053 - val_loss: 0.0186 - val_mse: 0.0052\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0187 - val_mse: 0.0054\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0185 - val_mse: 0.0051\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0052 - val_loss: 0.0193 - val_mse: 0.0059\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0051 - val_loss: 0.0186 - val_mse: 0.0052\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0051 - val_loss: 0.0192 - val_mse: 0.0058\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0050 - val_loss: 0.0188 - val_mse: 0.0055\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0049 - val_loss: 0.0184 - val_mse: 0.0051\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0049 - val_loss: 0.0184 - val_mse: 0.0050\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0050 - val_loss: 0.0187 - val_mse: 0.0054\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0047 - val_loss: 0.0187 - val_mse: 0.0054\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0050 - val_loss: 0.0184 - val_mse: 0.0051\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0048 - val_loss: 0.0183 - val_mse: 0.0050\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0048 - val_loss: 0.0184 - val_mse: 0.0051\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0047 - val_loss: 0.0180 - val_mse: 0.0048\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0049 - val_loss: 0.0184 - val_mse: 0.0051\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0046 - val_loss: 0.0183 - val_mse: 0.0051\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0047 - val_loss: 0.0180 - val_mse: 0.0048\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0046 - val_loss: 0.0182 - val_mse: 0.0050\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0047 - val_loss: 0.0179 - val_mse: 0.0046\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0045 - val_loss: 0.0178 - val_mse: 0.0046\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0045 - val_loss: 0.0177 - val_mse: 0.0045\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0046 - val_loss: 0.0185 - val_mse: 0.0053\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0046 - val_loss: 0.0177 - val_mse: 0.0045\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0176 - val_mse: 0.0044\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0177 - val_mse: 0.0046\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0045 - val_loss: 0.0175 - val_mse: 0.0044\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0174 - val_mse: 0.0043\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0174 - val_mse: 0.0043\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0044 - val_loss: 0.0182 - val_mse: 0.0051\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0043 - val_loss: 0.0185 - val_mse: 0.0054\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0042 - val_loss: 0.0172 - val_mse: 0.0041\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0043 - val_loss: 0.0175 - val_mse: 0.0044\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0042 - val_loss: 0.0177 - val_mse: 0.0046\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0042 - val_loss: 0.0171 - val_mse: 0.0041\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0041 - val_loss: 0.0173 - val_mse: 0.0043\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0041 - val_loss: 0.0172 - val_mse: 0.0041\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0041 - val_loss: 0.0172 - val_mse: 0.0042\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0040 - val_loss: 0.0172 - val_mse: 0.0042\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0041 - val_loss: 0.0170 - val_mse: 0.0040\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0040 - val_loss: 0.0174 - val_mse: 0.0044\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0040 - val_loss: 0.0177 - val_mse: 0.0047\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0041 - val_loss: 0.0169 - val_mse: 0.0039\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0041 - val_loss: 0.0170 - val_mse: 0.0040\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0040 - val_loss: 0.0168 - val_mse: 0.0039\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0039 - val_loss: 0.0172 - val_mse: 0.0042\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0039 - val_loss: 0.0168 - val_mse: 0.0038\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0038 - val_loss: 0.0169 - val_mse: 0.0039\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0038 - val_loss: 0.0172 - val_mse: 0.0042\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0039 - val_loss: 0.0169 - val_mse: 0.0040\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0039 - val_loss: 0.0177 - val_mse: 0.0048\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0037 - val_loss: 0.0166 - val_mse: 0.0037\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0039 - val_loss: 0.0171 - val_mse: 0.0042\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0038 - val_loss: 0.0165 - val_mse: 0.0036\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0038 - val_loss: 0.0167 - val_mse: 0.0038\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0036 - val_loss: 0.0165 - val_mse: 0.0036\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0037 - val_loss: 0.0164 - val_mse: 0.0036\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0168 - val_mse: 0.0039\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0037 - val_loss: 0.0164 - val_mse: 0.0035\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0164 - val_mse: 0.0035\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0164 - val_mse: 0.0036\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0168 - val_mse: 0.0039\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0163 - val_mse: 0.0035\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0035 - val_loss: 0.0164 - val_mse: 0.0036\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0036 - val_loss: 0.0162 - val_mse: 0.0034\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0035 - val_loss: 0.0162 - val_mse: 0.0034\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0036 - val_loss: 0.0161 - val_mse: 0.0033\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0035 - val_loss: 0.0162 - val_mse: 0.0035\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0035 - val_loss: 0.0162 - val_mse: 0.0034\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0035 - val_loss: 0.0162 - val_mse: 0.0034\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0035 - val_loss: 0.0160 - val_mse: 0.0033\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0036 - val_loss: 0.0162 - val_mse: 0.0034\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0035 - val_loss: 0.0161 - val_mse: 0.0034\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0034 - val_loss: 0.0163 - val_mse: 0.0036\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0034 - val_loss: 0.0162 - val_mse: 0.0035\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0034 - val_loss: 0.0159 - val_mse: 0.0033\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0034 - val_loss: 0.0160 - val_mse: 0.0033\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0034 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0034 - val_loss: 0.0158 - val_mse: 0.0031\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0033 - val_loss: 0.0158 - val_mse: 0.0031\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0033 - val_loss: 0.0157 - val_mse: 0.0031\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0033 - val_loss: 0.0160 - val_mse: 0.0034\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0033 - val_loss: 0.0158 - val_mse: 0.0031\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0156 - val_mse: 0.0030\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0032 - val_loss: 0.0156 - val_mse: 0.0030\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0032 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0032 - val_loss: 0.0158 - val_mse: 0.0032\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0032 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0031 - val_loss: 0.0154 - val_mse: 0.0029\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0031 - val_loss: 0.0155 - val_mse: 0.0030\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0031 - val_loss: 0.0154 - val_mse: 0.0029\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0032 - val_loss: 0.0154 - val_mse: 0.0029\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0030 - val_loss: 0.0153 - val_mse: 0.0028\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0031 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0031 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0031 - val_loss: 0.0153 - val_mse: 0.0028\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0030 - val_loss: 0.0156 - val_mse: 0.0031\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0030 - val_loss: 0.0152 - val_mse: 0.0028\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0030 - val_loss: 0.0153 - val_mse: 0.0028\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0030 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0030 - val_loss: 0.0157 - val_mse: 0.0033\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0030 - val_loss: 0.0153 - val_mse: 0.0029\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0030 - val_loss: 0.0151 - val_mse: 0.0027\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0029 - val_loss: 0.0151 - val_mse: 0.0027\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0029 - val_loss: 0.0154 - val_mse: 0.0030\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0029 - val_loss: 0.0152 - val_mse: 0.0028\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0029 - val_loss: 0.0150 - val_mse: 0.0026\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0152 - val_mse: 0.0029\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0150 - val_mse: 0.0026\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0151 - val_mse: 0.0027\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0028 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0028 - val_loss: 0.0150 - val_mse: 0.0027\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0151 - val_mse: 0.0028\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0148 - val_mse: 0.0025\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0029 - val_loss: 0.0154 - val_mse: 0.0031\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0028 - val_loss: 0.0150 - val_mse: 0.0027\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0028 - val_loss: 0.0148 - val_mse: 0.0026\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0028 - val_loss: 0.0152 - val_mse: 0.0030\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0028 - val_loss: 0.0148 - val_mse: 0.0025\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0028 - val_loss: 0.0148 - val_mse: 0.0026\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0028 - val_loss: 0.0149 - val_mse: 0.0027\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0028 - val_loss: 0.0147 - val_mse: 0.0025\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0027 - val_loss: 0.0158 - val_mse: 0.0036\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0028 - val_loss: 0.0148 - val_mse: 0.0026\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0028 - val_loss: 0.0147 - val_mse: 0.0025\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0027 - val_loss: 0.0147 - val_mse: 0.0025\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0027 - val_loss: 0.0147 - val_mse: 0.0026\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0027 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0146 - val_mse: 0.0024\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0026 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0148 - val_mse: 0.0027\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0026 - val_loss: 0.0145 - val_mse: 0.0024\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0146 - val_mse: 0.0025\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0145 - val_mse: 0.0025\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0026 - val_loss: 0.0144 - val_mse: 0.0023\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0027 - val_loss: 0.0144 - val_mse: 0.0023\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0026 - val_loss: 0.0144 - val_mse: 0.0024\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0026 - val_loss: 0.0144 - val_mse: 0.0024\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0026 - val_loss: 0.0144 - val_mse: 0.0024\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0025 - val_loss: 0.0144 - val_mse: 0.0024\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0027 - val_loss: 0.0144 - val_mse: 0.0024\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0026 - val_loss: 0.0145 - val_mse: 0.0025\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0026 - val_loss: 0.0147 - val_mse: 0.0027\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0025 - val_loss: 0.0146 - val_mse: 0.0026\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0026 - val_loss: 0.0142 - val_mse: 0.0023\n",
      "Epoch 458: early stopping\n",
      "0 0.0026 0.0023 458 {'hidden_layer_nodes': [5, 6]}\n",
      "1 0.0028 0.0024 500 {'hidden_layer_nodes': [3, 6]}\n",
      "2 0.0022 0.0024 476 {'hidden_layer_nodes': [4, 4]}\n",
      "3 0.0032 0.0027 276 {'hidden_layer_nodes': [5, 4]}\n",
      "4 0.0041 0.0043 371 {'hidden_layer_nodes': [4, 6]}\n",
      "5 0.0891 0.0514 22 {'hidden_layer_nodes': [3, 4]}\n",
      "6 0.0878 0.0521 24 {'hidden_layer_nodes': [5, 2]}\n",
      "7 0.0883 0.0553 46 {'hidden_layer_nodes': [3, 2]}\n",
      "8 0.0889 0.0582 31 {'hidden_layer_nodes': [4, 2]}\n"
     ]
    }
   ],
   "source": [
    "nh1 = [3, 4, 5]\n",
    "nh2 = [2, 4, 6]\n",
    "layers = [list(items) for items in itertools.product(nh1, nh2)]\n",
    "\n",
    "param_dict = dict(hidden_layer_nodes=layers)\n",
    "\n",
    "arch_eval_grid = grid_search(param_dict, X_train, y_train, X_val, y_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find best regularizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "{'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE2B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.2617 - mse: 0.0887 - val_loss: 0.1877 - val_mse: 0.0517\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1942 - mse: 0.0882 - val_loss: 0.1316 - val_mse: 0.0510\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1512 - mse: 0.0882 - val_loss: 0.1016 - val_mse: 0.0516\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.0887 - val_loss: 0.0860 - val_mse: 0.0543\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1161 - mse: 0.0897 - val_loss: 0.0764 - val_mse: 0.0540\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1069 - mse: 0.0891 - val_loss: 0.0676 - val_mse: 0.0520\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1042 - mse: 0.0898 - val_loss: 0.0711 - val_mse: 0.0557\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1041 - mse: 0.0905 - val_loss: 0.0659 - val_mse: 0.0520\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0999 - mse: 0.0871 - val_loss: 0.0659 - val_mse: 0.0535\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1019 - mse: 0.0896 - val_loss: 0.0655 - val_mse: 0.0536\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1025 - mse: 0.0908 - val_loss: 0.0670 - val_mse: 0.0560\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1005 - mse: 0.0894 - val_loss: 0.0834 - val_mse: 0.0701\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.0905 - val_loss: 0.0784 - val_mse: 0.0690\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1007 - mse: 0.0906 - val_loss: 0.0672 - val_mse: 0.0581\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0986 - mse: 0.0890 - val_loss: 0.0761 - val_mse: 0.0671\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0898 - val_loss: 0.0641 - val_mse: 0.0549\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0897 - val_loss: 0.0631 - val_mse: 0.0538\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0895 - val_loss: 0.0620 - val_mse: 0.0525\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.0906 - val_loss: 0.0619 - val_mse: 0.0521\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0999 - mse: 0.0903 - val_loss: 0.0626 - val_mse: 0.0533\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0896 - val_loss: 0.0620 - val_mse: 0.0520\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0997 - mse: 0.0900 - val_loss: 0.0632 - val_mse: 0.0539\n",
      "Epoch 22: early stopping\n",
      "{'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 0.1133 - mse: 0.0908 - val_loss: 0.0736 - val_mse: 0.0515\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1092 - mse: 0.0876 - val_loss: 0.0737 - val_mse: 0.0526\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.0872 - val_loss: 0.0841 - val_mse: 0.0638\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0876 - val_loss: 0.0699 - val_mse: 0.0501\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1047 - mse: 0.0852 - val_loss: 0.0683 - val_mse: 0.0492\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1016 - mse: 0.0826 - val_loss: 0.0675 - val_mse: 0.0486\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0996 - mse: 0.0809 - val_loss: 0.0689 - val_mse: 0.0502\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0951 - mse: 0.0764 - val_loss: 0.0622 - val_mse: 0.0435\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0914 - mse: 0.0725 - val_loss: 0.0586 - val_mse: 0.0395\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0855 - mse: 0.0662 - val_loss: 0.0539 - val_mse: 0.0343\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0744 - mse: 0.0545 - val_loss: 0.0509 - val_mse: 0.0306\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0439 - val_loss: 0.0558 - val_mse: 0.0349\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0357 - val_loss: 0.0430 - val_mse: 0.0217\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0312 - val_loss: 0.0419 - val_mse: 0.0205\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0296 - val_loss: 0.0406 - val_mse: 0.0194\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0269 - val_loss: 0.0435 - val_mse: 0.0225\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0263 - val_loss: 0.0390 - val_mse: 0.0183\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0258 - val_loss: 0.0379 - val_mse: 0.0175\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0250 - val_loss: 0.0374 - val_mse: 0.0174\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0239 - val_loss: 0.0379 - val_mse: 0.0182\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0238 - val_loss: 0.0368 - val_mse: 0.0174\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0228 - val_loss: 0.0380 - val_mse: 0.0188\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0228 - val_loss: 0.0431 - val_mse: 0.0241\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0215 - val_loss: 0.0356 - val_mse: 0.0169\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0211 - val_loss: 0.0335 - val_mse: 0.0151\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0213 - val_loss: 0.0340 - val_mse: 0.0158\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0201 - val_loss: 0.0331 - val_mse: 0.0152\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0208 - val_loss: 0.0353 - val_mse: 0.0176\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0193 - val_loss: 0.0320 - val_mse: 0.0145\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0191 - val_loss: 0.0313 - val_mse: 0.0140\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0185 - val_loss: 0.0325 - val_mse: 0.0155\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0192 - val_loss: 0.0324 - val_mse: 0.0156\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0348 - mse: 0.0180 - val_loss: 0.0303 - val_mse: 0.0137\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0181 - val_loss: 0.0303 - val_mse: 0.0138\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0177 - val_loss: 0.0300 - val_mse: 0.0137\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0175 - val_loss: 0.0304 - val_mse: 0.0141\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0167 - val_loss: 0.0296 - val_mse: 0.0136\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0172 - val_loss: 0.0301 - val_mse: 0.0141\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0165 - val_loss: 0.0288 - val_mse: 0.0128\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0169 - val_loss: 0.0336 - val_mse: 0.0177\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0168 - val_loss: 0.0326 - val_mse: 0.0167\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0160 - val_loss: 0.0283 - val_mse: 0.0126\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0161 - val_loss: 0.0285 - val_mse: 0.0128\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0164 - val_loss: 0.0282 - val_mse: 0.0126\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0162 - val_loss: 0.0286 - val_mse: 0.0131\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0162 - val_loss: 0.0303 - val_mse: 0.0149\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0153 - val_loss: 0.0279 - val_mse: 0.0125\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0156 - val_loss: 0.0279 - val_mse: 0.0126\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0151 - val_loss: 0.0301 - val_mse: 0.0148\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0156 - val_loss: 0.0286 - val_mse: 0.0134\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0154 - val_loss: 0.0287 - val_mse: 0.0135\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0300 - mse: 0.0149 - val_loss: 0.0303 - val_mse: 0.0152\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0154 - val_loss: 0.0274 - val_mse: 0.0124\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0148 - val_loss: 0.0293 - val_mse: 0.0142\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0148 - val_loss: 0.0269 - val_mse: 0.0120\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0147 - val_loss: 0.0273 - val_mse: 0.0124\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0148 - val_loss: 0.0309 - val_mse: 0.0161\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0150 - val_loss: 0.0304 - val_mse: 0.0156\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0295 - mse: 0.0147 - val_loss: 0.0267 - val_mse: 0.0119\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0146 - val_loss: 0.0272 - val_mse: 0.0125\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0146 - val_loss: 0.0288 - val_mse: 0.0141\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0143 - val_loss: 0.0340 - val_mse: 0.0194\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0145 - val_loss: 0.0283 - val_mse: 0.0136\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0148 - val_loss: 0.0259 - val_mse: 0.0114\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0140 - val_loss: 0.0260 - val_mse: 0.0115\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0142 - val_loss: 0.0259 - val_mse: 0.0114\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0149 - val_loss: 0.0334 - val_mse: 0.0190\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0141 - val_loss: 0.0275 - val_mse: 0.0130\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0282 - mse: 0.0139 - val_loss: 0.0271 - val_mse: 0.0127\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0138 - val_loss: 0.0258 - val_mse: 0.0115\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0136 - val_loss: 0.0257 - val_mse: 0.0114\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0290 - mse: 0.0147 - val_loss: 0.0262 - val_mse: 0.0120\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0142 - val_loss: 0.0255 - val_mse: 0.0113\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0144 - val_loss: 0.0253 - val_mse: 0.0110\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0142 - val_loss: 0.0252 - val_mse: 0.0110\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0132 - val_loss: 0.0280 - val_mse: 0.0137\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0139 - val_loss: 0.0297 - val_mse: 0.0155\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0132 - val_loss: 0.0253 - val_mse: 0.0111\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0136 - val_loss: 0.0263 - val_mse: 0.0122\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0139 - val_loss: 0.0266 - val_mse: 0.0124\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0135 - val_loss: 0.0267 - val_mse: 0.0126\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0138 - val_loss: 0.0245 - val_mse: 0.0104\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0134 - val_loss: 0.0258 - val_mse: 0.0117\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0128 - val_loss: 0.0244 - val_mse: 0.0103\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 0.0131 - val_loss: 0.0275 - val_mse: 0.0134\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0136 - val_loss: 0.0248 - val_mse: 0.0108\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0127 - val_loss: 0.0246 - val_mse: 0.0105\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0127 - val_loss: 0.0242 - val_mse: 0.0102\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0135 - val_loss: 0.0263 - val_mse: 0.0122\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0134 - val_loss: 0.0256 - val_mse: 0.0115\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0128 - val_loss: 0.0292 - val_mse: 0.0151\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0136 - val_loss: 0.0243 - val_mse: 0.0103\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 0.0132 - val_loss: 0.0242 - val_mse: 0.0103\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0126 - val_loss: 0.0279 - val_mse: 0.0139\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0262 - mse: 0.0122 - val_loss: 0.0271 - val_mse: 0.0130\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0131 - val_loss: 0.0269 - val_mse: 0.0130\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0127 - val_loss: 0.0264 - val_mse: 0.0124\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0124 - val_loss: 0.0244 - val_mse: 0.0105\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0126 - val_loss: 0.0241 - val_mse: 0.0103\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0126 - val_loss: 0.0271 - val_mse: 0.0132\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0128 - val_loss: 0.0249 - val_mse: 0.0110\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0125 - val_loss: 0.0255 - val_mse: 0.0117\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0127 - val_loss: 0.0242 - val_mse: 0.0104\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0125 - val_loss: 0.0247 - val_mse: 0.0110\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0129 - val_loss: 0.0251 - val_mse: 0.0114\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0131 - val_loss: 0.0246 - val_mse: 0.0108\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0259 - mse: 0.0122 - val_loss: 0.0242 - val_mse: 0.0105\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0124 - val_loss: 0.0283 - val_mse: 0.0146\n",
      "Epoch 108: early stopping\n",
      "{'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE0A0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1355 - mse: 0.1331 - val_loss: 0.0546 - val_mse: 0.0522\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0893 - mse: 0.0868 - val_loss: 0.0590 - val_mse: 0.0565\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0883 - mse: 0.0859 - val_loss: 0.0511 - val_mse: 0.0486\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0859 - mse: 0.0834 - val_loss: 0.0518 - val_mse: 0.0493\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0808 - mse: 0.0783 - val_loss: 0.0462 - val_mse: 0.0437\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0732 - mse: 0.0706 - val_loss: 0.0416 - val_mse: 0.0390\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0617 - val_loss: 0.0374 - val_mse: 0.0346\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0493 - val_loss: 0.0305 - val_mse: 0.0275\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0364 - val_loss: 0.0273 - val_mse: 0.0242\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0310 - val_loss: 0.0294 - val_mse: 0.0262\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0288 - val_loss: 0.0299 - val_mse: 0.0267\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0311 - mse: 0.0279 - val_loss: 0.0237 - val_mse: 0.0204\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0263 - val_loss: 0.0236 - val_mse: 0.0204\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0256 - val_loss: 0.0223 - val_mse: 0.0190\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0243 - val_loss: 0.0239 - val_mse: 0.0206\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0234 - val_loss: 0.0210 - val_mse: 0.0178\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0220 - val_loss: 0.0268 - val_mse: 0.0235\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0212 - val_loss: 0.0200 - val_mse: 0.0167\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0243 - mse: 0.0210 - val_loss: 0.0221 - val_mse: 0.0188\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0202 - val_loss: 0.0210 - val_mse: 0.0177\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0196 - val_loss: 0.0208 - val_mse: 0.0175\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0189 - val_loss: 0.0197 - val_mse: 0.0164\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0188 - val_loss: 0.0176 - val_mse: 0.0143\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0206 - mse: 0.0173 - val_loss: 0.0177 - val_mse: 0.0144\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0177 - val_loss: 0.0181 - val_mse: 0.0147\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0199 - mse: 0.0165 - val_loss: 0.0167 - val_mse: 0.0134\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0159 - val_loss: 0.0172 - val_mse: 0.0138\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0156 - val_loss: 0.0213 - val_mse: 0.0180\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0155 - val_loss: 0.0160 - val_mse: 0.0126\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0188 - mse: 0.0154 - val_loss: 0.0167 - val_mse: 0.0134\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0146 - val_loss: 0.0174 - val_mse: 0.0140\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0139 - val_loss: 0.0159 - val_mse: 0.0125\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0140 - val_loss: 0.0151 - val_mse: 0.0117\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0134 - val_loss: 0.0149 - val_mse: 0.0115\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0147 - val_mse: 0.0113\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0125 - val_loss: 0.0205 - val_mse: 0.0171\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0124 - val_loss: 0.0144 - val_mse: 0.0109\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0122 - val_loss: 0.0159 - val_mse: 0.0125\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0117 - val_loss: 0.0155 - val_mse: 0.0121\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0117 - val_loss: 0.0143 - val_mse: 0.0108\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0111 - val_loss: 0.0138 - val_mse: 0.0104\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0114 - val_loss: 0.0134 - val_mse: 0.0099\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0106 - val_loss: 0.0156 - val_mse: 0.0121\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0099 - val_loss: 0.0133 - val_mse: 0.0099\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0103 - val_loss: 0.0128 - val_mse: 0.0094\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0100 - val_loss: 0.0130 - val_mse: 0.0095\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0099 - val_loss: 0.0144 - val_mse: 0.0109\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0096 - val_loss: 0.0146 - val_mse: 0.0111\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0099 - val_loss: 0.0126 - val_mse: 0.0091\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0093 - val_loss: 0.0120 - val_mse: 0.0085\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0089 - val_loss: 0.0120 - val_mse: 0.0085\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0087 - val_loss: 0.0126 - val_mse: 0.0091\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0086 - val_loss: 0.0132 - val_mse: 0.0097\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0080 - val_loss: 0.0124 - val_mse: 0.0089\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0080 - val_loss: 0.0113 - val_mse: 0.0078\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0080 - val_loss: 0.0118 - val_mse: 0.0083\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0084 - val_loss: 0.0119 - val_mse: 0.0084\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0078 - val_loss: 0.0113 - val_mse: 0.0078\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0073\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0075 - val_loss: 0.0112 - val_mse: 0.0076\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0071 - val_loss: 0.0114 - val_mse: 0.0079\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0071 - val_loss: 0.0116 - val_mse: 0.0081\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0072 - val_loss: 0.0107 - val_mse: 0.0072\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0072 - val_loss: 0.0105 - val_mse: 0.0069\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0069 - val_loss: 0.0103 - val_mse: 0.0068\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0070 - val_loss: 0.0104 - val_mse: 0.0069\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0068 - val_loss: 0.0120 - val_mse: 0.0085\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0067 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0066 - val_loss: 0.0102 - val_mse: 0.0066\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0069 - val_loss: 0.0101 - val_mse: 0.0065\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0064 - val_loss: 0.0100 - val_mse: 0.0064\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0068 - val_loss: 0.0099 - val_mse: 0.0063\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0099 - val_mse: 0.0064\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0102 - val_mse: 0.0067\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0064 - val_loss: 0.0106 - val_mse: 0.0071\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0064 - val_loss: 0.0105 - val_mse: 0.0069\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0101 - val_mse: 0.0065\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0063 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0063 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0097 - val_mse: 0.0061\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0113 - val_mse: 0.0077\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0061 - val_loss: 0.0099 - val_mse: 0.0063\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0094 - val_mse: 0.0058\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0061 - val_loss: 0.0114 - val_mse: 0.0078\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0093 - val_mse: 0.0057\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0061 - val_loss: 0.0092 - val_mse: 0.0057\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0059 - val_loss: 0.0106 - val_mse: 0.0070\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0059 - val_loss: 0.0092 - val_mse: 0.0056\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0057 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0059 - val_loss: 0.0107 - val_mse: 0.0072\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0122 - val_mse: 0.0086\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0091 - val_mse: 0.0055\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0057 - val_loss: 0.0091 - val_mse: 0.0055\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0106 - val_mse: 0.0071\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0088 - val_mse: 0.0053\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0102 - val_mse: 0.0066\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0088 - val_mse: 0.0052\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0059 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0054 - val_loss: 0.0087 - val_mse: 0.0051\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0053 - val_loss: 0.0094 - val_mse: 0.0058\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0113 - val_mse: 0.0077\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0088 - val_mse: 0.0052\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0087 - val_mse: 0.0051\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0108 - val_mse: 0.0072\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0053 - val_loss: 0.0098 - val_mse: 0.0062\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0087 - val_mse: 0.0051\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0086 - val_mse: 0.0050\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0053 - val_loss: 0.0100 - val_mse: 0.0064\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0084 - val_mse: 0.0048\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0056 - val_loss: 0.0084 - val_mse: 0.0048\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0053 - val_loss: 0.0086 - val_mse: 0.0050\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0050 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0050 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0052 - val_loss: 0.0117 - val_mse: 0.0082\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0103 - val_mse: 0.0068\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0084 - val_mse: 0.0049\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0082 - val_mse: 0.0046\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0109 - val_mse: 0.0073\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0048 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0048 - val_loss: 0.0086 - val_mse: 0.0051\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0062\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0051 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0049 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0051 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0050 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0049 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0048 - val_loss: 0.0112 - val_mse: 0.0076\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0097 - val_mse: 0.0061\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0100 - val_mse: 0.0065\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0086 - val_mse: 0.0050\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0112 - val_mse: 0.0077\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0047 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0046 - val_loss: 0.0078 - val_mse: 0.0042\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0078 - val_mse: 0.0042\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0092 - val_mse: 0.0056\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0082 - val_mse: 0.0046\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0047 - val_loss: 0.0089 - val_mse: 0.0054\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0046 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0107 - val_mse: 0.0072\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0082 - val_mse: 0.0047\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0045 - val_loss: 0.0075 - val_mse: 0.0040\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0044 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0044 - val_loss: 0.0076 - val_mse: 0.0041\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0045 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0045 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0045 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0101 - val_mse: 0.0066\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0042 - val_loss: 0.0076 - val_mse: 0.0041\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0074 - val_mse: 0.0038\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0041 - val_loss: 0.0072 - val_mse: 0.0036\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0090 - val_mse: 0.0055\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0041 - val_loss: 0.0075 - val_mse: 0.0040\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0072 - val_mse: 0.0036\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0045 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0040 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0075 - val_mse: 0.0040\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0040 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0035\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0035\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0040 - val_loss: 0.0094 - val_mse: 0.0058\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0037 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0089 - val_mse: 0.0054\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0067 - val_mse: 0.0031\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0068 - val_mse: 0.0032\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0110 - val_mse: 0.0075\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0034 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0068 - val_mse: 0.0034\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0033\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0076 - val_mse: 0.0041\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0032 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0032 - val_loss: 0.0062 - val_mse: 0.0027\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0061 - val_mse: 0.0027\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0062 - val_mse: 0.0027\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0033 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0064 - val_mse: 0.0030\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0061 - val_mse: 0.0027\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0062 - val_mse: 0.0028\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0062 - val_mse: 0.0027\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0034\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0071 - val_mse: 0.0037\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0027 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0033\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0066 - val_mse: 0.0032\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0069 - val_mse: 0.0035\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0069 - val_mse: 0.0035\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0070 - val_mse: 0.0036\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0071 - val_mse: 0.0037\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0029 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0027 - val_loss: 0.0059 - val_mse: 0.0024\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0030\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 302: early stopping\n",
      "{'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8730>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.2700 - mse: 0.1552 - val_loss: 0.1348 - val_mse: 0.0521\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1495 - mse: 0.0867 - val_loss: 0.1126 - val_mse: 0.0647\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1248 - mse: 0.0887 - val_loss: 0.0797 - val_mse: 0.0518\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1105 - mse: 0.0886 - val_loss: 0.0687 - val_mse: 0.0513\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1017 - mse: 0.0875 - val_loss: 0.0634 - val_mse: 0.0517\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1022 - mse: 0.0924 - val_loss: 0.0620 - val_mse: 0.0538\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0974 - mse: 0.0901 - val_loss: 0.0586 - val_mse: 0.0518\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0883 - val_loss: 0.0587 - val_mse: 0.0527\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0958 - mse: 0.0907 - val_loss: 0.0739 - val_mse: 0.0699\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0938 - mse: 0.0892 - val_loss: 0.0657 - val_mse: 0.0619\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0944 - mse: 0.0900 - val_loss: 0.0568 - val_mse: 0.0525\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0925 - mse: 0.0883 - val_loss: 0.0660 - val_mse: 0.0625\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0887 - val_loss: 0.0762 - val_mse: 0.0731\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0906 - val_loss: 0.0690 - val_mse: 0.0657\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0889 - val_loss: 0.0652 - val_mse: 0.0618\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0902 - val_loss: 0.0575 - val_mse: 0.0536\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0937 - mse: 0.0897 - val_loss: 0.0616 - val_mse: 0.0580\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0888 - val_loss: 0.0776 - val_mse: 0.0746\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0968 - mse: 0.0928 - val_loss: 0.0572 - val_mse: 0.0532\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0938 - mse: 0.0898 - val_loss: 0.0752 - val_mse: 0.0722\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0951 - mse: 0.0911 - val_loss: 0.0619 - val_mse: 0.0570\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0940 - mse: 0.0899 - val_loss: 0.0713 - val_mse: 0.0681\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0953 - mse: 0.0913 - val_loss: 0.0710 - val_mse: 0.0678\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0901 - val_loss: 0.0597 - val_mse: 0.0560\n",
      "Epoch 24: early stopping\n",
      "{'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8E20>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 0.2893 - mse: 0.2751 - val_loss: 0.0727 - val_mse: 0.0589\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0856 - val_loss: 0.0731 - val_mse: 0.0601\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0971 - mse: 0.0842 - val_loss: 0.0611 - val_mse: 0.0485\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0931 - mse: 0.0806 - val_loss: 0.0632 - val_mse: 0.0508\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0894 - mse: 0.0770 - val_loss: 0.0563 - val_mse: 0.0439\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0717 - val_loss: 0.0527 - val_mse: 0.0398\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0775 - mse: 0.0642 - val_loss: 0.0540 - val_mse: 0.0403\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0700 - mse: 0.0557 - val_loss: 0.0482 - val_mse: 0.0333\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0467 - val_loss: 0.0430 - val_mse: 0.0267\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0401 - val_loss: 0.0420 - val_mse: 0.0244\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0356 - val_loss: 0.0484 - val_mse: 0.0298\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0314 - val_loss: 0.0407 - val_mse: 0.0213\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0295 - val_loss: 0.0412 - val_mse: 0.0215\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0270 - val_loss: 0.0496 - val_mse: 0.0297\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0272 - val_loss: 0.0397 - val_mse: 0.0198\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0263 - val_loss: 0.0399 - val_mse: 0.0201\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0265 - val_loss: 0.0393 - val_mse: 0.0194\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0255 - val_loss: 0.0394 - val_mse: 0.0197\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0243 - val_loss: 0.0382 - val_mse: 0.0186\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0247 - val_loss: 0.0381 - val_mse: 0.0185\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0247 - val_loss: 0.0377 - val_mse: 0.0180\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0237 - val_loss: 0.0397 - val_mse: 0.0201\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0237 - val_loss: 0.0374 - val_mse: 0.0178\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0232 - val_loss: 0.0394 - val_mse: 0.0198\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0233 - val_loss: 0.0368 - val_mse: 0.0172\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0227 - val_loss: 0.0382 - val_mse: 0.0187\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0232 - val_loss: 0.0364 - val_mse: 0.0168\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0218 - val_loss: 0.0363 - val_mse: 0.0167\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0218 - val_loss: 0.0380 - val_mse: 0.0184\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0222 - val_loss: 0.0400 - val_mse: 0.0205\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0219 - val_loss: 0.0360 - val_mse: 0.0164\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0216 - val_loss: 0.0377 - val_mse: 0.0181\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0212 - val_loss: 0.0358 - val_mse: 0.0161\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0205 - val_loss: 0.0373 - val_mse: 0.0176\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0206 - val_loss: 0.0356 - val_mse: 0.0159\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0211 - val_loss: 0.0357 - val_mse: 0.0159\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0209 - val_loss: 0.0353 - val_mse: 0.0155\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0403 - mse: 0.0205 - val_loss: 0.0394 - val_mse: 0.0196\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0207 - val_loss: 0.0351 - val_mse: 0.0152\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0204 - val_loss: 0.0351 - val_mse: 0.0152\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0201 - val_loss: 0.0351 - val_mse: 0.0151\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0398 - mse: 0.0199 - val_loss: 0.0354 - val_mse: 0.0155\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0202 - val_loss: 0.0355 - val_mse: 0.0155\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0196 - val_loss: 0.0359 - val_mse: 0.0161\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0197 - val_loss: 0.0345 - val_mse: 0.0147\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0195 - val_loss: 0.0353 - val_mse: 0.0153\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0192 - val_loss: 0.0349 - val_mse: 0.0148\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0398 - mse: 0.0199 - val_loss: 0.0376 - val_mse: 0.0175\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0190 - val_loss: 0.0346 - val_mse: 0.0144\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0194 - val_loss: 0.0366 - val_mse: 0.0164\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0193 - val_loss: 0.0347 - val_mse: 0.0145\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0192 - val_loss: 0.0346 - val_mse: 0.0144\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0191 - val_loss: 0.0382 - val_mse: 0.0179\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0188 - val_loss: 0.0347 - val_mse: 0.0143\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0189 - val_loss: 0.0343 - val_mse: 0.0140\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0188 - val_loss: 0.0346 - val_mse: 0.0143\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0194 - val_loss: 0.0355 - val_mse: 0.0153\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0188 - val_loss: 0.0410 - val_mse: 0.0207\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0187 - val_loss: 0.0348 - val_mse: 0.0144\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0191 - val_loss: 0.0359 - val_mse: 0.0155\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0188 - val_loss: 0.0357 - val_mse: 0.0153\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0186 - val_loss: 0.0342 - val_mse: 0.0137\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0184 - val_loss: 0.0376 - val_mse: 0.0171\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0184 - val_loss: 0.0343 - val_mse: 0.0138\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0184 - val_loss: 0.0341 - val_mse: 0.0135\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0179 - val_loss: 0.0351 - val_mse: 0.0145\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0179 - val_loss: 0.0397 - val_mse: 0.0190\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0183 - val_loss: 0.0340 - val_mse: 0.0134\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0179 - val_loss: 0.0348 - val_mse: 0.0142\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0179 - val_loss: 0.0342 - val_mse: 0.0135\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0175 - val_loss: 0.0340 - val_mse: 0.0133\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0182 - val_loss: 0.0384 - val_mse: 0.0176\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0179 - val_loss: 0.0344 - val_mse: 0.0137\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0175 - val_loss: 0.0341 - val_mse: 0.0134\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0178 - val_loss: 0.0406 - val_mse: 0.0200\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0187 - val_loss: 0.0341 - val_mse: 0.0134\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0175 - val_loss: 0.0345 - val_mse: 0.0137\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0178 - val_loss: 0.0341 - val_mse: 0.0133\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0179 - val_loss: 0.0340 - val_mse: 0.0132\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0175 - val_loss: 0.0358 - val_mse: 0.0150\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0175 - val_loss: 0.0402 - val_mse: 0.0194\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0173 - val_loss: 0.0343 - val_mse: 0.0135\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0174 - val_loss: 0.0355 - val_mse: 0.0147\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0176 - val_loss: 0.0359 - val_mse: 0.0151\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0176 - val_loss: 0.0345 - val_mse: 0.0136\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0179 - val_loss: 0.0357 - val_mse: 0.0148\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0175 - val_loss: 0.0338 - val_mse: 0.0130\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0177 - val_loss: 0.0339 - val_mse: 0.0130\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0169 - val_loss: 0.0340 - val_mse: 0.0130\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0178 - val_loss: 0.0372 - val_mse: 0.0164\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0177 - val_loss: 0.0397 - val_mse: 0.0188\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0174 - val_loss: 0.0341 - val_mse: 0.0132\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0177 - val_loss: 0.0380 - val_mse: 0.0170\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0175 - val_loss: 0.0342 - val_mse: 0.0133\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0178 - val_loss: 0.0338 - val_mse: 0.0129\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0172 - val_loss: 0.0348 - val_mse: 0.0139\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0172 - val_loss: 0.0353 - val_mse: 0.0144\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0173 - val_loss: 0.0337 - val_mse: 0.0129\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0174 - val_loss: 0.0339 - val_mse: 0.0129\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0169 - val_loss: 0.0361 - val_mse: 0.0153\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0169 - val_loss: 0.0387 - val_mse: 0.0179\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0178 - val_loss: 0.0337 - val_mse: 0.0128\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0174 - val_loss: 0.0336 - val_mse: 0.0128\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0175 - val_loss: 0.0352 - val_mse: 0.0143\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0172 - val_loss: 0.0339 - val_mse: 0.0130\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0173 - val_loss: 0.0349 - val_mse: 0.0139\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0169 - val_loss: 0.0348 - val_mse: 0.0139\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0166 - val_loss: 0.0345 - val_mse: 0.0136\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0178 - val_loss: 0.0343 - val_mse: 0.0134\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0170 - val_loss: 0.0339 - val_mse: 0.0129\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0171 - val_loss: 0.0339 - val_mse: 0.0129\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0172 - val_loss: 0.0337 - val_mse: 0.0128\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0172 - val_loss: 0.0337 - val_mse: 0.0129\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0171 - val_loss: 0.0342 - val_mse: 0.0133\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0170 - val_loss: 0.0386 - val_mse: 0.0177\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0169 - val_loss: 0.0343 - val_mse: 0.0134\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0170 - val_loss: 0.0354 - val_mse: 0.0146\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0168 - val_loss: 0.0397 - val_mse: 0.0189\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0174 - val_loss: 0.0340 - val_mse: 0.0132\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0166 - val_loss: 0.0355 - val_mse: 0.0147\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0171 - val_loss: 0.0340 - val_mse: 0.0131\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0168 - val_loss: 0.0335 - val_mse: 0.0126\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0166 - val_loss: 0.0334 - val_mse: 0.0126\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0170 - val_loss: 0.0333 - val_mse: 0.0126\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0171 - val_loss: 0.0396 - val_mse: 0.0188\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0168 - val_loss: 0.0340 - val_mse: 0.0131\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0165 - val_loss: 0.0350 - val_mse: 0.0142\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0167 - val_loss: 0.0343 - val_mse: 0.0135\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0381 - mse: 0.0173 - val_loss: 0.0349 - val_mse: 0.0141\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0167 - val_loss: 0.0388 - val_mse: 0.0180\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0167 - val_loss: 0.0341 - val_mse: 0.0132\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0169 - val_loss: 0.0335 - val_mse: 0.0127\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0169 - val_loss: 0.0333 - val_mse: 0.0125\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0168 - val_loss: 0.0345 - val_mse: 0.0138\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0173 - val_loss: 0.0339 - val_mse: 0.0130\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0167 - val_loss: 0.0336 - val_mse: 0.0129\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0169 - val_loss: 0.0339 - val_mse: 0.0130\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0171 - val_loss: 0.0340 - val_mse: 0.0132\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0166 - val_loss: 0.0376 - val_mse: 0.0169\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0171 - val_loss: 0.0356 - val_mse: 0.0149\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0170 - val_loss: 0.0343 - val_mse: 0.0135\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0166 - val_loss: 0.0334 - val_mse: 0.0127\n",
      "Epoch 142: early stopping\n",
      "{'regularizer': <keras.regularizers.L2 object at 0x000001AB334A85B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1277 - mse: 0.1263 - val_loss: 0.0551 - val_mse: 0.0537\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0941 - mse: 0.0928 - val_loss: 0.0658 - val_mse: 0.0644\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0903 - val_loss: 0.0635 - val_mse: 0.0621\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0893 - mse: 0.0880 - val_loss: 0.0518 - val_mse: 0.0504\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0871 - mse: 0.0857 - val_loss: 0.0509 - val_mse: 0.0495\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0849 - mse: 0.0835 - val_loss: 0.0505 - val_mse: 0.0490\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0821 - mse: 0.0807 - val_loss: 0.0467 - val_mse: 0.0451\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0735 - val_loss: 0.0451 - val_mse: 0.0435\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0666 - val_loss: 0.0368 - val_mse: 0.0350\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0524 - val_loss: 0.0312 - val_mse: 0.0292\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0412 - val_loss: 0.0266 - val_mse: 0.0244\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0340 - val_loss: 0.0250 - val_mse: 0.0226\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0305 - val_loss: 0.0229 - val_mse: 0.0204\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0312 - mse: 0.0287 - val_loss: 0.0224 - val_mse: 0.0198\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0268 - val_loss: 0.0218 - val_mse: 0.0192\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0260 - val_loss: 0.0339 - val_mse: 0.0313\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0251 - val_loss: 0.0203 - val_mse: 0.0177\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0238 - val_loss: 0.0199 - val_mse: 0.0172\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0233 - val_loss: 0.0199 - val_mse: 0.0172\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0223 - val_loss: 0.0204 - val_mse: 0.0176\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0224 - val_loss: 0.0185 - val_mse: 0.0158\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0213 - val_loss: 0.0208 - val_mse: 0.0180\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0243 - mse: 0.0215 - val_loss: 0.0178 - val_mse: 0.0150\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0206 - val_loss: 0.0198 - val_mse: 0.0169\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0233 - mse: 0.0205 - val_loss: 0.0171 - val_mse: 0.0143\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0201 - val_loss: 0.0212 - val_mse: 0.0183\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0192 - val_loss: 0.0167 - val_mse: 0.0138\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0186 - val_loss: 0.0179 - val_mse: 0.0150\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0180 - val_loss: 0.0179 - val_mse: 0.0149\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0178 - val_loss: 0.0160 - val_mse: 0.0130\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0179 - val_loss: 0.0237 - val_mse: 0.0207\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0171 - val_loss: 0.0159 - val_mse: 0.0129\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0168 - val_loss: 0.0155 - val_mse: 0.0124\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0165 - val_loss: 0.0168 - val_mse: 0.0137\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0161 - val_loss: 0.0178 - val_mse: 0.0147\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0157 - val_loss: 0.0171 - val_mse: 0.0140\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0117\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0150 - val_loss: 0.0152 - val_mse: 0.0120\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0112\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0143 - val_loss: 0.0148 - val_mse: 0.0115\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0109\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0121\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0117\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0130 - val_loss: 0.0165 - val_mse: 0.0131\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0130 - val_loss: 0.0144 - val_mse: 0.0110\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0127 - val_loss: 0.0138 - val_mse: 0.0104\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0121 - val_loss: 0.0153 - val_mse: 0.0118\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0122 - val_loss: 0.0135 - val_mse: 0.0100\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0121 - val_loss: 0.0140 - val_mse: 0.0105\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0116 - val_loss: 0.0136 - val_mse: 0.0100\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0112 - val_loss: 0.0140 - val_mse: 0.0105\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0112 - val_loss: 0.0131 - val_mse: 0.0095\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0107 - val_loss: 0.0154 - val_mse: 0.0118\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0109 - val_loss: 0.0132 - val_mse: 0.0095\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0105 - val_loss: 0.0129 - val_mse: 0.0092\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0108 - val_loss: 0.0158 - val_mse: 0.0121\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0102 - val_loss: 0.0129 - val_mse: 0.0092\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0102 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0097 - val_loss: 0.0145 - val_mse: 0.0107\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0099 - val_loss: 0.0129 - val_mse: 0.0091\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0097 - val_loss: 0.0148 - val_mse: 0.0109\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0099 - val_loss: 0.0145 - val_mse: 0.0106\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0093 - val_loss: 0.0122 - val_mse: 0.0083\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0089 - val_loss: 0.0155 - val_mse: 0.0116\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0089 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0088 - val_loss: 0.0122 - val_mse: 0.0082\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0088 - val_loss: 0.0135 - val_mse: 0.0095\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0088 - val_loss: 0.0117 - val_mse: 0.0077\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0088 - val_loss: 0.0119 - val_mse: 0.0078\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0083 - val_loss: 0.0119 - val_mse: 0.0079\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0081 - val_loss: 0.0116 - val_mse: 0.0076\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0082 - val_loss: 0.0118 - val_mse: 0.0076\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0077 - val_loss: 0.0119 - val_mse: 0.0078\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0078 - val_loss: 0.0120 - val_mse: 0.0078\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0078 - val_loss: 0.0121 - val_mse: 0.0079\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0075 - val_loss: 0.0119 - val_mse: 0.0077\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0076 - val_loss: 0.0113 - val_mse: 0.0071\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0111 - val_mse: 0.0069\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0114 - val_mse: 0.0071\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0109 - val_mse: 0.0065\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0108 - val_mse: 0.0064\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0116 - val_mse: 0.0072\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0106 - val_mse: 0.0062\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0108 - val_mse: 0.0064\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0112 - val_mse: 0.0068\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0104 - val_mse: 0.0060\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0110 - val_mse: 0.0066\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0059\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0063\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0061 - val_loss: 0.0124 - val_mse: 0.0079\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0057\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0060 - val_loss: 0.0102 - val_mse: 0.0056\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0058\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0109 - val_mse: 0.0063\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0056 - val_loss: 0.0107 - val_mse: 0.0061\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0062 - val_loss: 0.0110 - val_mse: 0.0065\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0114 - val_mse: 0.0068\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0059 - val_loss: 0.0106 - val_mse: 0.0060\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0057 - val_loss: 0.0103 - val_mse: 0.0057\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0057 - val_loss: 0.0102 - val_mse: 0.0056\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0056 - val_loss: 0.0106 - val_mse: 0.0060\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0056 - val_loss: 0.0114 - val_mse: 0.0068\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0056 - val_loss: 0.0103 - val_mse: 0.0056\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0058 - val_loss: 0.0110 - val_mse: 0.0063\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0054 - val_loss: 0.0101 - val_mse: 0.0054\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0056 - val_loss: 0.0098 - val_mse: 0.0051\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0056 - val_loss: 0.0099 - val_mse: 0.0052\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0055 - val_loss: 0.0099 - val_mse: 0.0052\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0053 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0054 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0055 - val_loss: 0.0098 - val_mse: 0.0051\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0099 - val_mse: 0.0053\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0118 - val_mse: 0.0071\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0054 - val_loss: 0.0104 - val_mse: 0.0057\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0054 - val_loss: 0.0104 - val_mse: 0.0057\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0052 - val_loss: 0.0111 - val_mse: 0.0064\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0123 - val_mse: 0.0076\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0052 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0052 - val_loss: 0.0099 - val_mse: 0.0052\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0106 - val_mse: 0.0058\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0051 - val_loss: 0.0116 - val_mse: 0.0069\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0051 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0103 - val_mse: 0.0056\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0051 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0048 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0108 - val_mse: 0.0060\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0049 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0048 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0049 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0050 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0048 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0047 - val_loss: 0.0097 - val_mse: 0.0049\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0048 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0048 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0105 - val_mse: 0.0057\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0048 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0103 - val_mse: 0.0055\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0117 - val_mse: 0.0069\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0047 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0127 - val_mse: 0.0079\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0128 - val_mse: 0.0080\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0044 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0112 - val_mse: 0.0064\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0046 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0039\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0087 - val_mse: 0.0039\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0141 - val_mse: 0.0093\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0112 - val_mse: 0.0063\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0043 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0046 - val_loss: 0.0126 - val_mse: 0.0077\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0039\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0039\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0044 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0042 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0045 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0042 - val_loss: 0.0116 - val_mse: 0.0067\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0049\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0043 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0042 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0041 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0043 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0043 - val_loss: 0.0109 - val_mse: 0.0060\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0044 - val_loss: 0.0108 - val_mse: 0.0059\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0042 - val_loss: 0.0105 - val_mse: 0.0056\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0039 - val_loss: 0.0085 - val_mse: 0.0037\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0120 - val_mse: 0.0071\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0041 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0084 - val_mse: 0.0036\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0041 - val_loss: 0.0095 - val_mse: 0.0046\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0113 - val_mse: 0.0064\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0044 - val_loss: 0.0085 - val_mse: 0.0037\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0039 - val_loss: 0.0113 - val_mse: 0.0064\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0039 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0042 - val_loss: 0.0084 - val_mse: 0.0035\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0086 - val_mse: 0.0037\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 247: early stopping\n",
      "{'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8280>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.5785 - mse: 0.3040 - val_loss: 0.2210 - val_mse: 0.0521\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1944 - mse: 0.0885 - val_loss: 0.1174 - val_mse: 0.0578\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.0891 - val_loss: 0.0802 - val_mse: 0.0520\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1110 - mse: 0.0894 - val_loss: 0.0749 - val_mse: 0.0571\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1088 - mse: 0.0907 - val_loss: 0.0774 - val_mse: 0.0612\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1065 - mse: 0.0892 - val_loss: 0.0793 - val_mse: 0.0638\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1063 - mse: 0.0895 - val_loss: 0.0858 - val_mse: 0.0715\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1061 - mse: 0.0895 - val_loss: 0.0694 - val_mse: 0.0526\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0899 - val_loss: 0.0696 - val_mse: 0.0532\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1044 - mse: 0.0880 - val_loss: 0.0785 - val_mse: 0.0639\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1053 - mse: 0.0889 - val_loss: 0.0733 - val_mse: 0.0578\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1056 - mse: 0.0893 - val_loss: 0.0698 - val_mse: 0.0535\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0908 - val_loss: 0.0736 - val_mse: 0.0582\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1046 - mse: 0.0883 - val_loss: 0.0692 - val_mse: 0.0525\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1081 - mse: 0.0916 - val_loss: 0.0875 - val_mse: 0.0738\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0901 - val_loss: 0.0691 - val_mse: 0.0522\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.0912 - val_loss: 0.0691 - val_mse: 0.0524\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.0888 - val_loss: 0.0696 - val_mse: 0.0521\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1071 - mse: 0.0908 - val_loss: 0.0691 - val_mse: 0.0521\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1050 - mse: 0.0886 - val_loss: 0.0818 - val_mse: 0.0675\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0914 - val_loss: 0.0703 - val_mse: 0.0525\n",
      "Epoch 21: early stopping\n",
      "{'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8DC0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1775 - mse: 0.1470 - val_loss: 0.0822 - val_mse: 0.0530\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1168 - mse: 0.0887 - val_loss: 0.0789 - val_mse: 0.0519\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.0911 - val_loss: 0.0831 - val_mse: 0.0579\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1119 - mse: 0.0877 - val_loss: 0.0835 - val_mse: 0.0601\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.0875 - val_loss: 0.0730 - val_mse: 0.0508\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1055 - mse: 0.0838 - val_loss: 0.0702 - val_mse: 0.0489\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1032 - mse: 0.0821 - val_loss: 0.0671 - val_mse: 0.0461\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.0792 - val_loss: 0.0654 - val_mse: 0.0443\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0955 - mse: 0.0743 - val_loss: 0.0718 - val_mse: 0.0504\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0927 - mse: 0.0707 - val_loss: 0.0619 - val_mse: 0.0392\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0879 - mse: 0.0646 - val_loss: 0.0729 - val_mse: 0.0486\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0808 - mse: 0.0553 - val_loss: 0.0577 - val_mse: 0.0309\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0455 - val_loss: 0.0542 - val_mse: 0.0250\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0376 - val_loss: 0.0526 - val_mse: 0.0213\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0650 - mse: 0.0329 - val_loss: 0.0520 - val_mse: 0.0192\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0285 - val_loss: 0.0524 - val_mse: 0.0190\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0272 - val_loss: 0.0538 - val_mse: 0.0203\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0266 - val_loss: 0.0511 - val_mse: 0.0176\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0257 - val_loss: 0.0505 - val_mse: 0.0169\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0248 - val_loss: 0.0517 - val_mse: 0.0182\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0247 - val_loss: 0.0544 - val_mse: 0.0212\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0231 - val_loss: 0.0491 - val_mse: 0.0161\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0242 - val_loss: 0.0487 - val_mse: 0.0156\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0226 - val_loss: 0.0517 - val_mse: 0.0187\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0227 - val_loss: 0.0494 - val_mse: 0.0166\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0219 - val_loss: 0.0480 - val_mse: 0.0152\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0219 - val_loss: 0.0487 - val_mse: 0.0160\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0217 - val_loss: 0.0473 - val_mse: 0.0146\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0544 - mse: 0.0215 - val_loss: 0.0488 - val_mse: 0.0162\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0209 - val_loss: 0.0483 - val_mse: 0.0155\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0208 - val_loss: 0.0484 - val_mse: 0.0157\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0206 - val_loss: 0.0471 - val_mse: 0.0143\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0221 - val_loss: 0.0489 - val_mse: 0.0161\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0202 - val_loss: 0.0468 - val_mse: 0.0143\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0213 - val_loss: 0.0500 - val_mse: 0.0174\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0203 - val_loss: 0.0490 - val_mse: 0.0164\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0205 - val_loss: 0.0468 - val_mse: 0.0144\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0203 - val_loss: 0.0471 - val_mse: 0.0148\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0204 - val_loss: 0.0490 - val_mse: 0.0166\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0201 - val_loss: 0.0469 - val_mse: 0.0144\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0530 - mse: 0.0203 - val_loss: 0.0513 - val_mse: 0.0189\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0204 - val_loss: 0.0467 - val_mse: 0.0143\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0204 - val_loss: 0.0480 - val_mse: 0.0155\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0205 - val_loss: 0.0468 - val_mse: 0.0142\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0207 - val_loss: 0.0486 - val_mse: 0.0162\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0209 - val_loss: 0.0533 - val_mse: 0.0207\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0210 - val_loss: 0.0468 - val_mse: 0.0143\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0200 - val_loss: 0.0493 - val_mse: 0.0171\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0201 - val_loss: 0.0476 - val_mse: 0.0153\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0203 - val_loss: 0.0470 - val_mse: 0.0147\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0204 - val_loss: 0.0467 - val_mse: 0.0143\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0529 - mse: 0.0207 - val_loss: 0.0466 - val_mse: 0.0144\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0201 - val_loss: 0.0462 - val_mse: 0.0140\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0523 - mse: 0.0202 - val_loss: 0.0463 - val_mse: 0.0141\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0213 - val_loss: 0.0465 - val_mse: 0.0142\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0205 - val_loss: 0.0510 - val_mse: 0.0189\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0206 - val_loss: 0.0459 - val_mse: 0.0139\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0202 - val_loss: 0.0462 - val_mse: 0.0143\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0213 - val_loss: 0.0458 - val_mse: 0.0139\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0208 - val_loss: 0.0477 - val_mse: 0.0159\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0204 - val_loss: 0.0484 - val_mse: 0.0168\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0209 - val_loss: 0.0520 - val_mse: 0.0204\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0206 - val_loss: 0.0521 - val_mse: 0.0206\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0204 - val_loss: 0.0466 - val_mse: 0.0150\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0207 - val_loss: 0.0463 - val_mse: 0.0146\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0200 - val_loss: 0.0503 - val_mse: 0.0188\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0204 - val_loss: 0.0509 - val_mse: 0.0196\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0206 - val_loss: 0.0457 - val_mse: 0.0143\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0205 - val_loss: 0.0454 - val_mse: 0.0140\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0207 - val_loss: 0.0468 - val_mse: 0.0153\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0203 - val_loss: 0.0452 - val_mse: 0.0139\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0207 - val_loss: 0.0453 - val_mse: 0.0142\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0206 - val_loss: 0.0450 - val_mse: 0.0140\n",
      "Epoch 73: early stopping\n",
      "{'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8220>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1054 - mse: 0.1018 - val_loss: 0.0536 - val_mse: 0.0501\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0864 - mse: 0.0828 - val_loss: 0.0518 - val_mse: 0.0482\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0812 - mse: 0.0775 - val_loss: 0.0531 - val_mse: 0.0493\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0710 - val_loss: 0.0416 - val_mse: 0.0376\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0599 - val_loss: 0.0474 - val_mse: 0.0432\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0483 - val_loss: 0.0311 - val_mse: 0.0266\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0391 - val_loss: 0.0258 - val_mse: 0.0209\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0322 - val_loss: 0.0245 - val_mse: 0.0194\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0335 - mse: 0.0283 - val_loss: 0.0298 - val_mse: 0.0245\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0269 - val_loss: 0.0246 - val_mse: 0.0192\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0268 - val_loss: 0.0242 - val_mse: 0.0189\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0253 - val_loss: 0.0236 - val_mse: 0.0181\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0239 - val_loss: 0.0294 - val_mse: 0.0239\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0238 - val_loss: 0.0222 - val_mse: 0.0168\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0227 - val_loss: 0.0221 - val_mse: 0.0166\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0231 - val_loss: 0.0212 - val_mse: 0.0157\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0219 - val_loss: 0.0210 - val_mse: 0.0155\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - mse: 0.0210 - val_loss: 0.0206 - val_mse: 0.0151\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0203 - val_loss: 0.0206 - val_mse: 0.0151\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0209 - val_loss: 0.0202 - val_mse: 0.0146\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0199 - val_loss: 0.0226 - val_mse: 0.0169\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0204 - val_loss: 0.0197 - val_mse: 0.0140\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0188 - val_loss: 0.0194 - val_mse: 0.0137\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0188 - val_loss: 0.0198 - val_mse: 0.0141\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0184 - val_loss: 0.0197 - val_mse: 0.0139\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0184 - val_loss: 0.0191 - val_mse: 0.0134\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0178 - val_loss: 0.0204 - val_mse: 0.0146\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 0.0172 - val_loss: 0.0202 - val_mse: 0.0144\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0230 - mse: 0.0171 - val_loss: 0.0185 - val_mse: 0.0126\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0172 - val_loss: 0.0181 - val_mse: 0.0122\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0164 - val_loss: 0.0188 - val_mse: 0.0129\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0159 - val_loss: 0.0200 - val_mse: 0.0140\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0162 - val_loss: 0.0180 - val_mse: 0.0120\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0150 - val_loss: 0.0191 - val_mse: 0.0131\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0157 - val_loss: 0.0176 - val_mse: 0.0116\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0150 - val_loss: 0.0176 - val_mse: 0.0116\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0149 - val_loss: 0.0184 - val_mse: 0.0123\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0148 - val_loss: 0.0190 - val_mse: 0.0129\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0208 - mse: 0.0147 - val_loss: 0.0178 - val_mse: 0.0116\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0141 - val_loss: 0.0201 - val_mse: 0.0140\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0144 - val_loss: 0.0183 - val_mse: 0.0121\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0201 - mse: 0.0139 - val_loss: 0.0193 - val_mse: 0.0131\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0140 - val_loss: 0.0172 - val_mse: 0.0109\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0195 - mse: 0.0133 - val_loss: 0.0170 - val_mse: 0.0108\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0199 - mse: 0.0137 - val_loss: 0.0170 - val_mse: 0.0107\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0134 - val_loss: 0.0172 - val_mse: 0.0109\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0128 - val_loss: 0.0171 - val_mse: 0.0108\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0134 - val_loss: 0.0175 - val_mse: 0.0112\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0129 - val_loss: 0.0181 - val_mse: 0.0118\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0129 - val_loss: 0.0196 - val_mse: 0.0133\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0125 - val_loss: 0.0167 - val_mse: 0.0103\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0123 - val_loss: 0.0168 - val_mse: 0.0104\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0122 - val_loss: 0.0195 - val_mse: 0.0131\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0126 - val_loss: 0.0167 - val_mse: 0.0103\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0125 - val_loss: 0.0218 - val_mse: 0.0153\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0196 - mse: 0.0132 - val_loss: 0.0166 - val_mse: 0.0101\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0120 - val_loss: 0.0167 - val_mse: 0.0102\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0119 - val_loss: 0.0170 - val_mse: 0.0105\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0186 - mse: 0.0121 - val_loss: 0.0174 - val_mse: 0.0109\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0124 - val_loss: 0.0166 - val_mse: 0.0101\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0190 - mse: 0.0125 - val_loss: 0.0164 - val_mse: 0.0099\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0120 - val_loss: 0.0182 - val_mse: 0.0116\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0117 - val_loss: 0.0163 - val_mse: 0.0098\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0116 - val_loss: 0.0178 - val_mse: 0.0113\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0118 - val_loss: 0.0170 - val_mse: 0.0105\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0117 - val_loss: 0.0163 - val_mse: 0.0097\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0111 - val_loss: 0.0167 - val_mse: 0.0102\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0116 - val_loss: 0.0163 - val_mse: 0.0097\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0113 - val_loss: 0.0163 - val_mse: 0.0097\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0111 - val_loss: 0.0178 - val_mse: 0.0112\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0110 - val_loss: 0.0163 - val_mse: 0.0097\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0110 - val_loss: 0.0167 - val_mse: 0.0101\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0112 - val_loss: 0.0177 - val_mse: 0.0112\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0115 - val_loss: 0.0198 - val_mse: 0.0132\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 0.0116 - val_loss: 0.0163 - val_mse: 0.0097\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 0.0112 - val_loss: 0.0168 - val_mse: 0.0102\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0115 - val_loss: 0.0161 - val_mse: 0.0095\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0112 - val_loss: 0.0180 - val_mse: 0.0114\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0113 - val_loss: 0.0250 - val_mse: 0.0184\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0113 - val_loss: 0.0166 - val_mse: 0.0099\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0115 - val_loss: 0.0178 - val_mse: 0.0111\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0108 - val_loss: 0.0195 - val_mse: 0.0129\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0109 - val_loss: 0.0163 - val_mse: 0.0096\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0107 - val_loss: 0.0156 - val_mse: 0.0090\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0109 - val_loss: 0.0159 - val_mse: 0.0093\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0107 - val_loss: 0.0165 - val_mse: 0.0098\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0174 - mse: 0.0107 - val_loss: 0.0179 - val_mse: 0.0112\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0104 - val_loss: 0.0157 - val_mse: 0.0090\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 0.0106 - val_loss: 0.0157 - val_mse: 0.0090\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0103 - val_loss: 0.0200 - val_mse: 0.0133\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0108 - val_loss: 0.0156 - val_mse: 0.0088\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0107 - val_loss: 0.0184 - val_mse: 0.0116\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0109 - val_loss: 0.0165 - val_mse: 0.0097\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0108 - val_loss: 0.0156 - val_mse: 0.0088\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0102 - val_loss: 0.0159 - val_mse: 0.0091\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0107 - val_loss: 0.0162 - val_mse: 0.0095\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0103 - val_loss: 0.0157 - val_mse: 0.0090\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0104 - val_loss: 0.0156 - val_mse: 0.0088\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0175 - mse: 0.0108 - val_loss: 0.0164 - val_mse: 0.0096\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0104 - val_loss: 0.0154 - val_mse: 0.0086\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0101 - val_loss: 0.0155 - val_mse: 0.0087\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0170 - mse: 0.0102 - val_loss: 0.0154 - val_mse: 0.0086\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0105 - val_loss: 0.0161 - val_mse: 0.0093\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0102 - val_loss: 0.0152 - val_mse: 0.0083\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0098 - val_loss: 0.0154 - val_mse: 0.0086\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0098 - val_loss: 0.0151 - val_mse: 0.0082\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0098 - val_loss: 0.0151 - val_mse: 0.0082\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0095 - val_loss: 0.0163 - val_mse: 0.0094\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0099 - val_loss: 0.0172 - val_mse: 0.0103\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0098 - val_loss: 0.0153 - val_mse: 0.0084\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0097 - val_loss: 0.0157 - val_mse: 0.0088\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0093 - val_loss: 0.0150 - val_mse: 0.0080\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0095 - val_loss: 0.0151 - val_mse: 0.0081\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0089 - val_loss: 0.0192 - val_mse: 0.0122\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0091 - val_loss: 0.0163 - val_mse: 0.0093\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0164 - mse: 0.0094 - val_loss: 0.0153 - val_mse: 0.0083\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0088 - val_loss: 0.0158 - val_mse: 0.0087\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0163 - mse: 0.0092 - val_loss: 0.0152 - val_mse: 0.0082\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0089 - val_loss: 0.0153 - val_mse: 0.0082\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0091 - val_loss: 0.0165 - val_mse: 0.0095\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0088 - val_loss: 0.0151 - val_mse: 0.0080\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0086 - val_loss: 0.0150 - val_mse: 0.0079\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0091 - val_loss: 0.0147 - val_mse: 0.0076\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0087 - val_loss: 0.0154 - val_mse: 0.0083\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0083 - val_loss: 0.0155 - val_mse: 0.0084\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 0.0084 - val_loss: 0.0187 - val_mse: 0.0116\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0083\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0082 - val_loss: 0.0149 - val_mse: 0.0077\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0077 - val_loss: 0.0146 - val_mse: 0.0074\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0083 - val_loss: 0.0160 - val_mse: 0.0088\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0080 - val_loss: 0.0183 - val_mse: 0.0111\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 0.0084 - val_loss: 0.0146 - val_mse: 0.0073\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0080 - val_loss: 0.0154 - val_mse: 0.0081\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0081 - val_loss: 0.0154 - val_mse: 0.0081\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0077 - val_loss: 0.0180 - val_mse: 0.0107\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0076 - val_loss: 0.0148 - val_mse: 0.0075\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0080 - val_loss: 0.0161 - val_mse: 0.0088\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0077 - val_loss: 0.0147 - val_mse: 0.0074\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0078 - val_loss: 0.0145 - val_mse: 0.0071\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0076 - val_loss: 0.0142 - val_mse: 0.0069\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0075 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0073 - val_loss: 0.0154 - val_mse: 0.0080\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0074 - val_loss: 0.0164 - val_mse: 0.0090\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0072 - val_loss: 0.0156 - val_mse: 0.0082\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 0.0071 - val_loss: 0.0167 - val_mse: 0.0092\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0072 - val_loss: 0.0140 - val_mse: 0.0065\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0073 - val_loss: 0.0140 - val_mse: 0.0066\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0068 - val_loss: 0.0171 - val_mse: 0.0096\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0071 - val_loss: 0.0139 - val_mse: 0.0064\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0067 - val_loss: 0.0142 - val_mse: 0.0066\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0070 - val_loss: 0.0156 - val_mse: 0.0081\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0070 - val_loss: 0.0146 - val_mse: 0.0071\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0067 - val_loss: 0.0158 - val_mse: 0.0082\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0067 - val_loss: 0.0147 - val_mse: 0.0071\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0065 - val_loss: 0.0156 - val_mse: 0.0081\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0068 - val_loss: 0.0137 - val_mse: 0.0062\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0067 - val_loss: 0.0137 - val_mse: 0.0061\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0063 - val_loss: 0.0155 - val_mse: 0.0079\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0067 - val_loss: 0.0177 - val_mse: 0.0101\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 0.0065 - val_loss: 0.0136 - val_mse: 0.0060\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 0.0061 - val_loss: 0.0136 - val_mse: 0.0060\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0063 - val_loss: 0.0151 - val_mse: 0.0075\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0065 - val_loss: 0.0152 - val_mse: 0.0076\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0061 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0063 - val_loss: 0.0138 - val_mse: 0.0062\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0068 - val_loss: 0.0144 - val_mse: 0.0068\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0059 - val_loss: 0.0141 - val_mse: 0.0064\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0063 - val_loss: 0.0137 - val_mse: 0.0060\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0063 - val_loss: 0.0166 - val_mse: 0.0089\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0063 - val_loss: 0.0133 - val_mse: 0.0057\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0134 - val_mse: 0.0057\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0059 - val_loss: 0.0142 - val_mse: 0.0065\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0062 - val_loss: 0.0137 - val_mse: 0.0060\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0061 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0056 - val_loss: 0.0135 - val_mse: 0.0058\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0059 - val_loss: 0.0161 - val_mse: 0.0084\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0059 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0134 - val_mse: 0.0057\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0057 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0061 - val_loss: 0.0142 - val_mse: 0.0065\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0138 - val_mse: 0.0062\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0061 - val_loss: 0.0136 - val_mse: 0.0059\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0059 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0134 - val_mse: 0.0057\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0057 - val_loss: 0.0137 - val_mse: 0.0060\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0057 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0132 - val_mse: 0.0055\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0056 - val_loss: 0.0135 - val_mse: 0.0058\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0058 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0057 - val_loss: 0.0129 - val_mse: 0.0052\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0056 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0143 - val_mse: 0.0066\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0139 - val_mse: 0.0062\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0132 - val_mse: 0.0054\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0144 - val_mse: 0.0067\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0056 - val_loss: 0.0128 - val_mse: 0.0051\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0053 - val_loss: 0.0136 - val_mse: 0.0059\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0053 - val_loss: 0.0138 - val_mse: 0.0060\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0056 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0128 - val_mse: 0.0051\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0051 - val_loss: 0.0129 - val_mse: 0.0052\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0055 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0127 - val_mse: 0.0050\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0050\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0053 - val_loss: 0.0127 - val_mse: 0.0049\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0054 - val_loss: 0.0136 - val_mse: 0.0059\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0053 - val_loss: 0.0134 - val_mse: 0.0057\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0052 - val_loss: 0.0141 - val_mse: 0.0064\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0053 - val_loss: 0.0126 - val_mse: 0.0049\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0049 - val_loss: 0.0132 - val_mse: 0.0054\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0053 - val_loss: 0.0139 - val_mse: 0.0062\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0126 - val_mse: 0.0049\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0053 - val_loss: 0.0135 - val_mse: 0.0058\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0057 - val_loss: 0.0133 - val_mse: 0.0056\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0052 - val_loss: 0.0132 - val_mse: 0.0054\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0053 - val_loss: 0.0128 - val_mse: 0.0051\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0144 - val_mse: 0.0067\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0126 - val_mse: 0.0048\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0135 - val_mse: 0.0057\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0049 - val_loss: 0.0155 - val_mse: 0.0077\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0156 - val_mse: 0.0079\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0057 - val_loss: 0.0142 - val_mse: 0.0065\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0136 - val_mse: 0.0059\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0130 - mse: 0.0053 - val_loss: 0.0125 - val_mse: 0.0048\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0125 - val_mse: 0.0048\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0050 - val_loss: 0.0124 - val_mse: 0.0047\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0126 - val_mse: 0.0049\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0049\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0050 - val_loss: 0.0124 - val_mse: 0.0047\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0124 - val_mse: 0.0046\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0050 - val_loss: 0.0133 - val_mse: 0.0055\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0048 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0050 - val_loss: 0.0129 - val_mse: 0.0052\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0051 - val_loss: 0.0124 - val_mse: 0.0046\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0054 - val_loss: 0.0124 - val_mse: 0.0047\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0051 - val_loss: 0.0129 - val_mse: 0.0051\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 0.0054 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0124 - val_mse: 0.0047\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0049 - val_loss: 0.0123 - val_mse: 0.0046\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0048 - val_loss: 0.0147 - val_mse: 0.0069\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0049 - val_loss: 0.0124 - val_mse: 0.0047\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0050 - val_loss: 0.0123 - val_mse: 0.0045\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0126 - val_mse: 0.0048\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0130 - val_mse: 0.0052\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0123 - val_mse: 0.0046\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0152 - val_mse: 0.0074\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0129 - mse: 0.0052 - val_loss: 0.0124 - val_mse: 0.0046\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0049 - val_loss: 0.0122 - val_mse: 0.0045\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0050 - val_loss: 0.0137 - val_mse: 0.0059\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0050 - val_loss: 0.0123 - val_mse: 0.0046\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0123 - val_mse: 0.0045\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0048 - val_loss: 0.0129 - val_mse: 0.0052\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0132 - val_mse: 0.0054\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0049 - val_loss: 0.0131 - val_mse: 0.0054\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0128 - val_mse: 0.0050\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0049 - val_loss: 0.0147 - val_mse: 0.0069\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0048 - val_loss: 0.0137 - val_mse: 0.0059\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0130 - val_mse: 0.0052\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0049 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0124 - val_mse: 0.0046\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0048 - val_loss: 0.0123 - val_mse: 0.0045\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0050 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0133 - val_mse: 0.0055\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0120 - val_mse: 0.0043\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0132 - val_mse: 0.0054\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0047 - val_loss: 0.0121 - val_mse: 0.0043\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0046 - val_loss: 0.0125 - val_mse: 0.0048\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0051 - val_loss: 0.0122 - val_mse: 0.0045\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0049 - val_loss: 0.0120 - val_mse: 0.0042\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0046 - val_loss: 0.0130 - val_mse: 0.0053\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0126 - val_mse: 0.0048\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0047 - val_loss: 0.0126 - val_mse: 0.0049\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0045 - val_loss: 0.0119 - val_mse: 0.0042\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0125 - val_mse: 0.0048\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0045 - val_loss: 0.0147 - val_mse: 0.0069\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0119 - val_mse: 0.0041\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0045 - val_loss: 0.0119 - val_mse: 0.0042\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0046 - val_loss: 0.0120 - val_mse: 0.0042\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0046 - val_loss: 0.0121 - val_mse: 0.0043\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0047 - val_loss: 0.0121 - val_mse: 0.0043\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0042 - val_loss: 0.0126 - val_mse: 0.0049\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0122 - val_mse: 0.0044\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0124 - mse: 0.0047 - val_loss: 0.0138 - val_mse: 0.0060\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0047 - val_loss: 0.0123 - val_mse: 0.0045\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0044 - val_loss: 0.0123 - val_mse: 0.0045\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0050 - val_loss: 0.0119 - val_mse: 0.0041\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0043 - val_loss: 0.0120 - val_mse: 0.0043\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0044 - val_loss: 0.0119 - val_mse: 0.0041\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0046 - val_loss: 0.0123 - val_mse: 0.0046\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0045 - val_loss: 0.0118 - val_mse: 0.0041\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0044 - val_loss: 0.0119 - val_mse: 0.0042\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0048 - val_loss: 0.0119 - val_mse: 0.0042\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0044 - val_loss: 0.0125 - val_mse: 0.0048\n",
      "Epoch 306: early stopping\n",
      "0 0.002859553787857294 302 {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE0A0>}\n",
      "1 0.00430274149402976 247 {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A85B0>}\n",
      "2 0.00478592561557889 306 {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8220>}\n",
      "3 0.012700912542641163 142 {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8E20>}\n",
      "4 0.01397428847849369 73 {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8DC0>}\n",
      "5 0.014613157138228416 108 {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE340>}\n",
      "6 0.05252036452293396 21 {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8280>}\n",
      "7 0.05394618213176727 22 {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE2B0>}\n",
      "8 0.05599679425358772 24 {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8730>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_dict = dict(regularizer=[regularizers.L1(0.01),\n",
    "                               regularizers.L1(0.001),\n",
    "                               regularizers.L1(0.0001),\n",
    "                               regularizers.L2(0.01),\n",
    "                               regularizers.L2(0.001),\n",
    "                               regularizers.L2(0.0001),\n",
    "                               regularizers.L1L2(l1=0.01, l2=0.01),\n",
    "                               regularizers.L1L2(l1=0.001, l2=0.001),\n",
    "                               regularizers.L1L2(l1=0.0001, l2=0.0001)])\n",
    "\n",
    "arch_eval_grid = grid_search(param_dict, X_train, y_train, X_val, y_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.002859553787857294 302 {'l1': 9.999999747378752e-05} {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE0A0>}\n",
      "1 0.00430274149402976 247 {'l2': 9.999999747378752e-05} {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A85B0>}\n",
      "2 0.00478592561557889 306 {'l1': 9.999999747378752e-05, 'l2': 9.999999747378752e-05} {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8220>}\n",
      "3 0.012700912542641163 142 {'l2': 0.0010000000474974513} {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8E20>}\n",
      "4 0.01397428847849369 73 {'l1': 0.0010000000474974513, 'l2': 0.0010000000474974513} {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8DC0>}\n",
      "5 0.014613157138228416 108 {'l1': 0.0010000000474974513} {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE340>}\n",
      "6 0.05252036452293396 21 {'l1': 0.009999999776482582, 'l2': 0.009999999776482582} {'regularizer': <keras.regularizers.L1L2 object at 0x000001AB334A8280>}\n",
      "7 0.05394618213176727 22 {'l1': 0.009999999776482582} {'regularizer': <keras.regularizers.L1 object at 0x000001AB2CABE2B0>}\n",
      "8 0.05599679425358772 24 {'l2': 0.009999999776482582} {'regularizer': <keras.regularizers.L2 object at 0x000001AB334A8730>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (param, model, history, final_val_mse, epoch) in enumerate(arch_eval_grid):\n",
    "    config = param[\"regularizer\"].get_config()\n",
    "    print(i, final_val_mse, epoch, config, param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate weight initialization best vs worst architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/80 [===============>..............] - ETA: 0s - loss: 0.0276 - mse: 0.0126"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1142 - mse: 0.1118 - val_loss: 0.1228 - val_mse: 0.1204\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0957 - mse: 0.0933 - val_loss: 0.0526 - val_mse: 0.0502\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0870 - mse: 0.0846 - val_loss: 0.0496 - val_mse: 0.0471\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0808 - mse: 0.0783 - val_loss: 0.0442 - val_mse: 0.0416\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0668 - val_loss: 0.0408 - val_mse: 0.0381\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0513 - val_loss: 0.0306 - val_mse: 0.0278\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0409 - val_loss: 0.0323 - val_mse: 0.0294\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0342 - val_loss: 0.0254 - val_mse: 0.0223\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0304 - val_loss: 0.0303 - val_mse: 0.0272\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0297 - val_loss: 0.0262 - val_mse: 0.0231\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0273 - val_loss: 0.0254 - val_mse: 0.0223\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0271 - val_loss: 0.0243 - val_mse: 0.0212\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0261 - val_loss: 0.0234 - val_mse: 0.0203\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0243 - val_loss: 0.0273 - val_mse: 0.0241\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0243 - val_loss: 0.0221 - val_mse: 0.0190\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0237 - val_loss: 0.0217 - val_mse: 0.0186\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0226 - val_loss: 0.0224 - val_mse: 0.0192\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0225 - val_loss: 0.0209 - val_mse: 0.0178\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0214 - val_loss: 0.0271 - val_mse: 0.0239\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0212 - val_loss: 0.0235 - val_mse: 0.0203\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0213 - val_loss: 0.0200 - val_mse: 0.0169\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0215 - val_loss: 0.0212 - val_mse: 0.0180\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0204 - val_loss: 0.0197 - val_mse: 0.0165\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0203 - val_loss: 0.0221 - val_mse: 0.0190\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0193 - val_loss: 0.0275 - val_mse: 0.0244\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0191 - val_loss: 0.0215 - val_mse: 0.0183\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0191 - val_loss: 0.0216 - val_mse: 0.0185\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0223 - mse: 0.0191 - val_loss: 0.0187 - val_mse: 0.0156\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0180 - val_loss: 0.0213 - val_mse: 0.0181\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0174 - val_loss: 0.0181 - val_mse: 0.0150\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0166 - val_loss: 0.0182 - val_mse: 0.0151\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0172 - val_loss: 0.0249 - val_mse: 0.0217\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0167 - val_loss: 0.0174 - val_mse: 0.0142\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0163 - val_loss: 0.0178 - val_mse: 0.0146\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0156 - val_loss: 0.0173 - val_mse: 0.0141\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0157 - val_loss: 0.0226 - val_mse: 0.0194\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0157 - val_loss: 0.0167 - val_mse: 0.0135\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0151 - val_loss: 0.0209 - val_mse: 0.0177\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0151 - val_loss: 0.0171 - val_mse: 0.0138\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0149 - val_loss: 0.0162 - val_mse: 0.0130\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0144 - val_loss: 0.0165 - val_mse: 0.0132\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0140 - val_loss: 0.0159 - val_mse: 0.0126\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0138 - val_loss: 0.0173 - val_mse: 0.0140\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0142 - val_loss: 0.0155 - val_mse: 0.0122\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0117\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0180 - val_mse: 0.0147\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0128 - val_loss: 0.0148 - val_mse: 0.0114\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0127 - val_loss: 0.0148 - val_mse: 0.0115\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0123 - val_loss: 0.0145 - val_mse: 0.0111\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0115 - val_loss: 0.0153 - val_mse: 0.0119\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0125 - val_loss: 0.0146 - val_mse: 0.0112\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0122 - val_loss: 0.0150 - val_mse: 0.0116\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0117 - val_loss: 0.0155 - val_mse: 0.0121\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0116 - val_loss: 0.0141 - val_mse: 0.0106\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0111 - val_loss: 0.0140 - val_mse: 0.0105\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0113 - val_loss: 0.0147 - val_mse: 0.0113\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0108 - val_loss: 0.0135 - val_mse: 0.0100\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0106 - val_loss: 0.0142 - val_mse: 0.0107\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0103 - val_loss: 0.0133 - val_mse: 0.0098\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0112 - val_loss: 0.0143 - val_mse: 0.0109\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0104 - val_loss: 0.0141 - val_mse: 0.0106\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0103 - val_loss: 0.0129 - val_mse: 0.0094\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0098 - val_loss: 0.0127 - val_mse: 0.0092\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0096 - val_loss: 0.0160 - val_mse: 0.0125\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0097 - val_loss: 0.0125 - val_mse: 0.0090\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0093 - val_loss: 0.0132 - val_mse: 0.0096\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0090 - val_loss: 0.0146 - val_mse: 0.0110\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0090 - val_loss: 0.0121 - val_mse: 0.0085\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0087 - val_loss: 0.0128 - val_mse: 0.0092\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0090 - val_loss: 0.0125 - val_mse: 0.0089\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0086 - val_loss: 0.0117 - val_mse: 0.0081\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0086 - val_loss: 0.0119 - val_mse: 0.0083\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0081 - val_loss: 0.0123 - val_mse: 0.0088\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0081 - val_loss: 0.0124 - val_mse: 0.0088\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0077\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0080 - val_loss: 0.0114 - val_mse: 0.0078\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0076\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0076\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0075 - val_loss: 0.0121 - val_mse: 0.0085\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0073\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0072\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0071 - val_loss: 0.0118 - val_mse: 0.0081\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0108 - mse: 0.0072 - val_loss: 0.0107 - val_mse: 0.0071\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0070 - val_loss: 0.0114 - val_mse: 0.0077\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0072 - val_loss: 0.0135 - val_mse: 0.0098\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0105 - mse: 0.0068 - val_loss: 0.0127 - val_mse: 0.0091\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0068 - val_loss: 0.0112 - val_mse: 0.0076\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0069 - val_loss: 0.0105 - val_mse: 0.0069\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0068 - val_loss: 0.0104 - val_mse: 0.0068\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0067 - val_loss: 0.0104 - val_mse: 0.0068\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0065 - val_loss: 0.0108 - val_mse: 0.0071\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0071\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0068 - val_loss: 0.0114 - val_mse: 0.0077\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0069 - val_loss: 0.0103 - val_mse: 0.0067\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0065 - val_loss: 0.0100 - val_mse: 0.0063\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0062\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0064 - val_loss: 0.0158 - val_mse: 0.0121\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0107 - val_mse: 0.0071\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0064 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0066 - val_loss: 0.0098 - val_mse: 0.0061\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0060 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0096 - val_mse: 0.0060\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0059 - val_loss: 0.0097 - val_mse: 0.0061\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0065 - val_loss: 0.0101 - val_mse: 0.0065\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0060 - val_loss: 0.0093 - val_mse: 0.0057\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0059 - val_loss: 0.0109 - val_mse: 0.0073\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0062 - val_loss: 0.0094 - val_mse: 0.0058\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0057 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0058 - val_loss: 0.0099 - val_mse: 0.0063\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0057 - val_loss: 0.0102 - val_mse: 0.0066\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0056 - val_loss: 0.0101 - val_mse: 0.0065\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0057 - val_loss: 0.0093 - val_mse: 0.0056\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0090 - val_mse: 0.0054\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0053 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0054 - val_loss: 0.0102 - val_mse: 0.0066\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0057 - val_loss: 0.0135 - val_mse: 0.0099\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0053 - val_loss: 0.0088 - val_mse: 0.0052\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0053 - val_loss: 0.0087 - val_mse: 0.0051\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0052 - val_loss: 0.0090 - val_mse: 0.0054\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0054 - val_loss: 0.0087 - val_mse: 0.0050\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0055 - val_loss: 0.0092 - val_mse: 0.0055\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0110 - val_mse: 0.0074\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0050 - val_loss: 0.0089 - val_mse: 0.0052\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0051 - val_loss: 0.0094 - val_mse: 0.0058\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0051 - val_loss: 0.0084 - val_mse: 0.0048\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0055 - val_loss: 0.0099 - val_mse: 0.0063\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0051 - val_loss: 0.0084 - val_mse: 0.0047\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0053 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0092 - val_mse: 0.0056\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0052 - val_loss: 0.0086 - val_mse: 0.0050\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0050 - val_loss: 0.0097 - val_mse: 0.0061\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0050 - val_loss: 0.0082 - val_mse: 0.0046\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0092 - val_mse: 0.0056\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0106 - val_mse: 0.0070\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0102 - val_mse: 0.0066\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0052\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0049 - val_loss: 0.0109 - val_mse: 0.0073\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0052\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0045 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0046 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0045 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0046 - val_loss: 0.0084 - val_mse: 0.0048\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0045 - val_loss: 0.0095 - val_mse: 0.0059\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0082 - val_mse: 0.0047\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0045 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0087 - val_mse: 0.0051\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0044 - val_loss: 0.0104 - val_mse: 0.0069\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0048 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0042 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0042 - val_loss: 0.0074 - val_mse: 0.0038\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0040 - val_loss: 0.0076 - val_mse: 0.0041\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0043 - val_loss: 0.0073 - val_mse: 0.0037\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0123 - val_mse: 0.0088\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0041 - val_loss: 0.0098 - val_mse: 0.0063\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0043 - val_loss: 0.0073 - val_mse: 0.0037\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0040 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0075 - val_mse: 0.0040\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0072 - val_mse: 0.0036\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0041 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0042 - val_loss: 0.0099 - val_mse: 0.0063\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0071 - val_mse: 0.0035\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0041 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0040 - val_loss: 0.0074 - val_mse: 0.0039\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0038 - val_loss: 0.0073 - val_mse: 0.0037\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0036 - val_loss: 0.0090 - val_mse: 0.0054\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0041 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0038 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0101 - val_mse: 0.0066\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0073 - val_mse: 0.0038\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0036 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0092 - val_mse: 0.0057\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0072 - val_mse: 0.0037\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0038 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0036 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0089 - val_mse: 0.0053\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0039 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0039 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0067 - val_mse: 0.0031\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0066 - val_mse: 0.0031\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0036 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0086 - val_mse: 0.0051\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0037 - val_loss: 0.0068 - val_mse: 0.0033\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0034 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0035 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0094 - val_mse: 0.0059\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0034 - val_loss: 0.0067 - val_mse: 0.0032\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0033 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0032 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0035 - val_loss: 0.0063 - val_mse: 0.0028\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0062 - val_mse: 0.0027\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0062 - val_mse: 0.0027\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0061 - val_mse: 0.0027\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0033 - val_loss: 0.0064 - val_mse: 0.0029\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0069 - val_mse: 0.0034\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0036\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0065 - val_mse: 0.0031\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0032 - val_loss: 0.0102 - val_mse: 0.0068\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0065 - val_mse: 0.0030\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0032 - val_loss: 0.0069 - val_mse: 0.0035\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0032\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0035\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0062 - val_mse: 0.0028\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0034\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0031 - val_loss: 0.0060 - val_mse: 0.0025\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0029\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0030 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0030\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0061 - val_mse: 0.0027\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0033\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0061 - val_mse: 0.0026\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0030\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0066 - val_mse: 0.0032\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0059 - val_mse: 0.0025\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0069 - val_mse: 0.0035\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0065 - val_mse: 0.0031\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0064 - mse: 0.0030 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0029 - val_loss: 0.0060 - val_mse: 0.0026\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0041\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0031 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0030 - val_loss: 0.0062 - val_mse: 0.0028\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0057 - val_mse: 0.0023\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0030\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0025 - val_loss: 0.0057 - val_mse: 0.0023\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0057 - val_mse: 0.0024\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0058 - val_mse: 0.0024\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0065 - val_mse: 0.0031\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0022\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0057 - val_mse: 0.0024\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0058 - val_mse: 0.0025\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0029 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0028 - val_loss: 0.0056 - val_mse: 0.0022\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0033\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0029 - val_loss: 0.0058 - val_mse: 0.0025\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0056 - val_mse: 0.0022\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0027 - val_loss: 0.0081 - val_mse: 0.0047\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0028 - val_loss: 0.0062 - val_mse: 0.0029\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0029 - val_loss: 0.0059 - val_mse: 0.0026\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0026 - val_loss: 0.0063 - val_mse: 0.0030\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0025 - val_loss: 0.0061 - val_mse: 0.0027\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0059 - val_mse: 0.0026\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0055 - val_mse: 0.0022\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0058 - val_mse: 0.0025\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0065 - val_mse: 0.0032\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0026 - val_loss: 0.0068 - val_mse: 0.0035\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0029 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0113 - val_mse: 0.0080\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0028 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0071 - val_mse: 0.0037\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0077 - val_mse: 0.0044\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0056 - val_mse: 0.0022\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0025 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0024 - val_loss: 0.0070 - val_mse: 0.0037\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0025 - val_loss: 0.0064 - val_mse: 0.0031\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0055 - val_mse: 0.0022\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0053 - val_mse: 0.0020\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0061 - mse: 0.0028 - val_loss: 0.0053 - val_mse: 0.0020\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0057 - val_mse: 0.0024\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0059 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0060 - mse: 0.0027 - val_loss: 0.0053 - val_mse: 0.0020\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0025 - val_loss: 0.0056 - val_mse: 0.0023\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0058 - mse: 0.0025 - val_loss: 0.0054 - val_mse: 0.0021\n",
      "Epoch 324: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1039 - mse: 0.1007 - val_loss: 0.0612 - val_mse: 0.0580\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0863 - mse: 0.0832 - val_loss: 0.0772 - val_mse: 0.0740\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0742 - mse: 0.0709 - val_loss: 0.0407 - val_mse: 0.0373\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0620 - mse: 0.0586 - val_loss: 0.0456 - val_mse: 0.0421\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0451 - mse: 0.0415 - val_loss: 0.0258 - val_mse: 0.0222\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0303 - val_loss: 0.0232 - val_mse: 0.0195\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0256 - val_loss: 0.0239 - val_mse: 0.0200\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0245 - val_loss: 0.0308 - val_mse: 0.0270\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0232 - val_loss: 0.0230 - val_mse: 0.0192\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0222 - val_loss: 0.0212 - val_mse: 0.0173\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0215 - val_loss: 0.0223 - val_mse: 0.0184\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0202 - val_loss: 0.0210 - val_mse: 0.0171\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0201 - val_loss: 0.0206 - val_mse: 0.0168\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0194 - val_loss: 0.0297 - val_mse: 0.0258\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0191 - val_loss: 0.0239 - val_mse: 0.0200\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0194 - val_loss: 0.0216 - val_mse: 0.0177\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0186 - val_loss: 0.0200 - val_mse: 0.0161\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0177 - val_loss: 0.0185 - val_mse: 0.0145\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0180 - val_loss: 0.0198 - val_mse: 0.0159\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0170 - val_loss: 0.0186 - val_mse: 0.0146\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0176 - val_loss: 0.0182 - val_mse: 0.0143\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0175 - val_loss: 0.0185 - val_mse: 0.0145\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0162 - val_loss: 0.0227 - val_mse: 0.0188\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0162 - val_loss: 0.0177 - val_mse: 0.0137\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0160 - val_loss: 0.0251 - val_mse: 0.0211\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0171 - val_loss: 0.0176 - val_mse: 0.0136\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0160 - val_loss: 0.0172 - val_mse: 0.0131\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0155 - val_loss: 0.0179 - val_mse: 0.0139\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0151 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0150 - val_loss: 0.0167 - val_mse: 0.0127\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0143 - val_loss: 0.0168 - val_mse: 0.0127\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0148 - val_loss: 0.0166 - val_mse: 0.0125\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0146 - val_loss: 0.0166 - val_mse: 0.0125\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0142 - val_loss: 0.0183 - val_mse: 0.0142\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0146 - val_loss: 0.0173 - val_mse: 0.0132\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0139 - val_loss: 0.0160 - val_mse: 0.0119\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0144 - val_loss: 0.0184 - val_mse: 0.0143\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0139 - val_loss: 0.0170 - val_mse: 0.0129\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0132 - val_loss: 0.0164 - val_mse: 0.0122\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0129 - val_loss: 0.0157 - val_mse: 0.0116\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0136 - val_loss: 0.0168 - val_mse: 0.0126\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0133 - val_loss: 0.0167 - val_mse: 0.0125\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0129 - val_loss: 0.0154 - val_mse: 0.0112\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0130 - val_loss: 0.0165 - val_mse: 0.0124\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0132 - val_loss: 0.0152 - val_mse: 0.0110\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0132 - val_loss: 0.0162 - val_mse: 0.0120\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0125 - val_loss: 0.0152 - val_mse: 0.0110\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0122 - val_loss: 0.0227 - val_mse: 0.0185\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0135 - val_loss: 0.0165 - val_mse: 0.0123\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0129 - val_loss: 0.0166 - val_mse: 0.0124\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0127 - val_loss: 0.0245 - val_mse: 0.0203\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0129 - val_loss: 0.0162 - val_mse: 0.0120\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0124 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0121 - val_loss: 0.0153 - val_mse: 0.0111\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0126 - val_loss: 0.0161 - val_mse: 0.0119\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0117 - val_loss: 0.0161 - val_mse: 0.0119\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0121 - val_loss: 0.0160 - val_mse: 0.0118\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0124 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0204 - val_mse: 0.0162\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0122 - val_loss: 0.0172 - val_mse: 0.0129\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0161 - val_mse: 0.0119\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0120 - val_loss: 0.0145 - val_mse: 0.0103\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0123 - val_loss: 0.0144 - val_mse: 0.0102\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0122 - val_loss: 0.0161 - val_mse: 0.0119\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0152 - val_mse: 0.0110\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0122 - val_loss: 0.0150 - val_mse: 0.0108\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0145 - val_mse: 0.0103\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0113 - val_loss: 0.0154 - val_mse: 0.0111\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0113 - val_loss: 0.0142 - val_mse: 0.0099\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0115 - val_loss: 0.0143 - val_mse: 0.0101\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0120 - val_loss: 0.0143 - val_mse: 0.0101\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0120 - val_loss: 0.0178 - val_mse: 0.0136\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0123 - val_loss: 0.0139 - val_mse: 0.0097\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0114 - val_loss: 0.0155 - val_mse: 0.0113\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0118 - val_loss: 0.0141 - val_mse: 0.0098\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0118 - val_loss: 0.0154 - val_mse: 0.0112\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0118 - val_loss: 0.0150 - val_mse: 0.0108\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0163 - val_mse: 0.0121\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0119 - val_loss: 0.0142 - val_mse: 0.0100\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0109 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0114 - val_loss: 0.0158 - val_mse: 0.0116\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0112 - val_loss: 0.0176 - val_mse: 0.0134\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0111 - val_loss: 0.0158 - val_mse: 0.0116\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0110 - val_loss: 0.0169 - val_mse: 0.0127\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0116 - val_loss: 0.0138 - val_mse: 0.0096\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0116 - val_loss: 0.0138 - val_mse: 0.0096\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0113 - val_loss: 0.0154 - val_mse: 0.0112\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0112 - val_loss: 0.0156 - val_mse: 0.0114\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0118 - val_loss: 0.0139 - val_mse: 0.0097\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0104 - val_loss: 0.0143 - val_mse: 0.0101\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0107 - val_loss: 0.0139 - val_mse: 0.0097\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0111 - val_loss: 0.0137 - val_mse: 0.0095\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0112 - val_loss: 0.0149 - val_mse: 0.0107\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0108 - val_loss: 0.0157 - val_mse: 0.0115\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0111 - val_loss: 0.0141 - val_mse: 0.0099\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0110 - val_loss: 0.0157 - val_mse: 0.0115\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0112 - val_loss: 0.0138 - val_mse: 0.0096\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0111 - val_loss: 0.0138 - val_mse: 0.0095\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0110 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0155 - val_mse: 0.0113\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0111 - val_loss: 0.0137 - val_mse: 0.0095\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0110 - val_loss: 0.0170 - val_mse: 0.0128\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0112 - val_loss: 0.0134 - val_mse: 0.0092\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0108 - val_loss: 0.0141 - val_mse: 0.0099\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0110 - val_loss: 0.0138 - val_mse: 0.0096\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0108 - val_loss: 0.0146 - val_mse: 0.0104\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0104 - val_loss: 0.0143 - val_mse: 0.0101\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0111 - val_loss: 0.0157 - val_mse: 0.0115\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0105 - val_loss: 0.0145 - val_mse: 0.0103\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0108 - val_loss: 0.0133 - val_mse: 0.0091\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0138 - val_mse: 0.0096\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0106 - val_loss: 0.0133 - val_mse: 0.0091\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0106 - val_loss: 0.0149 - val_mse: 0.0107\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0109 - val_loss: 0.0145 - val_mse: 0.0103\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0104 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0107 - val_loss: 0.0137 - val_mse: 0.0095\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0107 - val_loss: 0.0131 - val_mse: 0.0089\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0106 - val_loss: 0.0142 - val_mse: 0.0100\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0105 - val_loss: 0.0133 - val_mse: 0.0091\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0109 - val_loss: 0.0135 - val_mse: 0.0093\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0154 - val_mse: 0.0112\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0105 - val_loss: 0.0156 - val_mse: 0.0114\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0109 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0106 - val_loss: 0.0250 - val_mse: 0.0208\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0104 - val_loss: 0.0136 - val_mse: 0.0094\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0107 - val_loss: 0.0140 - val_mse: 0.0098\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0100 - val_loss: 0.0151 - val_mse: 0.0110\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0105 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0152 - val_mse: 0.0110\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0099 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0129 - val_mse: 0.0087\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0139 - val_mse: 0.0097\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0100 - val_loss: 0.0129 - val_mse: 0.0088\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0099 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0104 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0103 - val_loss: 0.0134 - val_mse: 0.0092\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0102 - val_loss: 0.0140 - val_mse: 0.0098\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0101 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0100 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0102 - val_loss: 0.0149 - val_mse: 0.0107\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0101 - val_loss: 0.0129 - val_mse: 0.0087\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0097 - val_loss: 0.0127 - val_mse: 0.0086\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0102 - val_loss: 0.0128 - val_mse: 0.0086\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0104 - val_loss: 0.0148 - val_mse: 0.0106\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0098 - val_loss: 0.0144 - val_mse: 0.0102\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0094 - val_loss: 0.0129 - val_mse: 0.0087\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0099 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0098 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0097 - val_loss: 0.0129 - val_mse: 0.0087\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0097 - val_loss: 0.0131 - val_mse: 0.0089\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0100 - val_loss: 0.0131 - val_mse: 0.0089\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0094 - val_loss: 0.0148 - val_mse: 0.0106\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0099 - val_loss: 0.0127 - val_mse: 0.0086\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0095 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0094 - val_loss: 0.0160 - val_mse: 0.0118\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0100 - val_loss: 0.0133 - val_mse: 0.0091\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0096 - val_loss: 0.0126 - val_mse: 0.0084\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0092 - val_loss: 0.0159 - val_mse: 0.0117\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0096 - val_loss: 0.0145 - val_mse: 0.0103\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0097 - val_loss: 0.0126 - val_mse: 0.0084\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0095 - val_loss: 0.0126 - val_mse: 0.0084\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0093 - val_loss: 0.0161 - val_mse: 0.0119\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0091 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0094 - val_loss: 0.0133 - val_mse: 0.0091\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0090 - val_loss: 0.0147 - val_mse: 0.0105\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0083\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0094 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0094 - val_loss: 0.0139 - val_mse: 0.0097\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0092 - val_loss: 0.0123 - val_mse: 0.0081\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0091 - val_loss: 0.0177 - val_mse: 0.0135\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0095 - val_loss: 0.0144 - val_mse: 0.0102\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0093 - val_loss: 0.0123 - val_mse: 0.0081\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0122 - val_mse: 0.0080\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0090 - val_loss: 0.0140 - val_mse: 0.0098\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0092 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0091 - val_loss: 0.0122 - val_mse: 0.0080\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0094 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0093 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0091 - val_loss: 0.0125 - val_mse: 0.0083\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0099 - val_loss: 0.0129 - val_mse: 0.0087\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0126 - val_mse: 0.0084\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0088 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0134 - val_mse: 0.0092\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0088 - val_loss: 0.0150 - val_mse: 0.0108\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0089 - val_loss: 0.0120 - val_mse: 0.0078\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0088 - val_loss: 0.0123 - val_mse: 0.0081\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0085 - val_loss: 0.0122 - val_mse: 0.0080\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0141 - val_mse: 0.0099\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0088 - val_loss: 0.0171 - val_mse: 0.0129\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0137 - val_mse: 0.0095\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0082 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0081 - val_loss: 0.0132 - val_mse: 0.0090\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0118 - val_mse: 0.0076\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0085 - val_loss: 0.0130 - val_mse: 0.0088\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0083 - val_loss: 0.0147 - val_mse: 0.0104\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0120 - val_mse: 0.0078\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0081 - val_loss: 0.0118 - val_mse: 0.0076\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0085 - val_loss: 0.0157 - val_mse: 0.0115\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0085 - val_loss: 0.0121 - val_mse: 0.0079\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0117 - val_mse: 0.0075\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0080 - val_loss: 0.0142 - val_mse: 0.0100\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0083 - val_loss: 0.0120 - val_mse: 0.0078\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0084 - val_loss: 0.0186 - val_mse: 0.0143\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0082 - val_loss: 0.0129 - val_mse: 0.0086\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0124 - val_mse: 0.0082\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0081 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0086 - val_loss: 0.0127 - val_mse: 0.0084\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0078 - val_loss: 0.0117 - val_mse: 0.0075\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0083 - val_loss: 0.0133 - val_mse: 0.0090\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0077 - val_loss: 0.0121 - val_mse: 0.0079\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0119 - val_mse: 0.0076\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0081 - val_loss: 0.0118 - val_mse: 0.0076\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0080 - val_loss: 0.0119 - val_mse: 0.0076\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0079 - val_loss: 0.0123 - val_mse: 0.0080\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0081 - val_loss: 0.0122 - val_mse: 0.0080\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0083 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0082 - val_loss: 0.0123 - val_mse: 0.0081\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0076 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0073 - val_loss: 0.0148 - val_mse: 0.0105\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0077 - val_loss: 0.0118 - val_mse: 0.0075\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0078 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0160 - val_mse: 0.0118\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0076 - val_loss: 0.0136 - val_mse: 0.0093\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0071\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0122 - val_mse: 0.0079\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0113 - val_mse: 0.0071\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0113 - val_mse: 0.0071\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0119 - val_mse: 0.0076\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0116 - val_mse: 0.0074\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0131 - val_mse: 0.0088\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0078 - val_loss: 0.0139 - val_mse: 0.0096\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0079 - val_loss: 0.0117 - val_mse: 0.0074\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0114 - val_mse: 0.0071\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0078 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0117 - val_mse: 0.0074\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0131 - val_mse: 0.0088\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0122 - val_mse: 0.0079\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0076 - val_loss: 0.0111 - val_mse: 0.0068\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0127 - val_mse: 0.0084\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0120 - val_mse: 0.0076\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0076 - val_loss: 0.0135 - val_mse: 0.0092\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0118 - val_mse: 0.0075\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0111 - val_mse: 0.0068\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0110 - val_mse: 0.0067\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0110 - val_mse: 0.0067\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0124 - val_mse: 0.0081\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0161 - val_mse: 0.0118\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0126 - val_mse: 0.0083\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0138 - val_mse: 0.0094\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0113 - val_mse: 0.0070\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0110 - val_mse: 0.0067\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0142 - val_mse: 0.0099\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0136 - val_mse: 0.0093\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0113 - val_mse: 0.0069\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0118 - val_mse: 0.0074\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0103 - val_mse: 0.0060\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0060\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0111 - val_mse: 0.0068\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0127 - val_mse: 0.0084\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0154 - val_mse: 0.0111\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0178 - val_mse: 0.0135\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0110 - val_mse: 0.0067\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0103 - val_mse: 0.0060\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0104 - val_mse: 0.0061\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0104 - val_mse: 0.0061\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0114 - val_mse: 0.0070\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0114 - val_mse: 0.0071\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0106 - val_mse: 0.0062\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0104 - val_mse: 0.0060\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0058 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0100 - val_mse: 0.0057\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0103 - val_mse: 0.0060\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0100 - val_mse: 0.0057\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0100 - val_mse: 0.0056\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0099 - val_mse: 0.0056\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0109 - val_mse: 0.0065\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0099 - val_mse: 0.0055\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0099 - val_mse: 0.0056\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0113 - val_mse: 0.0069\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0168 - val_mse: 0.0125\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0134 - val_mse: 0.0091\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0108 - val_mse: 0.0065\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0055 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0099 - val_mse: 0.0056\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0104 - val_mse: 0.0061\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0054\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0056 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0103 - val_mse: 0.0059\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0125 - val_mse: 0.0082\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0103 - val_mse: 0.0060\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0092 - val_mse: 0.0048\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0102 - val_mse: 0.0058\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0049 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0101 - val_mse: 0.0058\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0048 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0111 - val_mse: 0.0068\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0091 - val_mse: 0.0049\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0099 - val_mse: 0.0056\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0046 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0044 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0043 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0043 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0043 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0120 - val_mse: 0.0078\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0093 - val_mse: 0.0051\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0046 - val_loss: 0.0104 - val_mse: 0.0061\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0058\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0037\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0093 - val_mse: 0.0051\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0091 - val_mse: 0.0049\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0118 - val_mse: 0.0075\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0036 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0077 - val_mse: 0.0034\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0035 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0035 - val_loss: 0.0093 - val_mse: 0.0051\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0076 - val_mse: 0.0033\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0031\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0032\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0033 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0031\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0035 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1017 - mse: 0.0989 - val_loss: 0.0501 - val_mse: 0.0474\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0818 - mse: 0.0790 - val_loss: 0.0447 - val_mse: 0.0419\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0703 - val_loss: 0.0406 - val_mse: 0.0376\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0612 - val_loss: 0.0361 - val_mse: 0.0330\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0489 - val_loss: 0.0324 - val_mse: 0.0293\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0393 - val_loss: 0.0244 - val_mse: 0.0211\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0331 - val_loss: 0.0232 - val_mse: 0.0198\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0317 - val_loss: 0.0336 - val_mse: 0.0302\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0285 - val_loss: 0.0233 - val_mse: 0.0199\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0273 - val_loss: 0.0218 - val_mse: 0.0184\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0265 - val_loss: 0.0209 - val_mse: 0.0174\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0260 - val_loss: 0.0207 - val_mse: 0.0173\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0247 - val_loss: 0.0202 - val_mse: 0.0167\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0244 - val_loss: 0.0253 - val_mse: 0.0218\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0240 - val_loss: 0.0288 - val_mse: 0.0253\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0233 - val_loss: 0.0198 - val_mse: 0.0163\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0237 - val_loss: 0.0223 - val_mse: 0.0188\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0229 - val_loss: 0.0183 - val_mse: 0.0148\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0213 - val_loss: 0.0180 - val_mse: 0.0145\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0207 - val_loss: 0.0177 - val_mse: 0.0142\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0207 - val_loss: 0.0210 - val_mse: 0.0174\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0200 - val_loss: 0.0181 - val_mse: 0.0146\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0198 - val_loss: 0.0169 - val_mse: 0.0133\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0194 - val_loss: 0.0210 - val_mse: 0.0175\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0189 - val_loss: 0.0167 - val_mse: 0.0132\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0176 - val_loss: 0.0170 - val_mse: 0.0134\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0177 - val_loss: 0.0167 - val_mse: 0.0131\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0171 - val_loss: 0.0167 - val_mse: 0.0130\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0175 - val_loss: 0.0180 - val_mse: 0.0144\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0160 - val_loss: 0.0164 - val_mse: 0.0127\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0163 - val_loss: 0.0157 - val_mse: 0.0121\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0155 - val_loss: 0.0205 - val_mse: 0.0168\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0155 - val_loss: 0.0225 - val_mse: 0.0188\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0147 - val_loss: 0.0151 - val_mse: 0.0114\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0144 - val_loss: 0.0211 - val_mse: 0.0174\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0142 - val_loss: 0.0149 - val_mse: 0.0112\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0140 - val_loss: 0.0154 - val_mse: 0.0117\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0133 - val_loss: 0.0152 - val_mse: 0.0114\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0138 - val_loss: 0.0151 - val_mse: 0.0113\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0132 - val_loss: 0.0205 - val_mse: 0.0167\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0129 - val_loss: 0.0145 - val_mse: 0.0106\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0127 - val_loss: 0.0144 - val_mse: 0.0105\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0125 - val_loss: 0.0168 - val_mse: 0.0130\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0129 - val_loss: 0.0175 - val_mse: 0.0136\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0119 - val_loss: 0.0161 - val_mse: 0.0123\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0115 - val_loss: 0.0142 - val_mse: 0.0103\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0115 - val_loss: 0.0162 - val_mse: 0.0123\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0115 - val_loss: 0.0223 - val_mse: 0.0184\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0115 - val_loss: 0.0163 - val_mse: 0.0124\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0139 - val_mse: 0.0100\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0108 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0104 - val_loss: 0.0144 - val_mse: 0.0104\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0103 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0106 - val_loss: 0.0151 - val_mse: 0.0111\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0104 - val_loss: 0.0140 - val_mse: 0.0099\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0105 - val_loss: 0.0135 - val_mse: 0.0094\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0098 - val_loss: 0.0142 - val_mse: 0.0101\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0099 - val_loss: 0.0144 - val_mse: 0.0103\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0100 - val_loss: 0.0138 - val_mse: 0.0097\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0095 - val_loss: 0.0144 - val_mse: 0.0103\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0098 - val_loss: 0.0137 - val_mse: 0.0096\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0099 - val_loss: 0.0139 - val_mse: 0.0098\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0093 - val_loss: 0.0144 - val_mse: 0.0103\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0090 - val_loss: 0.0170 - val_mse: 0.0129\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0092 - val_loss: 0.0130 - val_mse: 0.0089\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0091 - val_loss: 0.0179 - val_mse: 0.0137\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0089 - val_loss: 0.0171 - val_mse: 0.0129\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0094 - val_loss: 0.0140 - val_mse: 0.0098\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0090 - val_loss: 0.0127 - val_mse: 0.0085\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0088 - val_loss: 0.0134 - val_mse: 0.0092\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0087 - val_loss: 0.0156 - val_mse: 0.0113\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0082 - val_loss: 0.0134 - val_mse: 0.0092\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0083 - val_loss: 0.0125 - val_mse: 0.0082\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0082 - val_loss: 0.0144 - val_mse: 0.0101\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0085 - val_loss: 0.0127 - val_mse: 0.0084\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0085 - val_loss: 0.0127 - val_mse: 0.0084\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0077 - val_loss: 0.0123 - val_mse: 0.0080\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0078 - val_loss: 0.0126 - val_mse: 0.0083\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0081 - val_loss: 0.0124 - val_mse: 0.0081\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0079 - val_loss: 0.0126 - val_mse: 0.0083\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0080 - val_loss: 0.0124 - val_mse: 0.0081\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0084 - val_loss: 0.0140 - val_mse: 0.0097\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0080 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0123 - mse: 0.0080 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0156 - val_mse: 0.0113\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0084 - val_loss: 0.0163 - val_mse: 0.0120\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0079 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0131 - val_mse: 0.0088\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0080 - val_loss: 0.0118 - val_mse: 0.0074\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0077 - val_loss: 0.0131 - val_mse: 0.0088\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0074 - val_loss: 0.0142 - val_mse: 0.0099\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0072 - val_loss: 0.0120 - val_mse: 0.0076\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0147 - val_mse: 0.0104\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0116 - val_mse: 0.0073\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0076 - val_loss: 0.0114 - val_mse: 0.0071\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0118 - val_mse: 0.0075\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0121 - val_mse: 0.0077\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0122 - val_mse: 0.0078\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0133 - val_mse: 0.0090\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0123 - val_mse: 0.0079\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0073 - val_loss: 0.0117 - val_mse: 0.0073\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0113 - val_mse: 0.0069\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0117 - val_mse: 0.0073\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0120 - val_mse: 0.0076\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0150 - val_mse: 0.0106\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0110 - val_mse: 0.0066\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0116 - val_mse: 0.0072\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0114 - val_mse: 0.0070\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0112 - val_mse: 0.0068\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0108 - val_mse: 0.0064\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0110 - val_mse: 0.0066\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0064\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0109 - val_mse: 0.0066\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0156 - val_mse: 0.0113\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0121 - val_mse: 0.0078\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0122 - val_mse: 0.0078\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0113 - val_mse: 0.0069\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0105 - val_mse: 0.0061\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0117 - val_mse: 0.0074\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0123 - val_mse: 0.0080\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0111 - val_mse: 0.0067\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0103 - val_mse: 0.0059\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0115 - val_mse: 0.0071\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0057 - val_loss: 0.0105 - val_mse: 0.0061\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0057 - val_loss: 0.0110 - val_mse: 0.0066\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0100 - val_mse: 0.0057\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0058 - val_loss: 0.0119 - val_mse: 0.0076\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0104 - val_mse: 0.0060\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0100 - val_mse: 0.0056\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0055 - val_loss: 0.0103 - val_mse: 0.0059\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0099 - val_mse: 0.0055\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0099 - val_mse: 0.0056\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0059 - val_loss: 0.0112 - val_mse: 0.0069\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0098 - val_mse: 0.0054\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0110 - val_mse: 0.0066\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0055 - val_loss: 0.0100 - val_mse: 0.0057\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0053 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0097 - val_mse: 0.0053\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0053 - val_loss: 0.0098 - val_mse: 0.0054\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0104 - val_mse: 0.0061\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0056 - val_loss: 0.0106 - val_mse: 0.0062\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0056 - val_loss: 0.0102 - val_mse: 0.0059\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0136 - val_mse: 0.0092\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0052 - val_loss: 0.0107 - val_mse: 0.0064\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0054 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0053 - val_loss: 0.0097 - val_mse: 0.0053\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0094 - val_mse: 0.0050\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0054 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0055 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0050 - val_loss: 0.0092 - val_mse: 0.0048\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0051 - val_loss: 0.0107 - val_mse: 0.0063\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0053 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0050 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0049 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0047 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0047 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0098 - val_mse: 0.0055\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0106 - val_mse: 0.0063\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0048 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0120 - val_mse: 0.0077\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0046 - val_loss: 0.0095 - val_mse: 0.0052\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0046 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0047 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0044 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0058\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0045 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0092 - val_mse: 0.0050\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0043 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0042 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0044 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0045 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0042 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0115 - val_mse: 0.0072\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0040 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0041 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0040 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0040 - val_loss: 0.0080 - val_mse: 0.0037\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0091 - val_mse: 0.0049\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0041 - val_loss: 0.0077 - val_mse: 0.0034\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0039 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0038 - val_loss: 0.0076 - val_mse: 0.0033\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0040 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0039 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0106 - val_mse: 0.0064\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0033\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0034 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0104 - val_mse: 0.0062\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0032\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0073 - val_mse: 0.0030\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0079 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0074 - val_mse: 0.0031\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0038 - val_loss: 0.0074 - val_mse: 0.0032\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0072 - val_mse: 0.0030\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0033 - val_loss: 0.0072 - val_mse: 0.0030\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0095 - val_mse: 0.0053\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0093 - val_mse: 0.0051\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0092 - val_mse: 0.0050\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0034 - val_loss: 0.0074 - val_mse: 0.0032\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0071 - val_mse: 0.0030\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0069 - val_mse: 0.0028\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0033 - val_loss: 0.0102 - val_mse: 0.0060\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0035 - val_loss: 0.0069 - val_mse: 0.0027\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0030 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0033 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0036 - val_loss: 0.0069 - val_mse: 0.0028\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0032 - val_loss: 0.0069 - val_mse: 0.0027\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0030 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0036\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0032 - val_loss: 0.0111 - val_mse: 0.0069\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0033\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0027\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0029\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0035 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0075 - val_mse: 0.0034\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0076 - val_mse: 0.0034\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0026\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0028\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0034 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0070 - val_mse: 0.0028\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0033 - val_loss: 0.0072 - val_mse: 0.0031\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0030 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0027\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0026\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0026\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0026\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0028 - val_loss: 0.0072 - val_mse: 0.0030\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0032 - val_loss: 0.0072 - val_mse: 0.0031\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0027\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0025\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0025\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0032 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0029\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0025\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0026\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0028 - val_loss: 0.0067 - val_mse: 0.0025\n",
      "Epoch 351: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.0852 - mse: 0.0807 - val_loss: 0.0461 - val_mse: 0.0416\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0664 - mse: 0.0619 - val_loss: 0.0406 - val_mse: 0.0361\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0474 - val_loss: 0.0337 - val_mse: 0.0290\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0408 - val_loss: 0.0336 - val_mse: 0.0288\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0356 - val_loss: 0.0310 - val_mse: 0.0263\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0329 - val_loss: 0.0305 - val_mse: 0.0258\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0350 - mse: 0.0302 - val_loss: 0.0294 - val_mse: 0.0246\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0343 - mse: 0.0295 - val_loss: 0.0277 - val_mse: 0.0229\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0268 - val_loss: 0.0269 - val_mse: 0.0221\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0260 - val_loss: 0.0248 - val_mse: 0.0200\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0241 - val_loss: 0.0238 - val_mse: 0.0189\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0226 - val_loss: 0.0226 - val_mse: 0.0177\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0208 - val_loss: 0.0214 - val_mse: 0.0165\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0198 - val_loss: 0.0213 - val_mse: 0.0164\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0188 - val_loss: 0.0200 - val_mse: 0.0151\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0171 - val_loss: 0.0234 - val_mse: 0.0184\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0155 - val_loss: 0.0180 - val_mse: 0.0131\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0145 - val_loss: 0.0192 - val_mse: 0.0142\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0116\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0131 - val_loss: 0.0159 - val_mse: 0.0109\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0125 - val_loss: 0.0154 - val_mse: 0.0103\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0115 - val_loss: 0.0162 - val_mse: 0.0111\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0107 - val_loss: 0.0164 - val_mse: 0.0113\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0101 - val_loss: 0.0182 - val_mse: 0.0131\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0096 - val_loss: 0.0140 - val_mse: 0.0089\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0090 - val_loss: 0.0144 - val_mse: 0.0092\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0085 - val_loss: 0.0138 - val_mse: 0.0086\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0084 - val_loss: 0.0132 - val_mse: 0.0080\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0081 - val_loss: 0.0129 - val_mse: 0.0077\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0077 - val_loss: 0.0159 - val_mse: 0.0107\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0134 - val_mse: 0.0082\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0137 - val_mse: 0.0085\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0074 - val_loss: 0.0167 - val_mse: 0.0114\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0072 - val_loss: 0.0122 - val_mse: 0.0070\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0119 - val_mse: 0.0067\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0125 - val_mse: 0.0073\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0067 - val_loss: 0.0121 - val_mse: 0.0068\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0064 - val_loss: 0.0117 - val_mse: 0.0064\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0065 - val_loss: 0.0116 - val_mse: 0.0063\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0126 - val_mse: 0.0074\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0063 - val_loss: 0.0149 - val_mse: 0.0096\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0059 - val_loss: 0.0121 - val_mse: 0.0069\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0058 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0057 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0060 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0060 - val_loss: 0.0138 - val_mse: 0.0086\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0056 - val_loss: 0.0120 - val_mse: 0.0067\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0056 - val_loss: 0.0117 - val_mse: 0.0064\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0057 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0060 - val_loss: 0.0109 - val_mse: 0.0057\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0060 - val_loss: 0.0120 - val_mse: 0.0067\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0058 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0055 - val_loss: 0.0124 - val_mse: 0.0072\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0118 - val_mse: 0.0065\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0056 - val_loss: 0.0124 - val_mse: 0.0071\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0054 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0054 - val_loss: 0.0103 - val_mse: 0.0050\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0053 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0051 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0053 - val_loss: 0.0110 - val_mse: 0.0058\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0054 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0050 - val_loss: 0.0100 - val_mse: 0.0048\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0052 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0056 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0049 - val_loss: 0.0128 - val_mse: 0.0076\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0051 - val_loss: 0.0111 - val_mse: 0.0060\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0047 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0049 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0045 - val_loss: 0.0109 - val_mse: 0.0058\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0047 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0047 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0047 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0048 - val_loss: 0.0108 - val_mse: 0.0056\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0049 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0047 - val_loss: 0.0120 - val_mse: 0.0069\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0046 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0046 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0045 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0048 - val_loss: 0.0110 - val_mse: 0.0059\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0043 - val_loss: 0.0104 - val_mse: 0.0054\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0045 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0043 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0044 - val_loss: 0.0107 - val_mse: 0.0057\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0045 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0043 - val_loss: 0.0089 - val_mse: 0.0039\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0041 - val_loss: 0.0113 - val_mse: 0.0063\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0042 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0041 - val_loss: 0.0088 - val_mse: 0.0038\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0041 - val_loss: 0.0088 - val_mse: 0.0038\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0044 - val_loss: 0.0091 - val_mse: 0.0041\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0041 - val_loss: 0.0090 - val_mse: 0.0040\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0039 - val_loss: 0.0123 - val_mse: 0.0073\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0040 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0042 - val_loss: 0.0086 - val_mse: 0.0036\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0041 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0039 - val_loss: 0.0129 - val_mse: 0.0079\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0041 - val_loss: 0.0085 - val_mse: 0.0035\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0036\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0035\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0039 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0038 - val_loss: 0.0083 - val_mse: 0.0034\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0034\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0033\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0034\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0033\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0034\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0032\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0082 - val_mse: 0.0033\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0081 - val_mse: 0.0032\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0089 - val_mse: 0.0040\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0035 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0034\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0084 - val_mse: 0.0035\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0035 - val_loss: 0.0098 - val_mse: 0.0049\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0097 - val_mse: 0.0048\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0034 - val_loss: 0.0080 - val_mse: 0.0031\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0032\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0034 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0037 - val_loss: 0.0078 - val_mse: 0.0030\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0036 - val_loss: 0.0079 - val_mse: 0.0031\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0036 - val_loss: 0.0079 - val_mse: 0.0030\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0079 - val_mse: 0.0031\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0035 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0034 - val_loss: 0.0078 - val_mse: 0.0029\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0084 - val_mse: 0.0036\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0033\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0078 - val_mse: 0.0031\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0034 - val_loss: 0.0076 - val_mse: 0.0028\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0034 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0083 - val_mse: 0.0035\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0034 - val_loss: 0.0075 - val_mse: 0.0028\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0083 - val_mse: 0.0036\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0033 - val_loss: 0.0076 - val_mse: 0.0029\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0032 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0076 - val_mse: 0.0029\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0078 - val_mse: 0.0030\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0076 - val_mse: 0.0029\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0081 - val_mse: 0.0034\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0079 - val_mse: 0.0032\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0078 - val_mse: 0.0030\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0027\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0074 - val_mse: 0.0027\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0079 - val_mse: 0.0032\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0075 - val_mse: 0.0028\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0076 - val_mse: 0.0029\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0028 - val_loss: 0.0073 - val_mse: 0.0026\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0031 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0030\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0032 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0032 - val_loss: 0.0073 - val_mse: 0.0026\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0030 - val_loss: 0.0075 - val_mse: 0.0029\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0030 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0029 - val_loss: 0.0074 - val_mse: 0.0027\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0031 - val_loss: 0.0078 - val_mse: 0.0031\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0030 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0030 - val_loss: 0.0072 - val_mse: 0.0025\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0031\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0029 - val_loss: 0.0071 - val_mse: 0.0025\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0030 - val_loss: 0.0071 - val_mse: 0.0024\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0027 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0079 - val_mse: 0.0033\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0071 - val_mse: 0.0025\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0029 - val_loss: 0.0073 - val_mse: 0.0027\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0028 - val_loss: 0.0072 - val_mse: 0.0027\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0075 - val_mse: 0.0029\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0029 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0030 - val_loss: 0.0073 - val_mse: 0.0028\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0028 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0070 - val_mse: 0.0024\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0071 - val_mse: 0.0025\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0068 - val_mse: 0.0023\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0068 - val_mse: 0.0023\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0071 - val_mse: 0.0026\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0080 - val_mse: 0.0034\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0027 - val_loss: 0.0070 - val_mse: 0.0025\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0074 - val_mse: 0.0029\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0068 - val_mse: 0.0022\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0070 - val_mse: 0.0025\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0022\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0068 - val_mse: 0.0023\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0022\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0078 - val_mse: 0.0033\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0067 - val_mse: 0.0022\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0068 - val_mse: 0.0023\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0023\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0023\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0026 - val_loss: 0.0071 - val_mse: 0.0026\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0028 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0027 - val_loss: 0.0068 - val_mse: 0.0024\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0026 - val_loss: 0.0067 - val_mse: 0.0022\n",
      "Epoch 212: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1076 - mse: 0.1044 - val_loss: 0.0632 - val_mse: 0.0600\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0896 - mse: 0.0863 - val_loss: 0.0534 - val_mse: 0.0502\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0821 - mse: 0.0788 - val_loss: 0.0744 - val_mse: 0.0711\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0773 - mse: 0.0739 - val_loss: 0.0433 - val_mse: 0.0399\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0631 - val_loss: 0.0371 - val_mse: 0.0336\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0492 - val_loss: 0.0294 - val_mse: 0.0257\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0362 - val_loss: 0.0253 - val_mse: 0.0214\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0281 - val_loss: 0.0279 - val_mse: 0.0239\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0263 - val_loss: 0.0259 - val_mse: 0.0218\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0246 - val_loss: 0.0302 - val_mse: 0.0262\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0236 - val_loss: 0.0282 - val_mse: 0.0241\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0227 - val_loss: 0.0247 - val_mse: 0.0206\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0220 - val_loss: 0.0223 - val_mse: 0.0183\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0208 - val_loss: 0.0231 - val_mse: 0.0191\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0208 - val_loss: 0.0219 - val_mse: 0.0179\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0205 - val_loss: 0.0213 - val_mse: 0.0172\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0195 - val_loss: 0.0207 - val_mse: 0.0167\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0193 - val_loss: 0.0215 - val_mse: 0.0175\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0188 - val_loss: 0.0204 - val_mse: 0.0164\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0184 - val_loss: 0.0220 - val_mse: 0.0180\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0178 - val_loss: 0.0199 - val_mse: 0.0158\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0183 - val_loss: 0.0205 - val_mse: 0.0164\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0176 - val_loss: 0.0197 - val_mse: 0.0156\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0175 - val_loss: 0.0208 - val_mse: 0.0168\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0177 - val_loss: 0.0192 - val_mse: 0.0151\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0169 - val_loss: 0.0193 - val_mse: 0.0153\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0164 - val_loss: 0.0184 - val_mse: 0.0144\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0162 - val_loss: 0.0195 - val_mse: 0.0154\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0163 - val_loss: 0.0186 - val_mse: 0.0146\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0165 - val_loss: 0.0179 - val_mse: 0.0138\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0153 - val_loss: 0.0250 - val_mse: 0.0210\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0157 - val_loss: 0.0178 - val_mse: 0.0137\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0149 - val_loss: 0.0176 - val_mse: 0.0135\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0152 - val_loss: 0.0177 - val_mse: 0.0137\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0152 - val_loss: 0.0214 - val_mse: 0.0173\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0149 - val_loss: 0.0178 - val_mse: 0.0138\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0146 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0145 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0143 - val_loss: 0.0165 - val_mse: 0.0125\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0141 - val_loss: 0.0179 - val_mse: 0.0139\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0138 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0140 - val_loss: 0.0183 - val_mse: 0.0143\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0140 - val_loss: 0.0165 - val_mse: 0.0125\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0139 - val_loss: 0.0164 - val_mse: 0.0123\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0132 - val_loss: 0.0162 - val_mse: 0.0121\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0138 - val_loss: 0.0205 - val_mse: 0.0164\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0136 - val_loss: 0.0156 - val_mse: 0.0116\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0131 - val_loss: 0.0155 - val_mse: 0.0114\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0131 - val_loss: 0.0187 - val_mse: 0.0147\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0124 - val_loss: 0.0156 - val_mse: 0.0116\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0127 - val_loss: 0.0159 - val_mse: 0.0119\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0130 - val_loss: 0.0198 - val_mse: 0.0158\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0135 - val_loss: 0.0153 - val_mse: 0.0113\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0125 - val_loss: 0.0157 - val_mse: 0.0117\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0126 - val_loss: 0.0149 - val_mse: 0.0109\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0122 - val_loss: 0.0149 - val_mse: 0.0108\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0123 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0129 - val_loss: 0.0160 - val_mse: 0.0120\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0121 - val_loss: 0.0185 - val_mse: 0.0144\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0122 - val_loss: 0.0159 - val_mse: 0.0118\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0120 - val_loss: 0.0153 - val_mse: 0.0113\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0119 - val_loss: 0.0160 - val_mse: 0.0120\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0116 - val_loss: 0.0148 - val_mse: 0.0108\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0122 - val_loss: 0.0166 - val_mse: 0.0126\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0126 - val_loss: 0.0150 - val_mse: 0.0109\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0125 - val_loss: 0.0144 - val_mse: 0.0104\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0119 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0118 - val_loss: 0.0152 - val_mse: 0.0112\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0128 - val_loss: 0.0153 - val_mse: 0.0113\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0121 - val_loss: 0.0143 - val_mse: 0.0103\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0118 - val_loss: 0.0170 - val_mse: 0.0130\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0115 - val_loss: 0.0141 - val_mse: 0.0100\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0116 - val_loss: 0.0141 - val_mse: 0.0101\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0119 - val_loss: 0.0156 - val_mse: 0.0116\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0119 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0115 - val_loss: 0.0142 - val_mse: 0.0102\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0125 - val_loss: 0.0141 - val_mse: 0.0101\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0177 - val_mse: 0.0137\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0113 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0118 - val_loss: 0.0139 - val_mse: 0.0099\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0101\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0111 - val_loss: 0.0147 - val_mse: 0.0107\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0112 - val_loss: 0.0139 - val_mse: 0.0099\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0111 - val_loss: 0.0154 - val_mse: 0.0115\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0113 - val_loss: 0.0139 - val_mse: 0.0099\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0120 - val_loss: 0.0187 - val_mse: 0.0147\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0142 - val_mse: 0.0103\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0107 - val_loss: 0.0139 - val_mse: 0.0100\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0111 - val_loss: 0.0143 - val_mse: 0.0104\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0110 - val_loss: 0.0140 - val_mse: 0.0100\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0112 - val_loss: 0.0152 - val_mse: 0.0113\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0111 - val_loss: 0.0136 - val_mse: 0.0096\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0111 - val_loss: 0.0137 - val_mse: 0.0097\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0112 - val_loss: 0.0136 - val_mse: 0.0097\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0115 - val_loss: 0.0143 - val_mse: 0.0104\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0112 - val_loss: 0.0135 - val_mse: 0.0096\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0110 - val_loss: 0.0140 - val_mse: 0.0101\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0105 - val_loss: 0.0135 - val_mse: 0.0096\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0110 - val_loss: 0.0160 - val_mse: 0.0121\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0121 - val_loss: 0.0135 - val_mse: 0.0095\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0155 - val_mse: 0.0116\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0114 - val_loss: 0.0146 - val_mse: 0.0107\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0107 - val_loss: 0.0134 - val_mse: 0.0095\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0110 - val_loss: 0.0146 - val_mse: 0.0107\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0107 - val_loss: 0.0157 - val_mse: 0.0118\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0105 - val_loss: 0.0158 - val_mse: 0.0119\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0149 - val_mse: 0.0110\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0107 - val_loss: 0.0160 - val_mse: 0.0122\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0103 - val_loss: 0.0141 - val_mse: 0.0102\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0105 - val_loss: 0.0133 - val_mse: 0.0094\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0142 - val_mse: 0.0103\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0154 - val_mse: 0.0115\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0103 - val_loss: 0.0133 - val_mse: 0.0094\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0104 - val_loss: 0.0131 - val_mse: 0.0093\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0108 - val_loss: 0.0140 - val_mse: 0.0102\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0106 - val_loss: 0.0154 - val_mse: 0.0115\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0103 - val_loss: 0.0135 - val_mse: 0.0096\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0108 - val_loss: 0.0159 - val_mse: 0.0120\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0108 - val_loss: 0.0136 - val_mse: 0.0097\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0103 - val_loss: 0.0136 - val_mse: 0.0097\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0170 - val_mse: 0.0131\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0101 - val_loss: 0.0138 - val_mse: 0.0100\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0103 - val_loss: 0.0179 - val_mse: 0.0141\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0108 - val_loss: 0.0197 - val_mse: 0.0159\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0103 - val_loss: 0.0132 - val_mse: 0.0093\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0102 - val_loss: 0.0170 - val_mse: 0.0132\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0099 - val_loss: 0.0159 - val_mse: 0.0121\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0106 - val_loss: 0.0129 - val_mse: 0.0091\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0102 - val_loss: 0.0152 - val_mse: 0.0113\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0107 - val_loss: 0.0169 - val_mse: 0.0130\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0109 - val_loss: 0.0150 - val_mse: 0.0112\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0100 - val_loss: 0.0140 - val_mse: 0.0102\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0100 - val_loss: 0.0145 - val_mse: 0.0107\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0096 - val_loss: 0.0129 - val_mse: 0.0090\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0101 - val_loss: 0.0128 - val_mse: 0.0090\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0103 - val_loss: 0.0158 - val_mse: 0.0120\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0100 - val_loss: 0.0146 - val_mse: 0.0108\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0098 - val_loss: 0.0151 - val_mse: 0.0113\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0100 - val_loss: 0.0127 - val_mse: 0.0089\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0098 - val_loss: 0.0130 - val_mse: 0.0092\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0099 - val_loss: 0.0143 - val_mse: 0.0105\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0087\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0098 - val_loss: 0.0132 - val_mse: 0.0094\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0097 - val_loss: 0.0131 - val_mse: 0.0093\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0102 - val_loss: 0.0127 - val_mse: 0.0089\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0137 - val_mse: 0.0099\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0099 - val_loss: 0.0127 - val_mse: 0.0090\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0101 - val_loss: 0.0128 - val_mse: 0.0090\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0127 - val_mse: 0.0089\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0087\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0150 - val_mse: 0.0112\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0126 - val_mse: 0.0089\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0096 - val_loss: 0.0131 - val_mse: 0.0093\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0129 - val_mse: 0.0091\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0132 - val_mse: 0.0094\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0093 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0124 - val_mse: 0.0086\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0092 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0123 - val_mse: 0.0085\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0095 - val_loss: 0.0190 - val_mse: 0.0152\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0099 - val_loss: 0.0133 - val_mse: 0.0095\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0090 - val_loss: 0.0137 - val_mse: 0.0099\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0095 - val_loss: 0.0130 - val_mse: 0.0092\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0096 - val_loss: 0.0123 - val_mse: 0.0085\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0092 - val_loss: 0.0136 - val_mse: 0.0098\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0127 - val_mse: 0.0089\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0092 - val_loss: 0.0125 - val_mse: 0.0087\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0123 - val_mse: 0.0085\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0094 - val_loss: 0.0122 - val_mse: 0.0084\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0089 - val_loss: 0.0129 - val_mse: 0.0091\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0091 - val_loss: 0.0122 - val_mse: 0.0084\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0091 - val_loss: 0.0124 - val_mse: 0.0086\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0091 - val_loss: 0.0137 - val_mse: 0.0099\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0090 - val_loss: 0.0123 - val_mse: 0.0084\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0090 - val_loss: 0.0129 - val_mse: 0.0091\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0089 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0092 - val_loss: 0.0153 - val_mse: 0.0115\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0087 - val_loss: 0.0124 - val_mse: 0.0085\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0086 - val_loss: 0.0168 - val_mse: 0.0130\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0087 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0087 - val_loss: 0.0145 - val_mse: 0.0107\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0090 - val_loss: 0.0143 - val_mse: 0.0104\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0089 - val_loss: 0.0123 - val_mse: 0.0085\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0089 - val_loss: 0.0137 - val_mse: 0.0099\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0089 - val_loss: 0.0121 - val_mse: 0.0083\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0122 - val_mse: 0.0084\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0088 - val_loss: 0.0121 - val_mse: 0.0082\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0086 - val_loss: 0.0164 - val_mse: 0.0126\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0087 - val_loss: 0.0141 - val_mse: 0.0103\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0166 - val_mse: 0.0127\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0125 - val_mse: 0.0087\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0126 - val_mse: 0.0088\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0084 - val_loss: 0.0127 - val_mse: 0.0088\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0094 - val_loss: 0.0121 - val_mse: 0.0082\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0086 - val_loss: 0.0132 - val_mse: 0.0093\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0081 - val_loss: 0.0124 - val_mse: 0.0085\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0089 - val_loss: 0.0126 - val_mse: 0.0087\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0131 - val_mse: 0.0092\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0081 - val_loss: 0.0125 - val_mse: 0.0086\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0083 - val_loss: 0.0151 - val_mse: 0.0112\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0082 - val_loss: 0.0119 - val_mse: 0.0080\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0083 - val_loss: 0.0120 - val_mse: 0.0081\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0081 - val_loss: 0.0141 - val_mse: 0.0102\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0086 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0084 - val_loss: 0.0118 - val_mse: 0.0079\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0144 - val_mse: 0.0105\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0087 - val_loss: 0.0118 - val_mse: 0.0079\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0083 - val_loss: 0.0141 - val_mse: 0.0102\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0084 - val_loss: 0.0120 - val_mse: 0.0081\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0077 - val_loss: 0.0130 - val_mse: 0.0091\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0078 - val_loss: 0.0134 - val_mse: 0.0095\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0082 - val_loss: 0.0118 - val_mse: 0.0079\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0079 - val_loss: 0.0118 - val_mse: 0.0079\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0080 - val_loss: 0.0141 - val_mse: 0.0101\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0080 - val_loss: 0.0117 - val_mse: 0.0078\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0080 - val_loss: 0.0129 - val_mse: 0.0089\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0128 - val_mse: 0.0088\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0079 - val_loss: 0.0120 - val_mse: 0.0081\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0115 - mse: 0.0076 - val_loss: 0.0118 - val_mse: 0.0078\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0132 - val_mse: 0.0092\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0078 - val_loss: 0.0118 - val_mse: 0.0078\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0076 - val_loss: 0.0115 - val_mse: 0.0076\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0117 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0076\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0135 - val_mse: 0.0095\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0084 - val_loss: 0.0199 - val_mse: 0.0159\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0078 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0078 - val_loss: 0.0116 - val_mse: 0.0077\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0078 - val_loss: 0.0120 - val_mse: 0.0080\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0076\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0079 - val_loss: 0.0122 - val_mse: 0.0082\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0077 - val_loss: 0.0124 - val_mse: 0.0084\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0132 - val_mse: 0.0092\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0077 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0138 - val_mse: 0.0098\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0118 - val_mse: 0.0078\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0072 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0117 - mse: 0.0076 - val_loss: 0.0113 - val_mse: 0.0073\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0112 - mse: 0.0072 - val_loss: 0.0131 - val_mse: 0.0091\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0074 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0119 - val_mse: 0.0079\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0074 - val_loss: 0.0119 - val_mse: 0.0079\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0112 - val_mse: 0.0072\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0073 - val_loss: 0.0112 - val_mse: 0.0072\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0074 - val_loss: 0.0123 - val_mse: 0.0083\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0074 - val_loss: 0.0113 - val_mse: 0.0073\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0072 - val_loss: 0.0125 - val_mse: 0.0085\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0124 - val_mse: 0.0083\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0126 - val_mse: 0.0085\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0072 - val_loss: 0.0122 - val_mse: 0.0082\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0072 - val_loss: 0.0112 - val_mse: 0.0072\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0126 - val_mse: 0.0085\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0111 - val_mse: 0.0071\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0126 - val_mse: 0.0086\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0146 - val_mse: 0.0105\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0074 - val_loss: 0.0113 - val_mse: 0.0073\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0073 - val_loss: 0.0109 - val_mse: 0.0068\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0111 - val_mse: 0.0070\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0109 - val_mse: 0.0069\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0108 - val_mse: 0.0067\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0120 - val_mse: 0.0080\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0107 - val_mse: 0.0067\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0109 - val_mse: 0.0069\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0072 - val_loss: 0.0108 - val_mse: 0.0067\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0110 - val_mse: 0.0070\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0107 - val_mse: 0.0066\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0111 - val_mse: 0.0070\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0129 - val_mse: 0.0089\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0108 - val_mse: 0.0067\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0106 - val_mse: 0.0065\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0112 - val_mse: 0.0072\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0116 - val_mse: 0.0076\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0112 - val_mse: 0.0071\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0063\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0111 - val_mse: 0.0070\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0067\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0102 - val_mse: 0.0062\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0104 - val_mse: 0.0063\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0102 - val_mse: 0.0062\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0101 - val_mse: 0.0061\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0102 - val_mse: 0.0061\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0119 - val_mse: 0.0078\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0104 - val_mse: 0.0063\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0100 - val_mse: 0.0060\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0106 - val_mse: 0.0065\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0103 - val_mse: 0.0062\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0101 - val_mse: 0.0060\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0112 - val_mse: 0.0072\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0099 - val_mse: 0.0058\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0103 - val_mse: 0.0062\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0099 - val_mse: 0.0059\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0109 - val_mse: 0.0069\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0099 - val_mse: 0.0058\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0057 - val_loss: 0.0104 - val_mse: 0.0064\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0097 - val_mse: 0.0057\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0102 - val_mse: 0.0062\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0104 - val_mse: 0.0064\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0100 - val_mse: 0.0059\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0056 - val_loss: 0.0102 - val_mse: 0.0061\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0096 - val_mse: 0.0056\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0106 - val_mse: 0.0066\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0059 - val_loss: 0.0103 - val_mse: 0.0063\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0100 - val_mse: 0.0059\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0056 - val_loss: 0.0098 - val_mse: 0.0057\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0056 - val_loss: 0.0103 - val_mse: 0.0062\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0101 - val_mse: 0.0061\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0055 - val_loss: 0.0093 - val_mse: 0.0052\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0056 - val_loss: 0.0147 - val_mse: 0.0107\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0054 - val_loss: 0.0097 - val_mse: 0.0056\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0053 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0053 - val_loss: 0.0100 - val_mse: 0.0060\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0055 - val_loss: 0.0092 - val_mse: 0.0052\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0056 - val_loss: 0.0160 - val_mse: 0.0120\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0091 - val_mse: 0.0050\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0053 - val_loss: 0.0097 - val_mse: 0.0057\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0090\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0054 - val_loss: 0.0090 - val_mse: 0.0050\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0051 - val_loss: 0.0090 - val_mse: 0.0050\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0051 - val_loss: 0.0090 - val_mse: 0.0050\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0052 - val_loss: 0.0089 - val_mse: 0.0049\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0054 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0053 - val_loss: 0.0095 - val_mse: 0.0055\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0091 - mse: 0.0051 - val_loss: 0.0088 - val_mse: 0.0047\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0050 - val_loss: 0.0091 - val_mse: 0.0051\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0051 - val_loss: 0.0090 - val_mse: 0.0050\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0050 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0050 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0048 - val_loss: 0.0089 - val_mse: 0.0048\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0049 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0091 - val_mse: 0.0051\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0048 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0049 - val_loss: 0.0086 - val_mse: 0.0046\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0050 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0049 - val_loss: 0.0113 - val_mse: 0.0072\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0046 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0048 - val_loss: 0.0123 - val_mse: 0.0083\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0048 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0048 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0052 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0047 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0045 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0048 - val_loss: 0.0088 - val_mse: 0.0047\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0046 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0084 - mse: 0.0044 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0044 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0047 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0042 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0043 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0046 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0043 - val_loss: 0.0089 - val_mse: 0.0048\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0047 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0045 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0043 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0045 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0043 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0042 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0042 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0040 - val_loss: 0.0084 - val_mse: 0.0044\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0039 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0039 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0039 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0038 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0078 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0032\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0089 - val_mse: 0.0048\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0037 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0070 - val_mse: 0.0029\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0093 - val_mse: 0.0053\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0072 - mse: 0.0032 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0066 - val_mse: 0.0026\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0026\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0065 - val_mse: 0.0025\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0030\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0024\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0029 - val_loss: 0.0065 - val_mse: 0.0025\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0024\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0024\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0065 - val_mse: 0.0025\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0028 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0033\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0023\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0029 - val_loss: 0.0063 - val_mse: 0.0023\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0027 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0028 - val_loss: 0.0073 - val_mse: 0.0033\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0027 - val_loss: 0.0072 - val_mse: 0.0033\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0028 - val_loss: 0.0070 - val_mse: 0.0031\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0070 - val_mse: 0.0031\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0026 - val_loss: 0.0062 - val_mse: 0.0023\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0062 - val_mse: 0.0023\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0062 - val_mse: 0.0022\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0027 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0027 - val_loss: 0.0061 - val_mse: 0.0021\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0066 - val_mse: 0.0026\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0026 - val_loss: 0.0062 - val_mse: 0.0023\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0060 - val_mse: 0.0021\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0066 - mse: 0.0027 - val_loss: 0.0060 - val_mse: 0.0021\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0026 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0061 - val_mse: 0.0022\n",
      "Epoch 493: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1159 - mse: 0.1115 - val_loss: 0.0497 - val_mse: 0.0453\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0787 - mse: 0.0743 - val_loss: 0.0475 - val_mse: 0.0431\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0681 - mse: 0.0636 - val_loss: 0.0359 - val_mse: 0.0314\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0520 - mse: 0.0474 - val_loss: 0.0499 - val_mse: 0.0452\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0399 - mse: 0.0352 - val_loss: 0.0227 - val_mse: 0.0180\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0310 - mse: 0.0262 - val_loss: 0.0241 - val_mse: 0.0193\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0278 - mse: 0.0229 - val_loss: 0.0197 - val_mse: 0.0148\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0206 - val_loss: 0.0199 - val_mse: 0.0150\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0267 - mse: 0.0218 - val_loss: 0.0210 - val_mse: 0.0160\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0192 - val_loss: 0.0198 - val_mse: 0.0149\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0185 - val_loss: 0.0242 - val_mse: 0.0193\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0179 - val_loss: 0.0218 - val_mse: 0.0168\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0175 - val_loss: 0.0213 - val_mse: 0.0163\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0179 - val_loss: 0.0183 - val_mse: 0.0133\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0162 - val_loss: 0.0189 - val_mse: 0.0139\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0155 - val_loss: 0.0181 - val_mse: 0.0130\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0152 - val_loss: 0.0259 - val_mse: 0.0208\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0153 - val_loss: 0.0172 - val_mse: 0.0122\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0142 - val_loss: 0.0171 - val_mse: 0.0121\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0116\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0136 - val_loss: 0.0181 - val_mse: 0.0130\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0130 - val_loss: 0.0174 - val_mse: 0.0123\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0134 - val_loss: 0.0198 - val_mse: 0.0147\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0129 - val_loss: 0.0164 - val_mse: 0.0113\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0122 - val_loss: 0.0242 - val_mse: 0.0191\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0116 - val_loss: 0.0170 - val_mse: 0.0119\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0113 - val_loss: 0.0170 - val_mse: 0.0119\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0110 - val_loss: 0.0282 - val_mse: 0.0230\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0112 - val_loss: 0.0150 - val_mse: 0.0099\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0110 - val_loss: 0.0162 - val_mse: 0.0111\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0101 - val_loss: 0.0148 - val_mse: 0.0096\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0104 - val_loss: 0.0151 - val_mse: 0.0100\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0100 - val_loss: 0.0147 - val_mse: 0.0096\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0095 - val_loss: 0.0144 - val_mse: 0.0092\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0097 - val_loss: 0.0141 - val_mse: 0.0089\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0096 - val_loss: 0.0144 - val_mse: 0.0092\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0087 - val_loss: 0.0140 - val_mse: 0.0088\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0085 - val_loss: 0.0143 - val_mse: 0.0091\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0089 - val_loss: 0.0142 - val_mse: 0.0090\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0084 - val_loss: 0.0135 - val_mse: 0.0083\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0083 - val_loss: 0.0133 - val_mse: 0.0081\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0085 - val_loss: 0.0135 - val_mse: 0.0082\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0084 - val_loss: 0.0139 - val_mse: 0.0087\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0136 - val_mse: 0.0084\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0081 - val_loss: 0.0134 - val_mse: 0.0081\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0079 - val_loss: 0.0133 - val_mse: 0.0080\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0147 - val_mse: 0.0095\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0131 - val_mse: 0.0079\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0140 - val_mse: 0.0088\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0077 - val_loss: 0.0125 - val_mse: 0.0073\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0131 - val_mse: 0.0078\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0072 - val_loss: 0.0129 - val_mse: 0.0077\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0124 - val_mse: 0.0071\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0129 - val_mse: 0.0076\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0123 - val_mse: 0.0070\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0070 - val_loss: 0.0140 - val_mse: 0.0087\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0068 - val_loss: 0.0125 - val_mse: 0.0072\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0121 - mse: 0.0068 - val_loss: 0.0134 - val_mse: 0.0081\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0121 - mse: 0.0068 - val_loss: 0.0178 - val_mse: 0.0125\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0071 - val_loss: 0.0126 - val_mse: 0.0073\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0118 - val_mse: 0.0065\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0121 - val_mse: 0.0068\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0066 - val_loss: 0.0117 - val_mse: 0.0065\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0068 - val_loss: 0.0135 - val_mse: 0.0082\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0136 - val_mse: 0.0084\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0136 - val_mse: 0.0083\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0066 - val_loss: 0.0116 - val_mse: 0.0063\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0065 - val_loss: 0.0117 - val_mse: 0.0064\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0060 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0060 - val_loss: 0.0116 - val_mse: 0.0063\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0064 - val_loss: 0.0138 - val_mse: 0.0085\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0060 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0062 - val_loss: 0.0136 - val_mse: 0.0083\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0064 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0058 - val_loss: 0.0132 - val_mse: 0.0079\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0129 - val_mse: 0.0076\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0059 - val_loss: 0.0130 - val_mse: 0.0077\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0058 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0059 - val_loss: 0.0120 - val_mse: 0.0067\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0057 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0059 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0058 - val_loss: 0.0108 - val_mse: 0.0055\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0062 - val_loss: 0.0118 - val_mse: 0.0065\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0059 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0058 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0055 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0110 - mse: 0.0057 - val_loss: 0.0137 - val_mse: 0.0084\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0056 - val_loss: 0.0113 - val_mse: 0.0060\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - mse: 0.0056 - val_loss: 0.0109 - val_mse: 0.0056\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0055 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0122 - val_mse: 0.0069\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0075\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0057 - val_loss: 0.0108 - val_mse: 0.0055\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0055 - val_loss: 0.0109 - val_mse: 0.0057\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0052 - val_loss: 0.0168 - val_mse: 0.0115\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0126 - val_mse: 0.0073\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0053 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0052 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0050 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0049 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0052 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0049 - val_loss: 0.0113 - val_mse: 0.0060\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0049 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0050 - val_loss: 0.0127 - val_mse: 0.0074\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0047 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0047 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0108 - val_mse: 0.0056\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0049 - val_loss: 0.0117 - val_mse: 0.0065\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0098 - val_mse: 0.0045\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0051 - val_loss: 0.0117 - val_mse: 0.0064\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0047 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0047 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0048 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0046 - val_loss: 0.0096 - val_mse: 0.0043\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0047 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0048 - val_loss: 0.0118 - val_mse: 0.0065\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0047 - val_loss: 0.0096 - val_mse: 0.0043\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0044 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0046 - val_loss: 0.0096 - val_mse: 0.0043\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0044 - val_loss: 0.0093 - val_mse: 0.0041\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0041\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0040\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0044 - val_loss: 0.0093 - val_mse: 0.0041\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0110 - val_mse: 0.0058\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0044 - val_loss: 0.0099 - val_mse: 0.0047\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0046 - val_loss: 0.0092 - val_mse: 0.0039\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0043 - val_loss: 0.0091 - val_mse: 0.0039\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0044 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0046 - val_loss: 0.0093 - val_mse: 0.0041\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0044\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0045 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0043 - val_loss: 0.0090 - val_mse: 0.0038\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0041 - val_loss: 0.0089 - val_mse: 0.0037\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0043 - val_loss: 0.0096 - val_mse: 0.0044\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0043 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0089 - val_mse: 0.0038\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0041 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0045 - val_loss: 0.0088 - val_mse: 0.0036\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0041 - val_loss: 0.0089 - val_mse: 0.0037\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0093 - val_mse: 0.0041\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0036\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0041 - val_loss: 0.0087 - val_mse: 0.0036\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0041 - val_loss: 0.0089 - val_mse: 0.0037\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0040 - val_loss: 0.0088 - val_mse: 0.0036\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0040\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0088 - val_mse: 0.0037\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0042 - val_loss: 0.0087 - val_mse: 0.0035\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0041 - val_loss: 0.0109 - val_mse: 0.0058\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0038 - val_loss: 0.0092 - val_mse: 0.0040\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0040 - val_loss: 0.0086 - val_mse: 0.0034\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0090 - val_mse: 0.0038\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0034\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0104 - val_mse: 0.0053\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0039 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0039 - val_loss: 0.0091 - val_mse: 0.0040\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0037 - val_loss: 0.0086 - val_mse: 0.0035\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0033\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0034\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0041 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0039 - val_loss: 0.0086 - val_mse: 0.0035\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0090 - val_mse: 0.0039\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0036 - val_loss: 0.0083 - val_mse: 0.0032\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0088 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0032\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0088 - mse: 0.0037 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0041 - val_loss: 0.0085 - val_mse: 0.0034\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0083 - val_mse: 0.0032\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0041 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0036 - val_loss: 0.0082 - val_mse: 0.0031\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0036 - val_loss: 0.0110 - val_mse: 0.0059\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0036 - val_loss: 0.0082 - val_mse: 0.0031\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0038 - val_loss: 0.0081 - val_mse: 0.0031\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0031\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0030\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0034 - val_loss: 0.0085 - val_mse: 0.0034\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0035 - val_loss: 0.0081 - val_mse: 0.0031\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0038 - val_loss: 0.0081 - val_mse: 0.0030\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0036 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0031\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0082 - val_mse: 0.0031\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0038 - val_loss: 0.0103 - val_mse: 0.0053\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0034 - val_loss: 0.0081 - val_mse: 0.0031\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0029\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0029\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0035 - val_loss: 0.0092 - val_mse: 0.0042\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0034 - val_loss: 0.0084 - val_mse: 0.0034\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0037 - val_loss: 0.0085 - val_mse: 0.0035\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0033 - val_loss: 0.0088 - val_mse: 0.0038\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0033 - val_loss: 0.0090 - val_mse: 0.0040\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0034 - val_loss: 0.0088 - val_mse: 0.0038\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0085 - val_mse: 0.0035\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0083 - val_mse: 0.0033\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0034 - val_loss: 0.0080 - val_mse: 0.0030\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0078 - val_mse: 0.0028\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0077 - val_mse: 0.0028\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0033 - val_loss: 0.0079 - val_mse: 0.0029\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0035 - val_loss: 0.0085 - val_mse: 0.0035\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0033 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0090 - val_mse: 0.0040\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0035 - val_loss: 0.0088 - val_mse: 0.0039\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0084 - val_mse: 0.0035\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0082 - val_mse: 0.0032\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0035 - val_loss: 0.0079 - val_mse: 0.0030\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0083 - val_mse: 0.0034\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0032 - val_loss: 0.0078 - val_mse: 0.0028\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0033 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0078 - val_mse: 0.0028\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0034 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0088 - val_mse: 0.0038\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0077 - val_mse: 0.0027\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0034 - val_loss: 0.0077 - val_mse: 0.0027\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0079 - val_mse: 0.0029\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0075 - val_mse: 0.0026\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0031 - val_loss: 0.0138 - val_mse: 0.0088\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0033 - val_loss: 0.0080 - val_mse: 0.0031\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0076 - val_mse: 0.0027\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0032 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0026\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0031 - val_loss: 0.0079 - val_mse: 0.0030\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0085 - val_mse: 0.0036\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0078 - val_mse: 0.0030\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0080 - mse: 0.0031 - val_loss: 0.0082 - val_mse: 0.0034\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0074 - val_mse: 0.0025\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0031 - val_loss: 0.0118 - val_mse: 0.0069\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0087 - val_mse: 0.0038\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0076 - val_mse: 0.0027\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0080 - val_mse: 0.0032\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0081 - val_mse: 0.0033\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0081 - val_mse: 0.0033\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0031 - val_loss: 0.0073 - val_mse: 0.0025\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0074 - val_mse: 0.0025\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0028\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0074 - val_mse: 0.0026\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0074 - val_mse: 0.0026\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0073 - val_mse: 0.0025\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0028\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0077 - val_mse: 0.0028\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0030 - val_loss: 0.0084 - val_mse: 0.0036\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0026\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0028 - val_loss: 0.0079 - val_mse: 0.0031\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0024\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0024\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0031 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0030 - val_loss: 0.0077 - val_mse: 0.0030\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0032 - val_loss: 0.0074 - val_mse: 0.0026\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0032 - val_loss: 0.0077 - val_mse: 0.0029\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0075 - val_mse: 0.0028\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0080 - val_mse: 0.0032\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0024\n",
      "Epoch 260: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1305 - mse: 0.1274 - val_loss: 0.0604 - val_mse: 0.0573\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0894 - val_loss: 0.0543 - val_mse: 0.0512\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0909 - mse: 0.0878 - val_loss: 0.0601 - val_mse: 0.0571\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0893 - mse: 0.0863 - val_loss: 0.0580 - val_mse: 0.0549\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0866 - mse: 0.0835 - val_loss: 0.0538 - val_mse: 0.0507\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0806 - mse: 0.0775 - val_loss: 0.0593 - val_mse: 0.0562\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0775 - mse: 0.0744 - val_loss: 0.0435 - val_mse: 0.0403\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0639 - mse: 0.0607 - val_loss: 0.0382 - val_mse: 0.0349\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0473 - val_loss: 0.0324 - val_mse: 0.0289\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0326 - val_loss: 0.0224 - val_mse: 0.0188\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0254 - val_loss: 0.0232 - val_mse: 0.0196\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0217 - val_loss: 0.0191 - val_mse: 0.0154\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0207 - val_loss: 0.0194 - val_mse: 0.0156\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0197 - val_loss: 0.0198 - val_mse: 0.0161\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0185 - val_loss: 0.0249 - val_mse: 0.0212\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0183 - val_loss: 0.0179 - val_mse: 0.0141\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0179 - val_loss: 0.0195 - val_mse: 0.0157\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0168 - val_loss: 0.0169 - val_mse: 0.0131\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0160 - val_loss: 0.0166 - val_mse: 0.0128\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0157 - val_loss: 0.0161 - val_mse: 0.0123\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0153 - val_loss: 0.0159 - val_mse: 0.0121\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0149 - val_loss: 0.0156 - val_mse: 0.0118\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0143 - val_loss: 0.0170 - val_mse: 0.0132\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0143 - val_loss: 0.0154 - val_mse: 0.0115\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0135 - val_loss: 0.0162 - val_mse: 0.0123\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0115\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0141 - val_loss: 0.0189 - val_mse: 0.0150\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0133 - val_loss: 0.0154 - val_mse: 0.0114\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0127 - val_loss: 0.0146 - val_mse: 0.0107\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0124 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0123 - val_loss: 0.0150 - val_mse: 0.0110\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0122 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0117 - val_loss: 0.0180 - val_mse: 0.0140\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0118 - val_loss: 0.0141 - val_mse: 0.0101\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0115 - val_loss: 0.0197 - val_mse: 0.0158\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0120 - val_loss: 0.0183 - val_mse: 0.0143\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0116 - val_loss: 0.0173 - val_mse: 0.0133\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0116 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0118 - val_loss: 0.0154 - val_mse: 0.0114\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0116 - val_loss: 0.0156 - val_mse: 0.0116\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0153 - val_mse: 0.0113\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0113 - val_loss: 0.0154 - val_mse: 0.0114\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0113 - val_loss: 0.0158 - val_mse: 0.0118\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0107 - val_loss: 0.0135 - val_mse: 0.0094\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0135 - val_mse: 0.0095\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0108 - val_loss: 0.0138 - val_mse: 0.0098\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0114 - val_loss: 0.0205 - val_mse: 0.0165\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0171 - val_mse: 0.0130\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0116 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0106 - val_loss: 0.0132 - val_mse: 0.0092\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0110 - val_loss: 0.0143 - val_mse: 0.0103\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0107 - val_loss: 0.0129 - val_mse: 0.0089\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0130 - val_mse: 0.0089\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0108 - val_loss: 0.0190 - val_mse: 0.0150\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0111 - val_loss: 0.0128 - val_mse: 0.0088\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0109 - val_loss: 0.0128 - val_mse: 0.0088\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0103 - val_loss: 0.0129 - val_mse: 0.0089\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0104 - val_loss: 0.0140 - val_mse: 0.0099\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0106 - val_loss: 0.0126 - val_mse: 0.0086\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0105 - val_loss: 0.0126 - val_mse: 0.0086\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0102 - val_loss: 0.0127 - val_mse: 0.0087\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0103 - val_loss: 0.0126 - val_mse: 0.0086\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0104 - val_loss: 0.0126 - val_mse: 0.0086\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0100 - val_loss: 0.0145 - val_mse: 0.0105\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0102 - val_loss: 0.0144 - val_mse: 0.0104\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0097 - val_loss: 0.0128 - val_mse: 0.0088\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0095 - val_loss: 0.0135 - val_mse: 0.0095\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0099 - val_loss: 0.0123 - val_mse: 0.0083\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0094 - val_loss: 0.0126 - val_mse: 0.0085\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0084\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0092 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0095 - val_loss: 0.0131 - val_mse: 0.0091\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0095 - val_loss: 0.0158 - val_mse: 0.0118\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0095 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0096 - val_loss: 0.0128 - val_mse: 0.0088\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0095 - val_loss: 0.0122 - val_mse: 0.0082\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0096 - val_loss: 0.0136 - val_mse: 0.0096\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0092 - val_loss: 0.0121 - val_mse: 0.0081\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0093 - val_loss: 0.0117 - val_mse: 0.0077\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0076\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0093 - val_loss: 0.0117 - val_mse: 0.0077\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0090 - val_loss: 0.0169 - val_mse: 0.0129\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0091 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0083 - val_loss: 0.0120 - val_mse: 0.0080\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0086 - val_loss: 0.0117 - val_mse: 0.0077\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0073\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0084 - val_loss: 0.0127 - val_mse: 0.0087\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0088 - val_loss: 0.0110 - val_mse: 0.0070\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0120 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0071\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0151 - val_mse: 0.0111\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0082 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0079 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0121 - mse: 0.0081 - val_loss: 0.0114 - val_mse: 0.0074\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0106 - val_mse: 0.0066\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0113 - val_mse: 0.0073\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0115 - val_mse: 0.0075\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0074 - val_loss: 0.0104 - val_mse: 0.0064\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0073 - val_loss: 0.0106 - val_mse: 0.0066\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0076 - val_loss: 0.0103 - val_mse: 0.0063\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0073 - val_loss: 0.0108 - val_mse: 0.0068\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0098 - val_mse: 0.0058\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0099 - val_mse: 0.0059\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0100 - val_mse: 0.0060\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0117 - val_mse: 0.0077\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0095 - val_mse: 0.0055\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0099 - val_mse: 0.0059\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0109 - val_mse: 0.0069\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0057 - val_loss: 0.0097 - val_mse: 0.0057\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0116 - val_mse: 0.0075\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0093 - val_mse: 0.0052\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0057 - val_loss: 0.0090 - val_mse: 0.0049\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0056 - val_loss: 0.0093 - val_mse: 0.0053\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0056 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0055 - val_loss: 0.0094 - val_mse: 0.0054\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0054 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0052 - val_loss: 0.0098 - val_mse: 0.0058\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0052 - val_loss: 0.0096 - val_mse: 0.0056\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0050 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0054 - val_loss: 0.0088 - val_mse: 0.0047\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0050 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0049 - val_loss: 0.0091 - val_mse: 0.0051\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0049 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0048 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0096 - val_mse: 0.0055\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0044 - val_loss: 0.0090 - val_mse: 0.0049\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0049 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0047 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0051 - val_loss: 0.0111 - val_mse: 0.0070\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0043 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0044 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0046 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0044 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0044 - val_loss: 0.0078 - val_mse: 0.0037\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0043 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0042 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0044 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0042 - val_loss: 0.0086 - val_mse: 0.0046\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0085 - mse: 0.0044 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0044 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0043 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0040 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0123 - val_mse: 0.0083\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0042 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0041 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0040 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0038 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0039 - val_loss: 0.0075 - val_mse: 0.0034\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0040 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0038 - val_loss: 0.0097 - val_mse: 0.0057\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0041 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0038 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0073 - val_mse: 0.0033\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0074 - val_mse: 0.0033\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0073 - val_mse: 0.0033\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0076 - val_mse: 0.0035\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0038 - val_loss: 0.0073 - val_mse: 0.0032\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0033\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0036 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0035 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0071 - val_mse: 0.0031\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0038 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0039 - val_loss: 0.0076 - val_mse: 0.0036\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0037 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0034\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0036 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0036 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0073 - val_mse: 0.0033\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0091 - val_mse: 0.0051\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0037 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0034 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0034 - val_loss: 0.0072 - val_mse: 0.0032\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0036 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0036 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0070 - val_mse: 0.0030\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0076 - val_mse: 0.0037\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0035 - val_loss: 0.0068 - val_mse: 0.0029\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0035 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0037 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0034 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0032 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0034 - val_loss: 0.0091 - val_mse: 0.0051\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0034 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0067 - val_mse: 0.0027\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0033 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0028\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0032\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0032 - val_loss: 0.0095 - val_mse: 0.0056\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0069 - val_mse: 0.0029\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0066 - val_mse: 0.0026\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0093 - val_mse: 0.0054\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0032\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0029\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0033 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0032 - val_loss: 0.0066 - val_mse: 0.0028\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0066 - val_mse: 0.0027\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0030 - val_loss: 0.0072 - val_mse: 0.0033\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0034\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0072 - val_mse: 0.0034\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0032 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0031 - val_loss: 0.0075 - val_mse: 0.0036\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0066 - val_mse: 0.0028\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0026\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0029 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0062 - val_mse: 0.0023\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0065 - val_mse: 0.0026\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0063 - val_mse: 0.0025\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0030 - val_loss: 0.0062 - val_mse: 0.0024\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0028\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0028 - val_loss: 0.0063 - val_mse: 0.0024\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0062 - val_mse: 0.0023\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0031 - val_loss: 0.0064 - val_mse: 0.0025\n",
      "Epoch 261: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1259 - mse: 0.1210 - val_loss: 0.0556 - val_mse: 0.0507\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0691 - mse: 0.0642 - val_loss: 0.0431 - val_mse: 0.0381\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0465 - mse: 0.0415 - val_loss: 0.0281 - val_mse: 0.0230\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0330 - mse: 0.0278 - val_loss: 0.0281 - val_mse: 0.0229\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0252 - val_loss: 0.0262 - val_mse: 0.0210\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0225 - val_loss: 0.0262 - val_mse: 0.0209\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0218 - val_loss: 0.0214 - val_mse: 0.0161\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0217 - val_loss: 0.0219 - val_mse: 0.0166\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0195 - val_loss: 0.0229 - val_mse: 0.0176\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0183 - val_loss: 0.0201 - val_mse: 0.0148\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0184 - val_loss: 0.0197 - val_mse: 0.0143\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0175 - val_loss: 0.0198 - val_mse: 0.0145\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0163 - val_loss: 0.0188 - val_mse: 0.0134\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0152 - val_loss: 0.0200 - val_mse: 0.0147\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0144 - val_loss: 0.0188 - val_mse: 0.0135\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0140 - val_loss: 0.0211 - val_mse: 0.0158\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0129 - val_loss: 0.0173 - val_mse: 0.0119\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0122 - val_loss: 0.0171 - val_mse: 0.0118\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0125 - val_loss: 0.0165 - val_mse: 0.0112\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0113 - val_loss: 0.0162 - val_mse: 0.0108\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0116 - val_loss: 0.0160 - val_mse: 0.0106\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0107 - val_loss: 0.0189 - val_mse: 0.0135\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0109 - val_loss: 0.0196 - val_mse: 0.0142\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0098 - val_loss: 0.0151 - val_mse: 0.0097\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0098 - val_loss: 0.0146 - val_mse: 0.0092\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0094 - val_loss: 0.0147 - val_mse: 0.0093\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0091 - val_loss: 0.0148 - val_mse: 0.0094\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0090 - val_loss: 0.0144 - val_mse: 0.0090\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0086 - val_loss: 0.0142 - val_mse: 0.0088\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0079 - val_loss: 0.0133 - val_mse: 0.0078\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0081 - val_loss: 0.0171 - val_mse: 0.0117\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0132 - val_mse: 0.0078\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0133 - val_mse: 0.0078\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0126 - val_mse: 0.0072\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0124 - val_mse: 0.0070\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0070 - val_loss: 0.0127 - val_mse: 0.0072\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0071 - val_loss: 0.0130 - val_mse: 0.0075\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0071 - val_loss: 0.0141 - val_mse: 0.0086\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0123 - val_mse: 0.0069\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0120 - val_mse: 0.0065\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0064 - val_loss: 0.0126 - val_mse: 0.0071\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0066 - val_loss: 0.0118 - val_mse: 0.0063\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0066 - val_loss: 0.0116 - val_mse: 0.0062\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0067 - val_loss: 0.0123 - val_mse: 0.0068\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0064 - val_loss: 0.0129 - val_mse: 0.0074\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0060 - val_loss: 0.0129 - val_mse: 0.0075\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0062 - val_loss: 0.0114 - val_mse: 0.0059\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0058 - val_loss: 0.0122 - val_mse: 0.0067\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0060 - val_loss: 0.0148 - val_mse: 0.0094\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0065 - val_loss: 0.0118 - val_mse: 0.0063\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0057 - val_loss: 0.0112 - val_mse: 0.0057\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0055 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0059 - val_loss: 0.0118 - val_mse: 0.0063\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0057 - val_loss: 0.0108 - val_mse: 0.0053\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0059 - val_loss: 0.0107 - val_mse: 0.0052\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0058 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0055 - val_loss: 0.0113 - val_mse: 0.0058\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0057 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0055 - val_loss: 0.0106 - val_mse: 0.0052\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0057 - val_loss: 0.0111 - val_mse: 0.0057\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0055 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0054 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0058 - val_loss: 0.0107 - val_mse: 0.0052\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0054 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0055 - val_loss: 0.0103 - val_mse: 0.0048\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0053 - val_loss: 0.0134 - val_mse: 0.0080\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0052 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0052 - val_loss: 0.0121 - val_mse: 0.0067\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0053 - val_loss: 0.0100 - val_mse: 0.0046\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0052 - val_loss: 0.0100 - val_mse: 0.0046\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0052 - val_loss: 0.0101 - val_mse: 0.0046\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0050 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0052 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0048 - val_loss: 0.0103 - val_mse: 0.0049\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0049 - val_loss: 0.0100 - val_mse: 0.0046\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0047 - val_loss: 0.0098 - val_mse: 0.0044\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0052 - val_loss: 0.0123 - val_mse: 0.0069\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0050 - val_loss: 0.0102 - val_mse: 0.0047\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0050 - val_loss: 0.0110 - val_mse: 0.0056\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0051 - val_loss: 0.0097 - val_mse: 0.0043\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0046 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0050 - val_loss: 0.0096 - val_mse: 0.0041\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0048 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0046 - val_loss: 0.0094 - val_mse: 0.0040\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0045 - val_loss: 0.0097 - val_mse: 0.0043\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0044 - val_loss: 0.0094 - val_mse: 0.0040\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0047 - val_loss: 0.0094 - val_mse: 0.0040\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0044 - val_loss: 0.0098 - val_mse: 0.0044\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0044 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0047 - val_loss: 0.0092 - val_mse: 0.0038\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0044 - val_loss: 0.0093 - val_mse: 0.0039\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0043 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0046 - val_loss: 0.0105 - val_mse: 0.0051\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0045 - val_loss: 0.0093 - val_mse: 0.0039\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0042 - val_loss: 0.0098 - val_mse: 0.0044\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0045 - val_loss: 0.0091 - val_mse: 0.0037\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0044 - val_loss: 0.0104 - val_mse: 0.0050\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0044 - val_loss: 0.0096 - val_mse: 0.0042\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0039\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0042 - val_loss: 0.0120 - val_mse: 0.0066\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0040 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0040 - val_loss: 0.0121 - val_mse: 0.0067\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0043 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0041 - val_loss: 0.0089 - val_mse: 0.0035\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0042 - val_loss: 0.0090 - val_mse: 0.0037\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0034\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0040 - val_loss: 0.0088 - val_mse: 0.0034\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0039\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0042 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0040 - val_loss: 0.0118 - val_mse: 0.0064\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0039 - val_loss: 0.0106 - val_mse: 0.0052\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0040 - val_loss: 0.0089 - val_mse: 0.0036\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0038 - val_loss: 0.0129 - val_mse: 0.0076\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0040 - val_loss: 0.0108 - val_mse: 0.0054\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0033\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0036 - val_loss: 0.0086 - val_mse: 0.0033\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0037 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0040 - val_loss: 0.0098 - val_mse: 0.0044\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0031\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0035 - val_loss: 0.0095 - val_mse: 0.0042\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0039 - val_loss: 0.0085 - val_mse: 0.0031\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0035 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0039 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0035 - val_loss: 0.0088 - val_mse: 0.0034\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0036 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0036 - val_loss: 0.0105 - val_mse: 0.0051\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0036 - val_loss: 0.0084 - val_mse: 0.0030\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0037 - val_loss: 0.0085 - val_mse: 0.0031\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0035 - val_loss: 0.0083 - val_mse: 0.0030\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0037 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0036 - val_loss: 0.0097 - val_mse: 0.0043\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0036 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0037 - val_loss: 0.0088 - val_mse: 0.0035\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0089 - val_mse: 0.0036\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0037 - val_loss: 0.0087 - val_mse: 0.0034\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0035 - val_loss: 0.0092 - val_mse: 0.0039\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0081 - val_mse: 0.0028\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0033 - val_loss: 0.0083 - val_mse: 0.0030\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0032 - val_loss: 0.0082 - val_mse: 0.0028\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0035 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0036 - val_loss: 0.0083 - val_mse: 0.0030\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0082 - val_mse: 0.0029\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0028\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0087 - val_mse: 0.0034\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0080 - val_mse: 0.0027\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0095 - val_mse: 0.0042\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0032 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0034 - val_loss: 0.0081 - val_mse: 0.0028\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0035 - val_loss: 0.0092 - val_mse: 0.0040\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0028\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0032 - val_loss: 0.0079 - val_mse: 0.0026\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0034 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0033 - val_loss: 0.0120 - val_mse: 0.0067\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0032 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0086 - val_mse: 0.0033\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0030 - val_loss: 0.0079 - val_mse: 0.0026\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0030 - val_loss: 0.0083 - val_mse: 0.0030\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0084 - val_mse: 0.0031\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0087 - val_mse: 0.0035\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0079 - val_mse: 0.0026\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0033 - val_loss: 0.0083 - val_mse: 0.0030\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0030 - val_loss: 0.0095 - val_mse: 0.0042\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0085 - val_mse: 0.0033\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0085 - mse: 0.0032 - val_loss: 0.0091 - val_mse: 0.0038\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0032 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0089 - val_mse: 0.0037\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0030 - val_loss: 0.0080 - val_mse: 0.0027\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0030 - val_loss: 0.0085 - val_mse: 0.0033\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0030 - val_loss: 0.0079 - val_mse: 0.0027\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0076 - val_mse: 0.0024\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0029 - val_loss: 0.0082 - val_mse: 0.0030\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0090 - val_mse: 0.0037\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0029 - val_loss: 0.0076 - val_mse: 0.0024\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0076 - val_mse: 0.0023\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0076 - val_mse: 0.0024\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0028 - val_loss: 0.0079 - val_mse: 0.0026\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0031 - val_loss: 0.0077 - val_mse: 0.0024\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0079 - val_mse: 0.0027\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0030 - val_loss: 0.0098 - val_mse: 0.0046\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0032 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0027 - val_loss: 0.0079 - val_mse: 0.0027\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0027 - val_loss: 0.0082 - val_mse: 0.0030\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0030 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0027 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0031 - val_loss: 0.0091 - val_mse: 0.0039\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0074 - val_mse: 0.0022\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0077 - val_mse: 0.0025\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0027 - val_loss: 0.0074 - val_mse: 0.0022\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0025 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0074 - val_mse: 0.0022\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0092 - val_mse: 0.0040\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0027 - val_loss: 0.0074 - val_mse: 0.0023\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0027 - val_loss: 0.0083 - val_mse: 0.0031\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0028 - val_loss: 0.0079 - val_mse: 0.0028\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0026 - val_loss: 0.0077 - val_mse: 0.0026\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0029 - val_loss: 0.0076 - val_mse: 0.0024\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0028 - val_loss: 0.0074 - val_mse: 0.0022\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0025 - val_loss: 0.0073 - val_mse: 0.0022\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0026 - val_loss: 0.0074 - val_mse: 0.0022\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0027 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0027 - val_loss: 0.0075 - val_mse: 0.0023\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0028 - val_loss: 0.0076 - val_mse: 0.0025\n",
      "Epoch 213: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1198 - mse: 0.1167 - val_loss: 0.0550 - val_mse: 0.0519\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0935 - mse: 0.0904 - val_loss: 0.0546 - val_mse: 0.0514\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0908 - val_loss: 0.0560 - val_mse: 0.0528\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0885 - mse: 0.0853 - val_loss: 0.0505 - val_mse: 0.0473\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0851 - val_loss: 0.0478 - val_mse: 0.0445\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0812 - mse: 0.0779 - val_loss: 0.0688 - val_mse: 0.0655\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0659 - val_loss: 0.0406 - val_mse: 0.0371\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0557 - mse: 0.0522 - val_loss: 0.0286 - val_mse: 0.0250\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0412 - mse: 0.0375 - val_loss: 0.0267 - val_mse: 0.0229\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0325 - mse: 0.0287 - val_loss: 0.0216 - val_mse: 0.0178\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0255 - val_loss: 0.0214 - val_mse: 0.0176\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0251 - val_loss: 0.0214 - val_mse: 0.0175\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0236 - val_loss: 0.0209 - val_mse: 0.0170\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0232 - val_loss: 0.0354 - val_mse: 0.0315\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0212 - val_loss: 0.0266 - val_mse: 0.0227\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0210 - val_loss: 0.0228 - val_mse: 0.0189\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0197 - val_loss: 0.0200 - val_mse: 0.0161\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0200 - val_loss: 0.0252 - val_mse: 0.0213\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0189 - val_loss: 0.0206 - val_mse: 0.0167\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0192 - val_loss: 0.0197 - val_mse: 0.0158\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0175 - val_loss: 0.0182 - val_mse: 0.0143\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0180 - val_loss: 0.0203 - val_mse: 0.0164\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0168 - val_loss: 0.0285 - val_mse: 0.0246\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0176 - val_loss: 0.0187 - val_mse: 0.0148\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0162 - val_loss: 0.0177 - val_mse: 0.0138\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0160 - val_loss: 0.0173 - val_mse: 0.0134\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0163 - val_loss: 0.0173 - val_mse: 0.0134\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0170 - val_loss: 0.0170 - val_mse: 0.0131\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0160 - val_loss: 0.0171 - val_mse: 0.0132\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0149 - val_loss: 0.0184 - val_mse: 0.0145\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0154 - val_loss: 0.0191 - val_mse: 0.0153\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0140 - val_loss: 0.0181 - val_mse: 0.0142\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0157 - val_loss: 0.0276 - val_mse: 0.0237\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0156 - val_loss: 0.0172 - val_mse: 0.0134\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0148 - val_loss: 0.0159 - val_mse: 0.0120\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0144 - val_loss: 0.0165 - val_mse: 0.0126\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0143 - val_loss: 0.0157 - val_mse: 0.0119\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0145 - val_loss: 0.0158 - val_mse: 0.0120\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0137 - val_loss: 0.0186 - val_mse: 0.0148\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0136 - val_loss: 0.0163 - val_mse: 0.0124\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0136 - val_loss: 0.0200 - val_mse: 0.0162\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0135 - val_loss: 0.0194 - val_mse: 0.0156\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0141 - val_loss: 0.0155 - val_mse: 0.0116\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0135 - val_loss: 0.0264 - val_mse: 0.0226\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0129 - val_loss: 0.0264 - val_mse: 0.0225\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0131 - val_loss: 0.0156 - val_mse: 0.0118\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0125 - val_loss: 0.0176 - val_mse: 0.0138\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0124 - val_loss: 0.0178 - val_mse: 0.0140\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0138 - val_loss: 0.0149 - val_mse: 0.0111\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0126 - val_loss: 0.0152 - val_mse: 0.0114\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0127 - val_loss: 0.0149 - val_mse: 0.0111\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0130 - val_loss: 0.0196 - val_mse: 0.0158\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0128 - val_loss: 0.0145 - val_mse: 0.0107\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0125 - val_loss: 0.0154 - val_mse: 0.0116\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0137 - val_loss: 0.0192 - val_mse: 0.0155\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0127 - val_loss: 0.0140 - val_mse: 0.0102\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0123 - val_loss: 0.0208 - val_mse: 0.0170\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0117 - val_loss: 0.0143 - val_mse: 0.0105\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0124 - val_loss: 0.0140 - val_mse: 0.0102\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0123 - val_loss: 0.0149 - val_mse: 0.0112\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0117 - val_loss: 0.0138 - val_mse: 0.0100\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.0139 - val_mse: 0.0102\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0117 - val_loss: 0.0175 - val_mse: 0.0137\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0115 - val_loss: 0.0136 - val_mse: 0.0099\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0116 - val_loss: 0.0149 - val_mse: 0.0111\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.0135 - val_mse: 0.0098\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0111 - val_loss: 0.0155 - val_mse: 0.0118\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0115 - val_loss: 0.0168 - val_mse: 0.0130\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0115 - val_loss: 0.0164 - val_mse: 0.0127\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0114 - val_loss: 0.0135 - val_mse: 0.0098\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0121 - val_loss: 0.0204 - val_mse: 0.0167\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0113 - val_loss: 0.0178 - val_mse: 0.0142\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.0137 - val_mse: 0.0100\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0115 - val_loss: 0.0145 - val_mse: 0.0108\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0110 - val_loss: 0.0133 - val_mse: 0.0097\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0111 - val_loss: 0.0134 - val_mse: 0.0098\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0120 - val_loss: 0.0153 - val_mse: 0.0116\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0117 - val_loss: 0.0161 - val_mse: 0.0125\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0109 - val_loss: 0.0133 - val_mse: 0.0096\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0110 - val_loss: 0.0157 - val_mse: 0.0120\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0119 - val_loss: 0.0135 - val_mse: 0.0099\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0120 - val_loss: 0.0130 - val_mse: 0.0094\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0120 - val_loss: 0.0131 - val_mse: 0.0095\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0119 - val_loss: 0.0131 - val_mse: 0.0095\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0117 - val_loss: 0.0130 - val_mse: 0.0094\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0113 - val_loss: 0.0130 - val_mse: 0.0094\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0110 - val_loss: 0.0247 - val_mse: 0.0211\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0117 - val_loss: 0.0128 - val_mse: 0.0092\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0116 - val_loss: 0.0129 - val_mse: 0.0093\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0110 - val_loss: 0.0190 - val_mse: 0.0154\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0121 - val_loss: 0.0155 - val_mse: 0.0119\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0109 - val_loss: 0.0130 - val_mse: 0.0094\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0117 - val_loss: 0.0129 - val_mse: 0.0093\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0116 - val_loss: 0.0140 - val_mse: 0.0105\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0113 - val_loss: 0.0127 - val_mse: 0.0092\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0111 - val_loss: 0.0175 - val_mse: 0.0140\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0108 - val_loss: 0.0209 - val_mse: 0.0173\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0112 - val_loss: 0.0127 - val_mse: 0.0092\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0109 - val_loss: 0.0201 - val_mse: 0.0166\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0109 - val_loss: 0.0132 - val_mse: 0.0097\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0105 - val_loss: 0.0126 - val_mse: 0.0091\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0111 - val_loss: 0.0129 - val_mse: 0.0094\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0090\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0111 - val_loss: 0.0125 - val_mse: 0.0090\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0106 - val_loss: 0.0133 - val_mse: 0.0098\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0113 - val_loss: 0.0129 - val_mse: 0.0094\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0108 - val_loss: 0.0136 - val_mse: 0.0101\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0108 - val_loss: 0.0143 - val_mse: 0.0108\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0110 - val_loss: 0.0132 - val_mse: 0.0097\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0109 - val_loss: 0.0154 - val_mse: 0.0119\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0117 - val_loss: 0.0187 - val_mse: 0.0152\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0108 - val_loss: 0.0123 - val_mse: 0.0088\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0110 - val_loss: 0.0142 - val_mse: 0.0108\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0105 - val_loss: 0.0175 - val_mse: 0.0141\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0104 - val_loss: 0.0125 - val_mse: 0.0090\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0107 - val_loss: 0.0227 - val_mse: 0.0193\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0111 - val_loss: 0.0126 - val_mse: 0.0091\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0103 - val_loss: 0.0122 - val_mse: 0.0088\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0106 - val_loss: 0.0124 - val_mse: 0.0089\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0112 - val_loss: 0.0141 - val_mse: 0.0107\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0106 - val_loss: 0.0176 - val_mse: 0.0141\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0100 - val_loss: 0.0128 - val_mse: 0.0093\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0105 - val_loss: 0.0132 - val_mse: 0.0097\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0100 - val_loss: 0.0123 - val_mse: 0.0089\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0103 - val_loss: 0.0123 - val_mse: 0.0088\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0104 - val_loss: 0.0200 - val_mse: 0.0165\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0101 - val_loss: 0.0152 - val_mse: 0.0117\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0102 - val_loss: 0.0126 - val_mse: 0.0092\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0104 - val_loss: 0.0151 - val_mse: 0.0116\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0108 - val_loss: 0.0169 - val_mse: 0.0135\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0097 - val_loss: 0.0136 - val_mse: 0.0101\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0098\n",
      "Epoch 132: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.0924 - mse: 0.0881 - val_loss: 0.0533 - val_mse: 0.0490\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0683 - val_loss: 0.0668 - val_mse: 0.0624\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0519 - val_loss: 0.0495 - val_mse: 0.0450\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0373 - val_loss: 0.0268 - val_mse: 0.0223\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0283 - val_loss: 0.0240 - val_mse: 0.0194\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0244 - val_loss: 0.0224 - val_mse: 0.0178\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0232 - val_loss: 0.0302 - val_mse: 0.0256\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0211 - val_loss: 0.0224 - val_mse: 0.0178\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0212 - val_loss: 0.0209 - val_mse: 0.0163\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0201 - val_loss: 0.0217 - val_mse: 0.0171\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0199 - val_loss: 0.0201 - val_mse: 0.0155\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0178 - val_loss: 0.0202 - val_mse: 0.0156\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0224 - mse: 0.0178 - val_loss: 0.0199 - val_mse: 0.0153\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0179 - val_loss: 0.0189 - val_mse: 0.0143\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0166 - val_loss: 0.0355 - val_mse: 0.0309\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0163 - val_loss: 0.0185 - val_mse: 0.0139\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0165 - val_loss: 0.0195 - val_mse: 0.0149\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0156 - val_loss: 0.0194 - val_mse: 0.0148\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0156 - val_loss: 0.0204 - val_mse: 0.0158\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0151 - val_loss: 0.0190 - val_mse: 0.0144\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0142 - val_loss: 0.0179 - val_mse: 0.0133\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0147 - val_loss: 0.0182 - val_mse: 0.0136\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0142 - val_loss: 0.0171 - val_mse: 0.0125\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0137 - val_loss: 0.0165 - val_mse: 0.0119\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0140 - val_loss: 0.0172 - val_mse: 0.0126\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0130 - val_loss: 0.0231 - val_mse: 0.0185\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0139 - val_loss: 0.0159 - val_mse: 0.0113\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0128 - val_loss: 0.0179 - val_mse: 0.0133\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0178 - mse: 0.0132 - val_loss: 0.0166 - val_mse: 0.0120\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0122 - val_loss: 0.0173 - val_mse: 0.0127\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0128 - val_loss: 0.0169 - val_mse: 0.0123\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0123 - val_loss: 0.0167 - val_mse: 0.0120\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0122 - val_loss: 0.0157 - val_mse: 0.0111\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0121 - val_loss: 0.0164 - val_mse: 0.0117\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0107 - val_loss: 0.0148 - val_mse: 0.0101\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0108 - val_loss: 0.0141 - val_mse: 0.0094\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0108 - val_loss: 0.0140 - val_mse: 0.0093\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0098 - val_loss: 0.0157 - val_mse: 0.0110\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0101 - val_loss: 0.0139 - val_mse: 0.0092\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0098 - val_loss: 0.0133 - val_mse: 0.0086\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0094 - val_loss: 0.0148 - val_mse: 0.0101\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0089 - val_loss: 0.0131 - val_mse: 0.0083\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0090 - val_loss: 0.0131 - val_mse: 0.0083\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0090 - val_loss: 0.0133 - val_mse: 0.0085\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0085 - val_loss: 0.0135 - val_mse: 0.0088\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0086 - val_loss: 0.0125 - val_mse: 0.0078\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0084 - val_loss: 0.0149 - val_mse: 0.0101\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0083 - val_loss: 0.0122 - val_mse: 0.0074\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0076 - val_loss: 0.0141 - val_mse: 0.0093\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0078 - val_loss: 0.0119 - val_mse: 0.0071\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0073 - val_loss: 0.0123 - val_mse: 0.0075\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0070 - val_loss: 0.0140 - val_mse: 0.0093\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0072 - val_loss: 0.0125 - val_mse: 0.0078\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0073 - val_loss: 0.0112 - val_mse: 0.0064\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0113 - mse: 0.0065 - val_loss: 0.0138 - val_mse: 0.0091\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0068 - val_loss: 0.0125 - val_mse: 0.0077\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0150 - val_mse: 0.0102\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0074 - val_loss: 0.0107 - val_mse: 0.0059\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0144 - val_mse: 0.0097\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0063 - val_loss: 0.0123 - val_mse: 0.0075\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0062 - val_loss: 0.0104 - val_mse: 0.0057\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0063 - val_loss: 0.0105 - val_mse: 0.0057\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0061 - val_loss: 0.0117 - val_mse: 0.0069\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0057 - val_loss: 0.0101 - val_mse: 0.0054\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0057 - val_loss: 0.0104 - val_mse: 0.0057\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0059 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0057 - val_loss: 0.0099 - val_mse: 0.0052\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0055 - val_loss: 0.0104 - val_mse: 0.0056\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0054 - val_loss: 0.0104 - val_mse: 0.0057\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0060 - val_loss: 0.0103 - val_mse: 0.0056\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0054 - val_loss: 0.0110 - val_mse: 0.0062\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0052 - val_loss: 0.0101 - val_mse: 0.0054\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0054 - val_loss: 0.0107 - val_mse: 0.0059\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0055 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0054 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0054 - val_loss: 0.0129 - val_mse: 0.0082\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0047 - val_loss: 0.0102 - val_mse: 0.0054\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0049 - val_loss: 0.0121 - val_mse: 0.0073\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0049 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0052 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0049 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0049 - val_loss: 0.0150 - val_mse: 0.0103\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0052 - val_loss: 0.0107 - val_mse: 0.0060\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0050 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0051 - val_loss: 0.0103 - val_mse: 0.0056\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0047 - val_loss: 0.0117 - val_mse: 0.0070\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0047 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0045 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0047 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0046 - val_loss: 0.0128 - val_mse: 0.0081\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0112 - val_mse: 0.0065\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0047 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0044 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0086 - val_mse: 0.0039\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0048 - val_loss: 0.0107 - val_mse: 0.0060\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0044 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0094 - val_mse: 0.0048\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0045 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0047 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0046 - val_loss: 0.0105 - val_mse: 0.0059\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0042 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0043 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0045 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0042 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0042 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0040 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0041 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0042 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0040 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0040 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0040 - val_loss: 0.0106 - val_mse: 0.0060\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0039 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0040 - val_loss: 0.0105 - val_mse: 0.0059\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0040 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0037 - val_loss: 0.0079 - val_mse: 0.0033\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0042 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0038 - val_loss: 0.0078 - val_mse: 0.0033\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0038 - val_loss: 0.0080 - val_mse: 0.0034\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0040 - val_loss: 0.0102 - val_mse: 0.0057\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0037 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0038 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0041 - val_loss: 0.0077 - val_mse: 0.0032\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0039 - val_loss: 0.0077 - val_mse: 0.0032\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0036 - val_loss: 0.0079 - val_mse: 0.0034\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0033\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0081 - val_mse: 0.0035\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0102 - val_mse: 0.0057\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0079 - val_mse: 0.0034\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0077 - val_mse: 0.0031\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0078 - val_mse: 0.0032\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0081 - val_mse: 0.0036\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0035 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0032\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0074 - val_mse: 0.0029\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0081 - val_mse: 0.0037\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0029\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0029\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0108 - val_mse: 0.0063\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0074 - val_mse: 0.0029\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0073 - val_mse: 0.0028\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0031\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0031\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0073 - val_mse: 0.0028\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0078 - val_mse: 0.0033\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0072 - val_mse: 0.0028\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0032 - val_loss: 0.0072 - val_mse: 0.0028\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0078 - val_mse: 0.0034\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0119 - val_mse: 0.0075\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0035 - val_loss: 0.0074 - val_mse: 0.0030\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0033 - val_loss: 0.0077 - val_mse: 0.0033\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0074 - val_mse: 0.0030\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0072 - val_mse: 0.0028\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0080 - val_mse: 0.0036\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0080 - val_mse: 0.0036\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0030 - val_loss: 0.0070 - val_mse: 0.0026\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0078 - val_mse: 0.0034\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0070 - val_mse: 0.0027\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0070 - val_mse: 0.0026\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0032 - val_loss: 0.0077 - val_mse: 0.0033\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0026\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0030 - val_loss: 0.0099 - val_mse: 0.0055\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0026\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0070 - val_mse: 0.0027\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0033\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0069 - val_mse: 0.0025\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0079 - val_mse: 0.0035\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0075 - val_mse: 0.0032\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0073 - val_mse: 0.0030\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0032 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0070 - val_mse: 0.0027\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0032 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0028 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0028 - val_loss: 0.0076 - val_mse: 0.0033\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0031 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0075 - val_mse: 0.0032\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0028 - val_loss: 0.0066 - val_mse: 0.0024\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0077 - val_mse: 0.0035\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0030 - val_loss: 0.0078 - val_mse: 0.0035\n",
      "Epoch 235: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.1538 - mse: 0.1503 - val_loss: 0.0616 - val_mse: 0.0582\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0937 - val_loss: 0.0550 - val_mse: 0.0515\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0905 - mse: 0.0870 - val_loss: 0.0517 - val_mse: 0.0483\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0876 - mse: 0.0841 - val_loss: 0.0472 - val_mse: 0.0437\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0802 - mse: 0.0766 - val_loss: 0.0412 - val_mse: 0.0376\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0609 - val_loss: 0.0343 - val_mse: 0.0306\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0461 - val_loss: 0.0286 - val_mse: 0.0247\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0368 - val_loss: 0.0330 - val_mse: 0.0290\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0314 - val_loss: 0.0297 - val_mse: 0.0256\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0292 - val_loss: 0.0249 - val_mse: 0.0207\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0265 - val_loss: 0.0298 - val_mse: 0.0256\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0271 - val_loss: 0.0248 - val_mse: 0.0207\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0253 - val_loss: 0.0225 - val_mse: 0.0183\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0248 - val_loss: 0.0232 - val_mse: 0.0190\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0230 - val_loss: 0.0219 - val_mse: 0.0177\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0221 - val_loss: 0.0301 - val_mse: 0.0258\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0232 - val_loss: 0.0250 - val_mse: 0.0207\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0224 - val_loss: 0.0204 - val_mse: 0.0162\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0215 - val_loss: 0.0254 - val_mse: 0.0211\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0208 - val_loss: 0.0199 - val_mse: 0.0157\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0198 - val_loss: 0.0198 - val_mse: 0.0156\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0200 - val_loss: 0.0203 - val_mse: 0.0160\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0198 - val_loss: 0.0199 - val_mse: 0.0156\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0188 - val_loss: 0.0186 - val_mse: 0.0143\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0191 - val_loss: 0.0229 - val_mse: 0.0186\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0179 - val_loss: 0.0184 - val_mse: 0.0141\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0172 - val_loss: 0.0198 - val_mse: 0.0155\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0167 - val_loss: 0.0182 - val_mse: 0.0139\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0169 - val_loss: 0.0175 - val_mse: 0.0132\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0160 - val_loss: 0.0173 - val_mse: 0.0130\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0162 - val_loss: 0.0210 - val_mse: 0.0167\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0148 - val_loss: 0.0202 - val_mse: 0.0159\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0148 - val_loss: 0.0196 - val_mse: 0.0153\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0143 - val_loss: 0.0182 - val_mse: 0.0139\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0142 - val_loss: 0.0181 - val_mse: 0.0137\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0135 - val_loss: 0.0159 - val_mse: 0.0115\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0129 - val_loss: 0.0156 - val_mse: 0.0112\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0135 - val_loss: 0.0157 - val_mse: 0.0113\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0130 - val_loss: 0.0151 - val_mse: 0.0108\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0122 - val_loss: 0.0159 - val_mse: 0.0115\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0115 - val_loss: 0.0168 - val_mse: 0.0124\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0119 - val_loss: 0.0154 - val_mse: 0.0110\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0113 - val_loss: 0.0146 - val_mse: 0.0102\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0108 - val_loss: 0.0141 - val_mse: 0.0096\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0110 - val_loss: 0.0191 - val_mse: 0.0146\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0103 - val_loss: 0.0184 - val_mse: 0.0139\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0098 - val_loss: 0.0132 - val_mse: 0.0088\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0094 - val_loss: 0.0135 - val_mse: 0.0091\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0092 - val_loss: 0.0147 - val_mse: 0.0103\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0088 - val_loss: 0.0128 - val_mse: 0.0083\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0079\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0084 - val_loss: 0.0127 - val_mse: 0.0082\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0081 - val_loss: 0.0148 - val_mse: 0.0103\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0077 - val_loss: 0.0142 - val_mse: 0.0097\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0079 - val_loss: 0.0119 - val_mse: 0.0073\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0075 - val_loss: 0.0119 - val_mse: 0.0074\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0070 - val_loss: 0.0118 - val_mse: 0.0072\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0068 - val_loss: 0.0122 - val_mse: 0.0076\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0118 - val_mse: 0.0072\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0113 - val_mse: 0.0067\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0060 - val_loss: 0.0109 - val_mse: 0.0063\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0060 - val_loss: 0.0105 - val_mse: 0.0059\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0104 - val_mse: 0.0058\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0113 - val_mse: 0.0067\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0060 - val_loss: 0.0108 - val_mse: 0.0062\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0141 - val_mse: 0.0095\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0055 - val_loss: 0.0123 - val_mse: 0.0077\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0057 - val_loss: 0.0099 - val_mse: 0.0053\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0053 - val_loss: 0.0099 - val_mse: 0.0053\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0102 - val_mse: 0.0056\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0053 - val_loss: 0.0125 - val_mse: 0.0079\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0052 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0055 - val_loss: 0.0122 - val_mse: 0.0076\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0052 - val_loss: 0.0095 - val_mse: 0.0049\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0053 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0053 - val_loss: 0.0116 - val_mse: 0.0070\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0048 - val_loss: 0.0094 - val_mse: 0.0048\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0049 - val_loss: 0.0093 - val_mse: 0.0047\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0049 - val_loss: 0.0094 - val_mse: 0.0048\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0049 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0047 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0047 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0047 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0043 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0045 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0046 - val_loss: 0.0097 - val_mse: 0.0051\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0046 - val_loss: 0.0120 - val_mse: 0.0074\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0090 - mse: 0.0044 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0091 - mse: 0.0046 - val_loss: 0.0111 - val_mse: 0.0065\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0045 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0043 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0043 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0043 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0044 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0088 - mse: 0.0043 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0042 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0049\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0088 - mse: 0.0043 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0087 - mse: 0.0042 - val_loss: 0.0108 - val_mse: 0.0063\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0039 - val_loss: 0.0082 - val_mse: 0.0037\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0041 - val_loss: 0.0083 - val_mse: 0.0037\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0041 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0040 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0086 - mse: 0.0041 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0080 - val_mse: 0.0035\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - mse: 0.0038 - val_loss: 0.0079 - val_mse: 0.0033\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0078 - val_mse: 0.0033\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 0.0039 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0038 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0038 - val_loss: 0.0077 - val_mse: 0.0033\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0082 - mse: 0.0037 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0036 - val_loss: 0.0081 - val_mse: 0.0036\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0035 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0038 - val_loss: 0.0077 - val_mse: 0.0032\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0075 - val_mse: 0.0031\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0129 - val_mse: 0.0084\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0082 - mse: 0.0038 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0037 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0036 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0037 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0081 - mse: 0.0036 - val_loss: 0.0081 - val_mse: 0.0037\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0034 - val_loss: 0.0077 - val_mse: 0.0032\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0035 - val_loss: 0.0073 - val_mse: 0.0029\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0075 - val_mse: 0.0031\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0072 - val_mse: 0.0027\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0078 - mse: 0.0034 - val_loss: 0.0095 - val_mse: 0.0051\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0076 - val_mse: 0.0031\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0079 - val_mse: 0.0035\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0070 - val_mse: 0.0026\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0033 - val_loss: 0.0078 - val_mse: 0.0034\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0072 - val_mse: 0.0028\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0075 - val_mse: 0.0031\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0080 - val_mse: 0.0036\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0032 - val_loss: 0.0083 - val_mse: 0.0039\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0025\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0070 - val_mse: 0.0026\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0069 - val_mse: 0.0025\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 0.0032 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0068 - val_mse: 0.0024\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0071 - val_mse: 0.0027\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0031 - val_loss: 0.0068 - val_mse: 0.0024\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0030 - val_loss: 0.0076 - val_mse: 0.0032\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0032 - val_loss: 0.0068 - val_mse: 0.0024\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0072 - val_mse: 0.0028\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0073 - val_mse: 0.0030\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0068 - val_mse: 0.0024\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0028 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0029 - val_loss: 0.0071 - val_mse: 0.0028\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0026 - val_loss: 0.0069 - val_mse: 0.0026\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0028 - val_loss: 0.0070 - val_mse: 0.0027\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0026 - val_loss: 0.0067 - val_mse: 0.0024\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0029 - val_loss: 0.0066 - val_mse: 0.0023\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0065 - val_mse: 0.0022\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0065 - val_mse: 0.0022\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0065 - val_mse: 0.0023\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0075 - val_mse: 0.0032\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0026 - val_loss: 0.0065 - val_mse: 0.0022\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0027 - val_loss: 0.0073 - val_mse: 0.0031\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0029 - val_loss: 0.0065 - val_mse: 0.0022\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0026 - val_loss: 0.0065 - val_mse: 0.0022\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0066 - val_mse: 0.0023\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0064 - val_mse: 0.0022\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0065 - val_mse: 0.0023\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0064 - val_mse: 0.0021\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0025 - val_loss: 0.0071 - val_mse: 0.0028\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0028 - val_loss: 0.0064 - val_mse: 0.0022\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0027 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0071 - val_mse: 0.0029\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0075 - val_mse: 0.0033\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0025 - val_loss: 0.0067 - val_mse: 0.0025\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0068 - val_mse: 0.0025\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0025 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0064 - val_mse: 0.0022\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0072 - val_mse: 0.0030\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0025 - val_loss: 0.0062 - val_mse: 0.0020\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0072 - val_mse: 0.0029\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0024 - val_loss: 0.0065 - val_mse: 0.0023\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0028 - val_loss: 0.0062 - val_mse: 0.0020\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0062 - val_mse: 0.0020\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0027 - val_loss: 0.0064 - val_mse: 0.0022\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0069 - val_mse: 0.0027\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0066 - val_mse: 0.0024\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0026 - val_loss: 0.0063 - val_mse: 0.0022\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0062 - val_mse: 0.0020\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0061 - val_mse: 0.0020\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0025 - val_loss: 0.0064 - val_mse: 0.0023\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0077 - val_mse: 0.0036\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0026 - val_loss: 0.0078 - val_mse: 0.0036\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0064 - val_mse: 0.0022\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0066 - mse: 0.0024 - val_loss: 0.0073 - val_mse: 0.0032\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0061 - val_mse: 0.0019\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0024 - val_loss: 0.0062 - val_mse: 0.0021\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0025 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0024 - val_loss: 0.0063 - val_mse: 0.0021\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0024 - val_loss: 0.0061 - val_mse: 0.0019\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0067 - mse: 0.0026 - val_loss: 0.0060 - val_mse: 0.0019\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0025 - val_loss: 0.0066 - val_mse: 0.0024\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0023 - val_loss: 0.0068 - val_mse: 0.0027\n",
      "Epoch 223: early stopping\n",
      "{'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.0508 - mse: 0.0441 - val_loss: 0.0229 - val_mse: 0.0161\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0325 - mse: 0.0256 - val_loss: 0.0277 - val_mse: 0.0208\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0306 - mse: 0.0237 - val_loss: 0.0232 - val_mse: 0.0163\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0224 - val_loss: 0.0209 - val_mse: 0.0140\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0220 - val_loss: 0.0224 - val_mse: 0.0156\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0201 - val_loss: 0.0198 - val_mse: 0.0130\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0264 - mse: 0.0196 - val_loss: 0.0241 - val_mse: 0.0173\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0189 - val_loss: 0.0203 - val_mse: 0.0134\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0196 - val_loss: 0.0207 - val_mse: 0.0138\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0180 - val_loss: 0.0195 - val_mse: 0.0127\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0170 - val_loss: 0.0198 - val_mse: 0.0130\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0168 - val_loss: 0.0198 - val_mse: 0.0131\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0161 - val_loss: 0.0200 - val_mse: 0.0132\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0153 - val_loss: 0.0280 - val_mse: 0.0212\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0153 - val_loss: 0.0172 - val_mse: 0.0105\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0145 - val_loss: 0.0250 - val_mse: 0.0182\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0151 - val_loss: 0.0221 - val_mse: 0.0153\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0141 - val_loss: 0.0221 - val_mse: 0.0154\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0137 - val_loss: 0.0192 - val_mse: 0.0125\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0135 - val_loss: 0.0220 - val_mse: 0.0153\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0132 - val_loss: 0.0165 - val_mse: 0.0098\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0122 - val_loss: 0.0168 - val_mse: 0.0100\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0121 - val_loss: 0.0167 - val_mse: 0.0100\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0119 - val_loss: 0.0234 - val_mse: 0.0166\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0121 - val_loss: 0.0163 - val_mse: 0.0095\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0114 - val_loss: 0.0177 - val_mse: 0.0109\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0123 - val_loss: 0.0163 - val_mse: 0.0096\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0118 - val_loss: 0.0163 - val_mse: 0.0096\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0113 - val_loss: 0.0164 - val_mse: 0.0096\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0112 - val_loss: 0.0176 - val_mse: 0.0108\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0114 - val_loss: 0.0169 - val_mse: 0.0102\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0117 - val_loss: 0.0166 - val_mse: 0.0099\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0117 - val_loss: 0.0211 - val_mse: 0.0144\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0110 - val_loss: 0.0167 - val_mse: 0.0100\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0111 - val_loss: 0.0209 - val_mse: 0.0142\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0104 - val_loss: 0.0257 - val_mse: 0.0190\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0106 - val_loss: 0.0218 - val_mse: 0.0150\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0113 - val_loss: 0.0179 - val_mse: 0.0112\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0116 - val_loss: 0.0169 - val_mse: 0.0102\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0105 - val_loss: 0.0172 - val_mse: 0.0105\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0106 - val_loss: 0.0163 - val_mse: 0.0096\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0103 - val_loss: 0.0162 - val_mse: 0.0095\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0105 - val_loss: 0.0164 - val_mse: 0.0097\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0098 - val_loss: 0.0204 - val_mse: 0.0137\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0099 - val_loss: 0.0166 - val_mse: 0.0099\n",
      "Epoch 45: early stopping\n",
      "0 0.0025 0.0021 324 {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "1 0.0026 0.0022 212 {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "2 0.0028 0.0022 493 {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "3 0.0029 0.0024 260 {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "4 0.0028 0.0025 351 {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "5 0.0031 0.0025 261 {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "6 0.0028 0.0025 213 {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "7 0.0023 0.0027 223 {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "8 0.0035 0.0031 500 {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "9 0.003 0.0035 235 {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "10 0.0102 0.0098 132 {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "11 0.0099 0.0099 45 {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n"
     ]
    }
   ],
   "source": [
    "layers = [[5, 6]]#, [4, 2]]\n",
    "param_dict = dict(hidden_layer_nodes=layers,\n",
    "                  kernel_initializer=[initializers.GlorotNormal(),\n",
    "                                      initializers.HeNormal(),\n",
    "                                      initializers.RandomNormal(mean=0., stddev=.5),\n",
    "                                      initializers.RandomNormal(mean=0., stddev=1.)\n",
    "                                      ],\n",
    "                  bias_initializer=[initializers.Zeros(),\n",
    "                                    initializers.RandomNormal(mean=0., stddev=1.),\n",
    "                                    initializers.Ones()]\n",
    "                  )\n",
    "\n",
    "weight_eval_grid = grid_search(param_dict, X_train, y_train, X_val, y_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0025 0.0021 324 {'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "1 0.0026 0.0022 212 {'mean': 0.0, 'stddev': 1.0, 'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "2 0.0028 0.0022 493 {'seed': None} {'mean': 0.0, 'stddev': 1.0, 'seed': None} {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "3 0.0029 0.0024 260 {'seed': None} {'mean': 0.0, 'stddev': 1.0, 'seed': None} {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "4 0.0028 0.0025 351 {'mean': 0.0, 'stddev': 0.5, 'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "5 0.0031 0.0025 261 {'mean': 0.0, 'stddev': 0.5, 'seed': None} {'mean': 0.0, 'stddev': 1.0, 'seed': None} {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "6 0.0028 0.0025 213 {'mean': 0.0, 'stddev': 1.0, 'seed': None} {'mean': 0.0, 'stddev': 1.0, 'seed': None} {'bias_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B03A0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n",
      "7 0.0023 0.0027 223 {'mean': 0.0, 'stddev': 0.5, 'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0940>}\n",
      "8 0.0035 0.0031 500 {'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Zeros object at 0x000001AB5F3B0310>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "9 0.003 0.0035 235 {'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.HeNormal object at 0x000001AAF889C1F0>}\n",
      "10 0.0102 0.0098 132 {'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.GlorotNormal object at 0x000001AA904736D0>}\n",
      "11 0.0099 0.0099 45 {'mean': 0.0, 'stddev': 1.0, 'seed': None} {} {'bias_initializer': <keras.initializers.initializers_v2.Ones object at 0x000001AB5F3B01C0>, 'hidden_layer_nodes': [5, 6], 'kernel_initializer': <keras.initializers.initializers_v2.RandomNormal object at 0x000001AB5F3B0220>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (param, model, history, final_train_mse, final_val_mse, epoch) in enumerate(weight_eval_grid):\n",
    "    config = param[\"kernel_initializer\"].get_config()\n",
    "    config2 = param[\"bias_initializer\"].get_config()\n",
    "    print(i, final_train_mse, final_val_mse, epoch, config, config2, param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "for i, (param, model, history, final_val_mse, epoch) in enumerate(weight_eval_grid):\n",
    "    plt.plot(history['loss'], label=f'model {i}: epoch: {epoch} {param}')\n",
    "#plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Evaluate best and worst config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 4\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.0886 - mse: 0.0756 - val_loss: 0.0323 - val_mse: 0.0192\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0260 - val_loss: 0.0299 - val_mse: 0.0168\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0239 - val_loss: 0.0295 - val_mse: 0.0164\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0228 - val_loss: 0.0286 - val_mse: 0.0156\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0345 - mse: 0.0215 - val_loss: 0.0292 - val_mse: 0.0161\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0211 - val_loss: 0.0271 - val_mse: 0.0141\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0197 - val_loss: 0.0270 - val_mse: 0.0139\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0193 - val_loss: 0.0279 - val_mse: 0.0148\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0183 - val_loss: 0.0260 - val_mse: 0.0130\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0186 - val_loss: 0.0305 - val_mse: 0.0175\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0173 - val_loss: 0.0261 - val_mse: 0.0131\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0174 - val_loss: 0.0276 - val_mse: 0.0146\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0170 - val_loss: 0.0259 - val_mse: 0.0129\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0164 - val_loss: 0.0260 - val_mse: 0.0130\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0163 - val_loss: 0.0296 - val_mse: 0.0166\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0159 - val_loss: 0.0254 - val_mse: 0.0124\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0158 - val_loss: 0.0258 - val_mse: 0.0128\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0156 - val_loss: 0.0258 - val_mse: 0.0128\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0151 - val_loss: 0.0322 - val_mse: 0.0192\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0149 - val_loss: 0.0254 - val_mse: 0.0124\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0146 - val_loss: 0.0254 - val_mse: 0.0124\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0155 - val_loss: 0.0277 - val_mse: 0.0147\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0154 - val_loss: 0.0272 - val_mse: 0.0142\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0146 - val_loss: 0.0278 - val_mse: 0.0148\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0144 - val_loss: 0.0273 - val_mse: 0.0144\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0140 - val_loss: 0.0258 - val_mse: 0.0128\n",
      "Epoch 26: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.028671791777014732, 0.015696685761213303]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "### Best\n",
    "model_best = create_model()\n",
    "es = EarlyStopping(monitor='val_mse', mode='min', patience=10, min_delta=0.0001, verbose=1, restore_best_weights=0)\n",
    "history_best = model_best.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=10, callbacks=es)\n",
    "\n",
    "perf_best = model_best.evaluate(X_test, y_test)\n",
    "display(perf_best)\n",
    "y_pred_best = model_best.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Worst\n",
    "model_worst = create_model(hidden_layer_nodes=[4, 2],\n",
    "                     regularizer=regularizers.L2(0.01),\n",
    "                     momentum=0,\n",
    "                     kernel_initializer=initializers.RandomNormal(mean=0., stddev=2.),\n",
    "                     bias_initializer=initializers.RandomNormal(mean=0., stddev=2.),)\n",
    "es = EarlyStopping(monitor='val_mse', mode='min', patience=10, min_delta=0.0001, verbose=1, restore_best_weights=0)\n",
    "history_worst = model_worst.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=10, callbacks=es)\n",
    "\n",
    "perf_worst = model_best.evaluate(X_test, y_test)\n",
    "display(perf_worst)\n",
    "y_pred_worst = model_worst.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xrange = range(len(y_pred_best))\n",
    "\n",
    "plt.plot(Xrange, y_pred_best, label=\"pred best\")\n",
    "plt.plot(Xrange, y_pred_worst, label=\"pred worst\")\n",
    "plt.plot(Xrange, y_test, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With Noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def add_gaussian_noise(data, mean=0.0, std=1.0):\n",
    "    noise = np.random.normal(loc=mean, scale=std, size=data.shape)\n",
    "    return data + noise\n",
    "\n",
    "\n",
    "noise_sigma = [0.05, 0.15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "layers = [[5, 3], [5, 6], [5, 9]]\n",
    "param_dict = dict(hidden_layer_nodes=layers,\n",
    "                  regularizer=[regularizers.L2(0.1),\n",
    "                               regularizers.L2(0.01),\n",
    "                               regularizers.L2(0.001),\n",
    "                               regularizers.L2(0.0001)]\n",
    "                  )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 7.2368 - mse: 0.1843 - val_loss: 0.1544 - val_mse: 0.0545\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1432 - mse: 0.0943 - val_loss: 0.1011 - val_mse: 0.0571\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1380 - mse: 0.0969 - val_loss: 0.1015 - val_mse: 0.0554\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1358 - mse: 0.0947 - val_loss: 0.1049 - val_mse: 0.0665\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1365 - mse: 0.0958 - val_loss: 0.1025 - val_mse: 0.0547\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.0940 - val_loss: 0.1036 - val_mse: 0.0641\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.0944 - val_loss: 0.1039 - val_mse: 0.0649\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1356 - mse: 0.0946 - val_loss: 0.1032 - val_mse: 0.0635\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1374 - mse: 0.0964 - val_loss: 0.1012 - val_mse: 0.0581\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1354 - mse: 0.0945 - val_loss: 0.1013 - val_mse: 0.0558\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1355 - mse: 0.0945 - val_loss: 0.1047 - val_mse: 0.0662\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1361 - mse: 0.0950 - val_loss: 0.1024 - val_mse: 0.0618\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1354 - mse: 0.0945 - val_loss: 0.1013 - val_mse: 0.0557\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1352 - mse: 0.0939 - val_loss: 0.1038 - val_mse: 0.0645\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1367 - mse: 0.0959 - val_loss: 0.1019 - val_mse: 0.0551\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1351 - mse: 0.0940 - val_loss: 0.1066 - val_mse: 0.0694\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1373 - mse: 0.0962 - val_loss: 0.1013 - val_mse: 0.0586\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1354 - mse: 0.0944 - val_loss: 0.1011 - val_mse: 0.0566\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1349 - mse: 0.0937 - val_loss: 0.1082 - val_mse: 0.0718\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.0939 - val_loss: 0.1025 - val_mse: 0.0619\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1354 - mse: 0.0945 - val_loss: 0.1130 - val_mse: 0.0788\n",
      "Epoch 21: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 4.2707 - mse: 0.5789 - val_loss: 2.6394 - val_mse: 0.0286\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9798 - mse: 0.0362 - val_loss: 1.4224 - val_mse: 0.0307\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0887 - mse: 0.0446 - val_loss: 0.7878 - val_mse: 0.0315\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6258 - mse: 0.0547 - val_loss: 0.4573 - val_mse: 0.0384\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3826 - mse: 0.0613 - val_loss: 0.2791 - val_mse: 0.0395\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2546 - mse: 0.0693 - val_loss: 0.1843 - val_mse: 0.0437\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1853 - mse: 0.0744 - val_loss: 0.1327 - val_mse: 0.0469\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1506 - mse: 0.0818 - val_loss: 0.1040 - val_mse: 0.0491\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1302 - mse: 0.0860 - val_loss: 0.0867 - val_mse: 0.0507\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1174 - mse: 0.0880 - val_loss: 0.0773 - val_mse: 0.0535\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.0900 - val_loss: 0.0725 - val_mse: 0.0551\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1038 - mse: 0.0896 - val_loss: 0.0706 - val_mse: 0.0590\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1030 - mse: 0.0925 - val_loss: 0.0774 - val_mse: 0.0691\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.0929 - val_loss: 0.0845 - val_mse: 0.0783\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0983 - mse: 0.0915 - val_loss: 0.0649 - val_mse: 0.0590\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0986 - mse: 0.0927 - val_loss: 0.0614 - val_mse: 0.0551\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0997 - mse: 0.0944 - val_loss: 0.0605 - val_mse: 0.0552\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0973 - mse: 0.0923 - val_loss: 0.0636 - val_mse: 0.0577\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0943 - val_loss: 0.0666 - val_mse: 0.0623\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0984 - mse: 0.0936 - val_loss: 0.0596 - val_mse: 0.0546\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0976 - mse: 0.0929 - val_loss: 0.0817 - val_mse: 0.0781\n",
      "Epoch 21: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.2759 - mse: 0.7432 - val_loss: 0.5491 - val_mse: 0.0334\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5408 - mse: 0.0406 - val_loss: 0.5157 - val_mse: 0.0315\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5060 - mse: 0.0366 - val_loss: 0.4802 - val_mse: 0.0259\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4750 - mse: 0.0347 - val_loss: 0.4637 - val_mse: 0.0377\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4471 - mse: 0.0341 - val_loss: 0.4251 - val_mse: 0.0252\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4203 - mse: 0.0328 - val_loss: 0.3996 - val_mse: 0.0243\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3956 - mse: 0.0319 - val_loss: 0.3756 - val_mse: 0.0234\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3718 - mse: 0.0304 - val_loss: 0.3543 - val_mse: 0.0236\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3492 - mse: 0.0286 - val_loss: 0.3318 - val_mse: 0.0212\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3284 - mse: 0.0272 - val_loss: 0.3145 - val_mse: 0.0228\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3090 - mse: 0.0260 - val_loss: 0.2933 - val_mse: 0.0191\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2904 - mse: 0.0244 - val_loss: 0.2774 - val_mse: 0.0196\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2731 - mse: 0.0229 - val_loss: 0.2602 - val_mse: 0.0176\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2573 - mse: 0.0218 - val_loss: 0.2456 - val_mse: 0.0174\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2422 - mse: 0.0207 - val_loss: 0.2314 - val_mse: 0.0165\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2282 - mse: 0.0195 - val_loss: 0.2181 - val_mse: 0.0157\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2153 - mse: 0.0188 - val_loss: 0.2063 - val_mse: 0.0156\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2040 - mse: 0.0187 - val_loss: 0.1947 - val_mse: 0.0148\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1927 - mse: 0.0179 - val_loss: 0.1885 - val_mse: 0.0188\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1825 - mse: 0.0175 - val_loss: 0.1747 - val_mse: 0.0145\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1728 - mse: 0.0170 - val_loss: 0.1658 - val_mse: 0.0145\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1641 - mse: 0.0169 - val_loss: 0.1571 - val_mse: 0.0141\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1558 - mse: 0.0166 - val_loss: 0.1491 - val_mse: 0.0139\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1479 - mse: 0.0163 - val_loss: 0.1437 - val_mse: 0.0157\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1409 - mse: 0.0163 - val_loss: 0.1349 - val_mse: 0.0137\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1340 - mse: 0.0160 - val_loss: 0.1285 - val_mse: 0.0136\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1278 - mse: 0.0159 - val_loss: 0.1250 - val_mse: 0.0159\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1223 - mse: 0.0160 - val_loss: 0.1168 - val_mse: 0.0134\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1166 - mse: 0.0157 - val_loss: 0.1118 - val_mse: 0.0135\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1117 - mse: 0.0159 - val_loss: 0.1071 - val_mse: 0.0135\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0160 - val_loss: 0.1030 - val_mse: 0.0141\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1027 - mse: 0.0159 - val_loss: 0.0980 - val_mse: 0.0133\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0155 - val_loss: 0.0947 - val_mse: 0.0140\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0944 - mse: 0.0156 - val_loss: 0.0913 - val_mse: 0.0141\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0905 - mse: 0.0152 - val_loss: 0.0869 - val_mse: 0.0134\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0873 - mse: 0.0154 - val_loss: 0.0845 - val_mse: 0.0142\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0155 - val_loss: 0.0805 - val_mse: 0.0132\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0818 - mse: 0.0160 - val_loss: 0.0783 - val_mse: 0.0138\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0786 - mse: 0.0154 - val_loss: 0.0752 - val_mse: 0.0135\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0756 - mse: 0.0151 - val_loss: 0.0749 - val_mse: 0.0157\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0739 - mse: 0.0157 - val_loss: 0.0703 - val_mse: 0.0133\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0155 - val_loss: 0.0683 - val_mse: 0.0134\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0153 - val_loss: 0.0758 - val_mse: 0.0231\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0162 - val_loss: 0.0644 - val_mse: 0.0133\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0156 - val_loss: 0.0625 - val_mse: 0.0132\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0160 - val_loss: 0.0640 - val_mse: 0.0164\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0160 - val_loss: 0.0593 - val_mse: 0.0133\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0156 - val_loss: 0.0583 - val_mse: 0.0137\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0161 - val_loss: 0.0565 - val_mse: 0.0132\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0161 - val_loss: 0.0598 - val_mse: 0.0179\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0165 - val_loss: 0.0554 - val_mse: 0.0146\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0161 - val_loss: 0.0575 - val_mse: 0.0178\n",
      "Epoch 52: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.2294 - mse: 0.1834 - val_loss: 0.1294 - val_mse: 0.0837\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1452 - mse: 0.0997 - val_loss: 0.0985 - val_mse: 0.0532\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.0907 - val_loss: 0.0989 - val_mse: 0.0540\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1309 - mse: 0.0862 - val_loss: 0.0933 - val_mse: 0.0488\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1248 - mse: 0.0804 - val_loss: 0.0968 - val_mse: 0.0526\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1126 - mse: 0.0686 - val_loss: 0.0905 - val_mse: 0.0466\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0930 - mse: 0.0493 - val_loss: 0.0677 - val_mse: 0.0241\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0391 - val_loss: 0.0674 - val_mse: 0.0241\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0785 - mse: 0.0353 - val_loss: 0.0619 - val_mse: 0.0190\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0320 - val_loss: 0.0610 - val_mse: 0.0183\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0728 - mse: 0.0302 - val_loss: 0.0646 - val_mse: 0.0222\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0288 - val_loss: 0.0586 - val_mse: 0.0165\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0274 - val_loss: 0.0577 - val_mse: 0.0159\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0263 - val_loss: 0.0572 - val_mse: 0.0156\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0244 - val_loss: 0.0578 - val_mse: 0.0165\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0655 - mse: 0.0243 - val_loss: 0.0561 - val_mse: 0.0151\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0227 - val_loss: 0.0592 - val_mse: 0.0185\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0223 - val_loss: 0.0556 - val_mse: 0.0151\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0218 - val_loss: 0.0545 - val_mse: 0.0142\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0206 - val_loss: 0.0540 - val_mse: 0.0140\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0194 - val_loss: 0.0549 - val_mse: 0.0152\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0199 - val_loss: 0.0529 - val_mse: 0.0135\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0183 - val_loss: 0.0526 - val_mse: 0.0134\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0187 - val_loss: 0.0523 - val_mse: 0.0133\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0177 - val_loss: 0.0534 - val_mse: 0.0147\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0173 - val_loss: 0.0516 - val_mse: 0.0131\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0170 - val_loss: 0.0513 - val_mse: 0.0131\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0165 - val_loss: 0.0533 - val_mse: 0.0153\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0161 - val_loss: 0.0516 - val_mse: 0.0139\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0530 - mse: 0.0154 - val_loss: 0.0510 - val_mse: 0.0135\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0150 - val_loss: 0.0515 - val_mse: 0.0143\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0143 - val_loss: 0.0500 - val_mse: 0.0131\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0143 - val_loss: 0.0500 - val_mse: 0.0133\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0143 - val_loss: 0.0497 - val_mse: 0.0132\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0139 - val_loss: 0.0494 - val_mse: 0.0131\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0497 - mse: 0.0136 - val_loss: 0.0493 - val_mse: 0.0133\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0495 - mse: 0.0136 - val_loss: 0.0509 - val_mse: 0.0151\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0133 - val_loss: 0.0489 - val_mse: 0.0134\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0132 - val_loss: 0.0485 - val_mse: 0.0132\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0126 - val_loss: 0.0493 - val_mse: 0.0142\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0127 - val_loss: 0.0488 - val_mse: 0.0140\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0475 - mse: 0.0128 - val_loss: 0.0474 - val_mse: 0.0128\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0127 - val_loss: 0.0495 - val_mse: 0.0151\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0467 - mse: 0.0124 - val_loss: 0.0468 - val_mse: 0.0127\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0121 - val_loss: 0.0467 - val_mse: 0.0128\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0464 - mse: 0.0126 - val_loss: 0.0465 - val_mse: 0.0128\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0124 - val_loss: 0.0462 - val_mse: 0.0127\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0123 - val_loss: 0.0462 - val_mse: 0.0129\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0123 - val_loss: 0.0461 - val_mse: 0.0130\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0119 - val_loss: 0.0462 - val_mse: 0.0133\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0119 - val_loss: 0.0452 - val_mse: 0.0126\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0117 - val_loss: 0.0547 - val_mse: 0.0223\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0119 - val_loss: 0.0456 - val_mse: 0.0134\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0117 - val_loss: 0.0481 - val_mse: 0.0161\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0119 - val_loss: 0.0461 - val_mse: 0.0142\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0119 - val_loss: 0.0452 - val_mse: 0.0136\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0122 - val_loss: 0.0437 - val_mse: 0.0122\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0117 - val_loss: 0.0458 - val_mse: 0.0145\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0116 - val_loss: 0.0443 - val_mse: 0.0133\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0120 - val_loss: 0.0439 - val_mse: 0.0131\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0118 - val_loss: 0.0428 - val_mse: 0.0122\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0121 - val_loss: 0.0427 - val_mse: 0.0123\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0423 - mse: 0.0119 - val_loss: 0.0433 - val_mse: 0.0130\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0113 - val_loss: 0.0430 - val_mse: 0.0130\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0117 - val_loss: 0.0425 - val_mse: 0.0126\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0114 - val_loss: 0.0426 - val_mse: 0.0129\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0117 - val_loss: 0.0430 - val_mse: 0.0135\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0116 - val_loss: 0.0419 - val_mse: 0.0126\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0116 - val_loss: 0.0411 - val_mse: 0.0120\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0116 - val_loss: 0.0444 - val_mse: 0.0155\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0112 - val_loss: 0.0415 - val_mse: 0.0127\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0112 - val_loss: 0.0407 - val_mse: 0.0121\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0113 - val_loss: 0.0403 - val_mse: 0.0119\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0113 - val_loss: 0.0407 - val_mse: 0.0124\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0110 - val_loss: 0.0417 - val_mse: 0.0137\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0110 - val_loss: 0.0395 - val_mse: 0.0116\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0115 - val_loss: 0.0414 - val_mse: 0.0137\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0111 - val_loss: 0.0392 - val_mse: 0.0116\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0110 - val_loss: 0.0396 - val_mse: 0.0122\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0112 - val_loss: 0.0387 - val_mse: 0.0114\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0110 - val_loss: 0.0385 - val_mse: 0.0114\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0112 - val_loss: 0.0389 - val_mse: 0.0120\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0109 - val_loss: 0.0400 - val_mse: 0.0133\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0113 - val_loss: 0.0382 - val_mse: 0.0116\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0109 - val_loss: 0.0412 - val_mse: 0.0148\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0112 - val_loss: 0.0378 - val_mse: 0.0116\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0112 - val_loss: 0.0379 - val_mse: 0.0118\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0106 - val_loss: 0.0372 - val_mse: 0.0113\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0112 - val_loss: 0.0371 - val_mse: 0.0114\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0110 - val_loss: 0.0367 - val_mse: 0.0111\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0107 - val_loss: 0.0371 - val_mse: 0.0117\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0112 - val_loss: 0.0372 - val_mse: 0.0119\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0110 - val_loss: 0.0363 - val_mse: 0.0112\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0107 - val_loss: 0.0364 - val_mse: 0.0115\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0107 - val_loss: 0.0357 - val_mse: 0.0109\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0107 - val_loss: 0.0357 - val_mse: 0.0111\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0108 - val_loss: 0.0378 - val_mse: 0.0133\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0106 - val_loss: 0.0360 - val_mse: 0.0117\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0108 - val_loss: 0.0349 - val_mse: 0.0107\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0110 - val_loss: 0.0365 - val_mse: 0.0125\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0107 - val_loss: 0.0346 - val_mse: 0.0107\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0340 - mse: 0.0101 - val_loss: 0.0346 - val_mse: 0.0109\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0105 - val_loss: 0.0343 - val_mse: 0.0107\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0106 - val_loss: 0.0342 - val_mse: 0.0108\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0105 - val_loss: 0.0342 - val_mse: 0.0109\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0105 - val_loss: 0.0340 - val_mse: 0.0108\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0104 - val_loss: 0.0350 - val_mse: 0.0120\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0106 - val_loss: 0.0336 - val_mse: 0.0107\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0103 - val_loss: 0.0334 - val_mse: 0.0106\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0105 - val_loss: 0.0331 - val_mse: 0.0105\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0098 - val_loss: 0.0337 - val_mse: 0.0112\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0102 - val_loss: 0.0334 - val_mse: 0.0111\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0103 - val_loss: 0.0328 - val_mse: 0.0106\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0105 - val_loss: 0.0324 - val_mse: 0.0103\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0101 - val_loss: 0.0322 - val_mse: 0.0103\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0102 - val_loss: 0.0321 - val_mse: 0.0103\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0105 - val_loss: 0.0341 - val_mse: 0.0124\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0101 - val_loss: 0.0319 - val_mse: 0.0103\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0103 - val_loss: 0.0322 - val_mse: 0.0107\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0106 - val_loss: 0.0327 - val_mse: 0.0114\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0102 - val_loss: 0.0326 - val_mse: 0.0114\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0102 - val_loss: 0.0312 - val_mse: 0.0101\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0312 - mse: 0.0102 - val_loss: 0.0330 - val_mse: 0.0120\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0099 - val_loss: 0.0335 - val_mse: 0.0127\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0103 - val_loss: 0.0308 - val_mse: 0.0101\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0101 - val_loss: 0.0306 - val_mse: 0.0101\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0099 - val_loss: 0.0305 - val_mse: 0.0100\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0101 - val_loss: 0.0305 - val_mse: 0.0102\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0102 - val_loss: 0.0302 - val_mse: 0.0100\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0102 - val_loss: 0.0301 - val_mse: 0.0100\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0096 - val_loss: 0.0305 - val_mse: 0.0105\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0099 - val_loss: 0.0306 - val_mse: 0.0107\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0099 - val_loss: 0.0299 - val_mse: 0.0102\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0100 - val_loss: 0.0299 - val_mse: 0.0102\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0100 - val_loss: 0.0302 - val_mse: 0.0107\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0101 - val_loss: 0.0292 - val_mse: 0.0098\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0100 - val_loss: 0.0299 - val_mse: 0.0106\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0097 - val_loss: 0.0331 - val_mse: 0.0139\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0100 - val_loss: 0.0288 - val_mse: 0.0097\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0098 - val_loss: 0.0286 - val_mse: 0.0097\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0096 - val_loss: 0.0295 - val_mse: 0.0107\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0097 - val_loss: 0.0291 - val_mse: 0.0104\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0097 - val_loss: 0.0287 - val_mse: 0.0101\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0098 - val_loss: 0.0283 - val_mse: 0.0098\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0283 - mse: 0.0099 - val_loss: 0.0295 - val_mse: 0.0111\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0100 - val_loss: 0.0283 - val_mse: 0.0100\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0096 - val_loss: 0.0282 - val_mse: 0.0100\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0095 - val_loss: 0.0290 - val_mse: 0.0109\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0098 - val_loss: 0.0280 - val_mse: 0.0100\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0097 - val_loss: 0.0275 - val_mse: 0.0096\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0098 - val_loss: 0.0283 - val_mse: 0.0105\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0097 - val_loss: 0.0273 - val_mse: 0.0096\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274 - mse: 0.0097 - val_loss: 0.0273 - val_mse: 0.0097\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0095 - val_loss: 0.0275 - val_mse: 0.0100\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0099 - val_loss: 0.0269 - val_mse: 0.0094\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0095 - val_loss: 0.0270 - val_mse: 0.0097\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0095 - val_loss: 0.0267 - val_mse: 0.0095\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0097 - val_loss: 0.0268 - val_mse: 0.0097\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0096 - val_loss: 0.0292 - val_mse: 0.0121\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0095 - val_loss: 0.0268 - val_mse: 0.0098\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0096 - val_loss: 0.0277 - val_mse: 0.0108\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0095 - val_loss: 0.0262 - val_mse: 0.0094\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0096 - val_loss: 0.0272 - val_mse: 0.0105\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0099 - val_loss: 0.0259 - val_mse: 0.0093\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0100 - val_loss: 0.0258 - val_mse: 0.0093\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0095 - val_loss: 0.0258 - val_mse: 0.0094\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0095 - val_loss: 0.0259 - val_mse: 0.0096\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0092 - val_loss: 0.0257 - val_mse: 0.0095\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0096 - val_loss: 0.0258 - val_mse: 0.0097\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0096 - val_loss: 0.0256 - val_mse: 0.0096\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0093 - val_loss: 0.0275 - val_mse: 0.0115\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0094 - val_loss: 0.0252 - val_mse: 0.0093\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0095 - val_loss: 0.0251 - val_mse: 0.0093\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0092 - val_loss: 0.0255 - val_mse: 0.0097\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0095 - val_loss: 0.0250 - val_mse: 0.0094\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0095 - val_loss: 0.0265 - val_mse: 0.0109\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0100 - val_loss: 0.0247 - val_mse: 0.0092\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0094 - val_loss: 0.0247 - val_mse: 0.0093\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0099 - val_loss: 0.0252 - val_mse: 0.0099\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0095 - val_loss: 0.0246 - val_mse: 0.0093\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0092 - val_loss: 0.0250 - val_mse: 0.0099\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0096 - val_loss: 0.0254 - val_mse: 0.0104\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0096 - val_loss: 0.0246 - val_mse: 0.0096\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0094 - val_loss: 0.0243 - val_mse: 0.0094\n",
      "Epoch 184: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 10.9425 - mse: 0.3379 - val_loss: 0.1876 - val_mse: 0.0837\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1394 - mse: 0.0973 - val_loss: 0.0946 - val_mse: 0.0566\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.0949 - val_loss: 0.0919 - val_mse: 0.0553\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1265 - mse: 0.0967 - val_loss: 0.0879 - val_mse: 0.0565\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1250 - mse: 0.0952 - val_loss: 0.0884 - val_mse: 0.0547\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.0960 - val_loss: 0.0910 - val_mse: 0.0550\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1253 - mse: 0.0955 - val_loss: 0.0898 - val_mse: 0.0609\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1260 - mse: 0.0961 - val_loss: 0.0914 - val_mse: 0.0634\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1277 - mse: 0.0978 - val_loss: 0.1001 - val_mse: 0.0754\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1237 - mse: 0.0940 - val_loss: 0.0933 - val_mse: 0.0663\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.0952 - val_loss: 0.0880 - val_mse: 0.0550\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.0943 - val_loss: 0.0920 - val_mse: 0.0554\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.0947 - val_loss: 0.1046 - val_mse: 0.0810\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1253 - mse: 0.0956 - val_loss: 0.0932 - val_mse: 0.0660\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1251 - mse: 0.0953 - val_loss: 0.1042 - val_mse: 0.0805\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1277 - mse: 0.0982 - val_loss: 0.0893 - val_mse: 0.0546\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.0940 - val_loss: 0.1168 - val_mse: 0.0956\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.0959 - val_loss: 0.0921 - val_mse: 0.0644\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.0966 - val_loss: 0.0900 - val_mse: 0.0612\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1238 - mse: 0.0941 - val_loss: 0.0893 - val_mse: 0.0600\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.0933 - val_loss: 0.0911 - val_mse: 0.0630\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.0953 - val_loss: 0.0882 - val_mse: 0.0548\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1248 - mse: 0.0949 - val_loss: 0.0888 - val_mse: 0.0546\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.0964 - val_loss: 0.1271 - val_mse: 0.1074\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.0966 - val_loss: 0.0981 - val_mse: 0.0728\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1272 - mse: 0.0975 - val_loss: 0.0878 - val_mse: 0.0556\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1266 - mse: 0.0968 - val_loss: 0.0935 - val_mse: 0.0561\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1235 - mse: 0.0936 - val_loss: 0.0967 - val_mse: 0.0709\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1260 - mse: 0.0963 - val_loss: 0.0931 - val_mse: 0.0659\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1243 - mse: 0.0943 - val_loss: 0.0894 - val_mse: 0.0601\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1244 - mse: 0.0947 - val_loss: 0.0914 - val_mse: 0.0635\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1015 - val_loss: 0.0903 - val_mse: 0.0617\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1235 - mse: 0.0938 - val_loss: 0.0879 - val_mse: 0.0565\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1226 - mse: 0.0929 - val_loss: 0.0924 - val_mse: 0.0556\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1248 - mse: 0.0946 - val_loss: 0.1035 - val_mse: 0.0796\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1248 - mse: 0.0951 - val_loss: 0.0888 - val_mse: 0.0589\n",
      "Epoch 36: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 5.1033 - mse: 0.4903 - val_loss: 3.3188 - val_mse: 0.0486\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4851 - mse: 0.0622 - val_loss: 1.7545 - val_mse: 0.0299\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3295 - mse: 0.0442 - val_loss: 0.9768 - val_mse: 0.0543\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7364 - mse: 0.0429 - val_loss: 0.5300 - val_mse: 0.0270\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4344 - mse: 0.0517 - val_loss: 0.3180 - val_mse: 0.0355\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2793 - mse: 0.0601 - val_loss: 0.2057 - val_mse: 0.0399\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2005 - mse: 0.0694 - val_loss: 0.1440 - val_mse: 0.0418\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1575 - mse: 0.0754 - val_loss: 0.1166 - val_mse: 0.0519\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1356 - mse: 0.0825 - val_loss: 0.1000 - val_mse: 0.0578\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1197 - mse: 0.0844 - val_loss: 0.0904 - val_mse: 0.0606\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1149 - mse: 0.0910 - val_loss: 0.0719 - val_mse: 0.0519\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0912 - val_loss: 0.0676 - val_mse: 0.0538\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1068 - mse: 0.0951 - val_loss: 0.0843 - val_mse: 0.0752\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1034 - mse: 0.0948 - val_loss: 0.0636 - val_mse: 0.0556\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1017 - mse: 0.0951 - val_loss: 0.0672 - val_mse: 0.0618\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1047 - mse: 0.0994 - val_loss: 0.0602 - val_mse: 0.0550\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0997 - mse: 0.0952 - val_loss: 0.0632 - val_mse: 0.0592\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0996 - mse: 0.0956 - val_loss: 0.0642 - val_mse: 0.0596\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0975 - mse: 0.0938 - val_loss: 0.0613 - val_mse: 0.0571\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0995 - mse: 0.0960 - val_loss: 0.0583 - val_mse: 0.0546\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0972 - mse: 0.0938 - val_loss: 0.0599 - val_mse: 0.0560\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0951 - mse: 0.0918 - val_loss: 0.0695 - val_mse: 0.0667\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0986 - mse: 0.0953 - val_loss: 0.0586 - val_mse: 0.0552\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0994 - mse: 0.0961 - val_loss: 0.0585 - val_mse: 0.0549\n",
      "Epoch 24: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.9152 - mse: 0.1262 - val_loss: 0.7946 - val_mse: 0.0306\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7723 - mse: 0.0318 - val_loss: 0.7520 - val_mse: 0.0350\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7271 - mse: 0.0324 - val_loss: 0.7012 - val_mse: 0.0287\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6824 - mse: 0.0306 - val_loss: 0.6614 - val_mse: 0.0303\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6401 - mse: 0.0285 - val_loss: 0.6218 - val_mse: 0.0298\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6026 - mse: 0.0288 - val_loss: 0.5843 - val_mse: 0.0287\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5675 - mse: 0.0291 - val_loss: 0.5491 - val_mse: 0.0278\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5339 - mse: 0.0286 - val_loss: 0.5175 - val_mse: 0.0284\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5022 - mse: 0.0280 - val_loss: 0.4889 - val_mse: 0.0298\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4726 - mse: 0.0276 - val_loss: 0.4560 - val_mse: 0.0251\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4452 - mse: 0.0276 - val_loss: 0.4296 - val_mse: 0.0252\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4192 - mse: 0.0271 - val_loss: 0.4073 - val_mse: 0.0277\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3956 - mse: 0.0275 - val_loss: 0.3822 - val_mse: 0.0257\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3726 - mse: 0.0268 - val_loss: 0.3589 - val_mse: 0.0243\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3512 - mse: 0.0268 - val_loss: 0.3381 - val_mse: 0.0237\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3313 - mse: 0.0264 - val_loss: 0.3185 - val_mse: 0.0232\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3128 - mse: 0.0264 - val_loss: 0.3020 - val_mse: 0.0246\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2952 - mse: 0.0260 - val_loss: 0.2834 - val_mse: 0.0226\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2797 - mse: 0.0268 - val_loss: 0.2705 - val_mse: 0.0254\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2634 - mse: 0.0256 - val_loss: 0.2528 - val_mse: 0.0223\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2498 - mse: 0.0261 - val_loss: 0.2386 - val_mse: 0.0218\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2355 - mse: 0.0251 - val_loss: 0.2285 - val_mse: 0.0246\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2235 - mse: 0.0255 - val_loss: 0.2139 - val_mse: 0.0220\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2117 - mse: 0.0253 - val_loss: 0.2075 - val_mse: 0.0268\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2005 - mse: 0.0250 - val_loss: 0.1916 - val_mse: 0.0212\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1892 - mse: 0.0237 - val_loss: 0.1866 - val_mse: 0.0261\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1806 - mse: 0.0246 - val_loss: 0.1717 - val_mse: 0.0204\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1711 - mse: 0.0240 - val_loss: 0.1653 - val_mse: 0.0224\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1627 - mse: 0.0239 - val_loss: 0.1549 - val_mse: 0.0201\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1556 - mse: 0.0246 - val_loss: 0.1506 - val_mse: 0.0232\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1477 - mse: 0.0239 - val_loss: 0.1396 - val_mse: 0.0192\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1412 - mse: 0.0241 - val_loss: 0.1333 - val_mse: 0.0194\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1342 - mse: 0.0234 - val_loss: 0.1314 - val_mse: 0.0236\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1279 - mse: 0.0230 - val_loss: 0.1216 - val_mse: 0.0195\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1229 - mse: 0.0234 - val_loss: 0.1156 - val_mse: 0.0187\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1181 - mse: 0.0237 - val_loss: 0.1107 - val_mse: 0.0189\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1122 - mse: 0.0226 - val_loss: 0.1106 - val_mse: 0.0233\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1086 - mse: 0.0235 - val_loss: 0.1021 - val_mse: 0.0192\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1034 - mse: 0.0225 - val_loss: 0.1057 - val_mse: 0.0267\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1008 - mse: 0.0238 - val_loss: 0.0963 - val_mse: 0.0213\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0961 - mse: 0.0227 - val_loss: 0.0895 - val_mse: 0.0179\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0229 - val_loss: 0.0887 - val_mse: 0.0204\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0893 - mse: 0.0225 - val_loss: 0.0838 - val_mse: 0.0186\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0865 - mse: 0.0227 - val_loss: 0.0802 - val_mse: 0.0177\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0838 - mse: 0.0227 - val_loss: 0.0780 - val_mse: 0.0181\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0815 - mse: 0.0230 - val_loss: 0.0789 - val_mse: 0.0216\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0789 - mse: 0.0227 - val_loss: 0.0722 - val_mse: 0.0172\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0763 - mse: 0.0224 - val_loss: 0.0703 - val_mse: 0.0174\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0741 - mse: 0.0223 - val_loss: 0.0675 - val_mse: 0.0167\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0227 - val_loss: 0.0658 - val_mse: 0.0169\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0226 - val_loss: 0.0649 - val_mse: 0.0177\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0225 - val_loss: 0.0624 - val_mse: 0.0169\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0222 - val_loss: 0.0603 - val_mse: 0.0164\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0226 - val_loss: 0.0654 - val_mse: 0.0231\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0227 - val_loss: 0.0575 - val_mse: 0.0165\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0218 - val_loss: 0.0573 - val_mse: 0.0176\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0217 - val_loss: 0.0550 - val_mse: 0.0165\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0220 - val_loss: 0.0675 - val_mse: 0.0303\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0230 - val_loss: 0.0544 - val_mse: 0.0181\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0223 - val_loss: 0.0530 - val_mse: 0.0177\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0221 - val_loss: 0.0524 - val_mse: 0.0182\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0224 - val_loss: 0.0497 - val_mse: 0.0163\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0219 - val_loss: 0.0504 - val_mse: 0.0178\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0219 - val_loss: 0.0493 - val_mse: 0.0175\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0221 - val_loss: 0.0477 - val_mse: 0.0166\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0225 - val_loss: 0.0469 - val_mse: 0.0167\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0221 - val_loss: 0.0525 - val_mse: 0.0228\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0230 - val_loss: 0.0482 - val_mse: 0.0193\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0223 - val_loss: 0.0446 - val_mse: 0.0162\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0506 - mse: 0.0224 - val_loss: 0.0464 - val_mse: 0.0185\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0221 - val_loss: 0.0443 - val_mse: 0.0168\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0227 - val_loss: 0.0540 - val_mse: 0.0272\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0222 - val_loss: 0.0426 - val_mse: 0.0162\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0226 - val_loss: 0.0440 - val_mse: 0.0181\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0475 - mse: 0.0217 - val_loss: 0.0415 - val_mse: 0.0159\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0222 - val_loss: 0.0412 - val_mse: 0.0160\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0223 - val_loss: 0.0444 - val_mse: 0.0194\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0468 - mse: 0.0221 - val_loss: 0.0463 - val_mse: 0.0218\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0220 - val_loss: 0.0406 - val_mse: 0.0164\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0220 - val_loss: 0.0405 - val_mse: 0.0165\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0216 - val_loss: 0.0439 - val_mse: 0.0203\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0447 - mse: 0.0211 - val_loss: 0.0416 - val_mse: 0.0181\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0221 - val_loss: 0.0448 - val_mse: 0.0217\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0221 - val_loss: 0.0398 - val_mse: 0.0169\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0222 - val_loss: 0.0386 - val_mse: 0.0161\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0223 - val_loss: 0.0397 - val_mse: 0.0172\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0226 - val_loss: 0.0402 - val_mse: 0.0181\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0222 - val_loss: 0.0490 - val_mse: 0.0269\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0227 - val_loss: 0.0398 - val_mse: 0.0179\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0220 - val_loss: 0.0399 - val_mse: 0.0182\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0220 - val_loss: 0.0395 - val_mse: 0.0180\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0221 - val_loss: 0.0387 - val_mse: 0.0174\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0224 - val_loss: 0.0397 - val_mse: 0.0185\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0224 - val_loss: 0.0388 - val_mse: 0.0178\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0227 - val_loss: 0.0369 - val_mse: 0.0159\n",
      "Epoch 95: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.9552 - mse: 0.9020 - val_loss: 0.1187 - val_mse: 0.0658\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1611 - mse: 0.1083 - val_loss: 0.1218 - val_mse: 0.0692\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1582 - mse: 0.1058 - val_loss: 0.1104 - val_mse: 0.0581\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1549 - mse: 0.1028 - val_loss: 0.1107 - val_mse: 0.0587\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1546 - mse: 0.1028 - val_loss: 0.1274 - val_mse: 0.0757\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1499 - mse: 0.0984 - val_loss: 0.1082 - val_mse: 0.0568\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1447 - mse: 0.0936 - val_loss: 0.1158 - val_mse: 0.0648\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1412 - mse: 0.0903 - val_loss: 0.1016 - val_mse: 0.0509\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1282 - mse: 0.0776 - val_loss: 0.0919 - val_mse: 0.0414\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0477 - val_loss: 0.0794 - val_mse: 0.0290\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0847 - mse: 0.0344 - val_loss: 0.0827 - val_mse: 0.0325\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0300 - val_loss: 0.0971 - val_mse: 0.0472\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0762 - mse: 0.0264 - val_loss: 0.0728 - val_mse: 0.0231\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0742 - mse: 0.0247 - val_loss: 0.0728 - val_mse: 0.0234\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0733 - mse: 0.0241 - val_loss: 0.0718 - val_mse: 0.0228\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0725 - mse: 0.0235 - val_loss: 0.0710 - val_mse: 0.0223\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0230 - val_loss: 0.0723 - val_mse: 0.0238\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0218 - val_loss: 0.0798 - val_mse: 0.0317\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0220 - val_loss: 0.0692 - val_mse: 0.0214\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0230 - val_loss: 0.0700 - val_mse: 0.0225\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0228 - val_loss: 0.0828 - val_mse: 0.0356\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0221 - val_loss: 0.0681 - val_mse: 0.0213\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0684 - mse: 0.0216 - val_loss: 0.0729 - val_mse: 0.0264\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0679 - mse: 0.0215 - val_loss: 0.0693 - val_mse: 0.0230\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0205 - val_loss: 0.0665 - val_mse: 0.0205\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0675 - mse: 0.0217 - val_loss: 0.0694 - val_mse: 0.0237\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0655 - mse: 0.0200 - val_loss: 0.0651 - val_mse: 0.0197\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0193 - val_loss: 0.0645 - val_mse: 0.0194\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0209 - val_loss: 0.0649 - val_mse: 0.0201\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0201 - val_loss: 0.0643 - val_mse: 0.0198\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0197 - val_loss: 0.0633 - val_mse: 0.0191\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0194 - val_loss: 0.0656 - val_mse: 0.0217\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0203 - val_loss: 0.0640 - val_mse: 0.0203\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0190 - val_loss: 0.0631 - val_mse: 0.0198\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0190 - val_loss: 0.0631 - val_mse: 0.0200\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0191 - val_loss: 0.0608 - val_mse: 0.0180\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0198 - val_loss: 0.0667 - val_mse: 0.0241\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0185 - val_loss: 0.0601 - val_mse: 0.0179\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0194 - val_loss: 0.0688 - val_mse: 0.0268\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0187 - val_loss: 0.0598 - val_mse: 0.0181\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0179 - val_loss: 0.0588 - val_mse: 0.0174\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0595 - mse: 0.0182 - val_loss: 0.0582 - val_mse: 0.0171\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0180 - val_loss: 0.0658 - val_mse: 0.0249\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0179 - val_loss: 0.0585 - val_mse: 0.0178\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0175 - val_loss: 0.0574 - val_mse: 0.0170\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0187 - val_loss: 0.0565 - val_mse: 0.0164\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0167 - val_loss: 0.0565 - val_mse: 0.0166\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0170 - val_loss: 0.0569 - val_mse: 0.0172\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0177 - val_loss: 0.0554 - val_mse: 0.0160\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0164 - val_loss: 0.0563 - val_mse: 0.0172\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0177 - val_loss: 0.0553 - val_mse: 0.0165\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0164 - val_loss: 0.0543 - val_mse: 0.0156\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0164 - val_loss: 0.0538 - val_mse: 0.0155\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0159 - val_loss: 0.0542 - val_mse: 0.0160\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0160 - val_loss: 0.0566 - val_mse: 0.0187\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0157 - val_loss: 0.0535 - val_mse: 0.0158\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0156 - val_loss: 0.0790 - val_mse: 0.0416\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0163 - val_loss: 0.0523 - val_mse: 0.0151\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0154 - val_loss: 0.0518 - val_mse: 0.0148\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0153 - val_loss: 0.0526 - val_mse: 0.0159\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0154 - val_loss: 0.0509 - val_mse: 0.0143\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0516 - mse: 0.0152 - val_loss: 0.0575 - val_mse: 0.0212\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0155 - val_loss: 0.0507 - val_mse: 0.0146\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0152 - val_loss: 0.0505 - val_mse: 0.0147\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0145 - val_loss: 0.0507 - val_mse: 0.0151\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0500 - mse: 0.0145 - val_loss: 0.0509 - val_mse: 0.0155\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0155 - val_loss: 0.0490 - val_mse: 0.0139\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0147 - val_loss: 0.0490 - val_mse: 0.0141\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0151 - val_loss: 0.0515 - val_mse: 0.0168\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0138 - val_loss: 0.0538 - val_mse: 0.0193\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0147 - val_loss: 0.0476 - val_mse: 0.0133\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0496 - mse: 0.0154 - val_loss: 0.0485 - val_mse: 0.0144\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0140 - val_loss: 0.0501 - val_mse: 0.0162\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0147 - val_loss: 0.0471 - val_mse: 0.0134\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0488 - mse: 0.0152 - val_loss: 0.0483 - val_mse: 0.0148\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0148 - val_loss: 0.0463 - val_mse: 0.0130\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0144 - val_loss: 0.0464 - val_mse: 0.0133\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0139 - val_loss: 0.0458 - val_mse: 0.0129\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0152 - val_loss: 0.0459 - val_mse: 0.0132\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0147 - val_loss: 0.0460 - val_mse: 0.0136\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0143 - val_loss: 0.0489 - val_mse: 0.0166\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0134 - val_loss: 0.0590 - val_mse: 0.0269\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0146 - val_loss: 0.0467 - val_mse: 0.0148\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0138 - val_loss: 0.0452 - val_mse: 0.0135\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0133 - val_loss: 0.0445 - val_mse: 0.0130\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0136 - val_loss: 0.0481 - val_mse: 0.0168\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0153 - val_loss: 0.0436 - val_mse: 0.0125\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0133 - val_loss: 0.0434 - val_mse: 0.0125\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0142 - val_loss: 0.0439 - val_mse: 0.0132\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0142 - val_loss: 0.0447 - val_mse: 0.0141\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0139 - val_loss: 0.0428 - val_mse: 0.0124\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0143 - val_loss: 0.0441 - val_mse: 0.0140\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0146 - val_loss: 0.0433 - val_mse: 0.0133\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0136 - val_loss: 0.0421 - val_mse: 0.0123\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0143 - val_loss: 0.0418 - val_mse: 0.0121\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0135 - val_loss: 0.0428 - val_mse: 0.0134\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0131 - val_loss: 0.0414 - val_mse: 0.0121\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0130 - val_loss: 0.0411 - val_mse: 0.0120\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0136 - val_loss: 0.0425 - val_mse: 0.0135\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0130 - val_loss: 0.0410 - val_mse: 0.0123\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0143 - val_loss: 0.0445 - val_mse: 0.0159\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0128 - val_loss: 0.0415 - val_mse: 0.0131\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0130 - val_loss: 0.0454 - val_mse: 0.0172\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0139 - val_loss: 0.0409 - val_mse: 0.0128\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0137 - val_loss: 0.0399 - val_mse: 0.0120\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0129 - val_loss: 0.0403 - val_mse: 0.0126\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0132 - val_loss: 0.0405 - val_mse: 0.0130\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0404 - mse: 0.0129 - val_loss: 0.0402 - val_mse: 0.0128\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0134 - val_loss: 0.0399 - val_mse: 0.0127\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0134 - val_loss: 0.0394 - val_mse: 0.0123\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0127 - val_loss: 0.0397 - val_mse: 0.0129\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0138 - val_loss: 0.0401 - val_mse: 0.0133\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0138 - val_loss: 0.0395 - val_mse: 0.0129\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0131 - val_loss: 0.0388 - val_mse: 0.0124\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0130 - val_loss: 0.0408 - val_mse: 0.0145\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0126 - val_loss: 0.0379 - val_mse: 0.0118\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0139 - val_loss: 0.0376 - val_mse: 0.0117\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0128 - val_loss: 0.0378 - val_mse: 0.0120\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0131 - val_loss: 0.0378 - val_mse: 0.0122\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0130 - val_loss: 0.0448 - val_mse: 0.0193\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0136 - val_loss: 0.0382 - val_mse: 0.0129\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0126 - val_loss: 0.0372 - val_mse: 0.0120\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0125 - val_loss: 0.0365 - val_mse: 0.0114\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0135 - val_loss: 0.0363 - val_mse: 0.0114\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0123 - val_loss: 0.0415 - val_mse: 0.0168\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0129 - val_loss: 0.0364 - val_mse: 0.0118\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0124 - val_loss: 0.0366 - val_mse: 0.0122\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0126 - val_loss: 0.0384 - val_mse: 0.0141\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0126 - val_loss: 0.0365 - val_mse: 0.0123\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0131 - val_loss: 0.0370 - val_mse: 0.0129\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0124 - val_loss: 0.0351 - val_mse: 0.0112\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0124 - val_loss: 0.0362 - val_mse: 0.0125\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0116 - val_loss: 0.0350 - val_mse: 0.0114\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0128 - val_loss: 0.0361 - val_mse: 0.0126\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0135 - val_loss: 0.0377 - val_mse: 0.0143\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0127 - val_loss: 0.0362 - val_mse: 0.0130\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0123 - val_loss: 0.0347 - val_mse: 0.0116\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0349 - mse: 0.0119 - val_loss: 0.0371 - val_mse: 0.0141\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0124 - val_loss: 0.0341 - val_mse: 0.0113\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0130 - val_loss: 0.0342 - val_mse: 0.0115\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0118 - val_loss: 0.0353 - val_mse: 0.0127\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0132 - val_loss: 0.0369 - val_mse: 0.0145\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0343 - mse: 0.0119 - val_loss: 0.0336 - val_mse: 0.0113\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0341 - mse: 0.0118 - val_loss: 0.0346 - val_mse: 0.0124\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0348 - mse: 0.0127 - val_loss: 0.0333 - val_mse: 0.0113\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0121 - val_loss: 0.0327 - val_mse: 0.0108\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0127 - val_loss: 0.0338 - val_mse: 0.0120\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0343 - mse: 0.0125 - val_loss: 0.0325 - val_mse: 0.0109\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0339 - mse: 0.0123 - val_loss: 0.0323 - val_mse: 0.0108\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0338 - mse: 0.0124 - val_loss: 0.0324 - val_mse: 0.0110\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0334 - mse: 0.0121 - val_loss: 0.0376 - val_mse: 0.0163\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0335 - mse: 0.0122 - val_loss: 0.0320 - val_mse: 0.0108\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0115 - val_loss: 0.0323 - val_mse: 0.0113\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0338 - mse: 0.0128 - val_loss: 0.0325 - val_mse: 0.0116\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0330 - mse: 0.0121 - val_loss: 0.0338 - val_mse: 0.0130\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0335 - mse: 0.0128 - val_loss: 0.0314 - val_mse: 0.0107\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0323 - mse: 0.0116 - val_loss: 0.0312 - val_mse: 0.0106\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0120 - val_loss: 0.0317 - val_mse: 0.0112\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0124 - val_loss: 0.0309 - val_mse: 0.0106\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0121 - val_loss: 0.0316 - val_mse: 0.0114\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0114 - val_loss: 0.0331 - val_mse: 0.0130\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0118 - val_loss: 0.0305 - val_mse: 0.0105\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0121 - val_loss: 0.0349 - val_mse: 0.0150\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0124 - val_loss: 0.0305 - val_mse: 0.0107\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0116 - val_loss: 0.0305 - val_mse: 0.0108\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0119 - val_loss: 0.0310 - val_mse: 0.0114\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0311 - mse: 0.0116 - val_loss: 0.0308 - val_mse: 0.0113\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0312 - mse: 0.0118 - val_loss: 0.0309 - val_mse: 0.0115\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0123 - val_loss: 0.0307 - val_mse: 0.0114\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0115 - val_loss: 0.0301 - val_mse: 0.0109\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0118 - val_loss: 0.0299 - val_mse: 0.0108\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0113 - val_loss: 0.0292 - val_mse: 0.0102\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0119 - val_loss: 0.0303 - val_mse: 0.0114\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0114 - val_loss: 0.0310 - val_mse: 0.0122\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0112 - val_loss: 0.0299 - val_mse: 0.0112\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0117 - val_loss: 0.0288 - val_mse: 0.0102\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0117 - val_loss: 0.0357 - val_mse: 0.0172\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0118 - val_loss: 0.0290 - val_mse: 0.0107\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0122 - val_loss: 0.0286 - val_mse: 0.0103\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0117 - val_loss: 0.0371 - val_mse: 0.0189\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0114 - val_loss: 0.0299 - val_mse: 0.0118\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0120 - val_loss: 0.0287 - val_mse: 0.0106\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0114 - val_loss: 0.0324 - val_mse: 0.0145\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0114 - val_loss: 0.0282 - val_mse: 0.0104\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0116 - val_loss: 0.0290 - val_mse: 0.0113\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0114 - val_loss: 0.0277 - val_mse: 0.0101\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0120 - val_loss: 0.0276 - val_mse: 0.0100\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0117 - val_loss: 0.0296 - val_mse: 0.0121\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0113 - val_loss: 0.0278 - val_mse: 0.0104\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0109 - val_loss: 0.0277 - val_mse: 0.0104\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0120 - val_loss: 0.0278 - val_mse: 0.0106\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0116 - val_loss: 0.0279 - val_mse: 0.0108\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0113 - val_loss: 0.0271 - val_mse: 0.0101\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0115 - val_loss: 0.0309 - val_mse: 0.0139\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0116 - val_loss: 0.0271 - val_mse: 0.0103\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0120 - val_loss: 0.0276 - val_mse: 0.0108\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0111 - val_loss: 0.0279 - val_mse: 0.0112\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0111 - val_loss: 0.0275 - val_mse: 0.0109\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0112 - val_loss: 0.0269 - val_mse: 0.0104\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0282 - mse: 0.0117 - val_loss: 0.0274 - val_mse: 0.0110\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0108 - val_loss: 0.0276 - val_mse: 0.0113\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0118 - val_loss: 0.0261 - val_mse: 0.0098\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0109 - val_loss: 0.0269 - val_mse: 0.0107\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0114 - val_loss: 0.0271 - val_mse: 0.0110\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0110 - val_loss: 0.0266 - val_mse: 0.0106\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0118 - val_loss: 0.0258 - val_mse: 0.0099\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0114 - val_loss: 0.0271 - val_mse: 0.0112\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0118 - val_loss: 0.0255 - val_mse: 0.0097\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0117 - val_loss: 0.0262 - val_mse: 0.0105\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0114 - val_loss: 0.0253 - val_mse: 0.0097\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0116 - val_loss: 0.0257 - val_mse: 0.0102\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0114 - val_loss: 0.0251 - val_mse: 0.0096\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0119 - val_loss: 0.0261 - val_mse: 0.0107\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0268 - mse: 0.0114 - val_loss: 0.0255 - val_mse: 0.0101\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0110 - val_loss: 0.0291 - val_mse: 0.0138\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0117 - val_loss: 0.0253 - val_mse: 0.0101\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0115 - val_loss: 0.0254 - val_mse: 0.0102\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0109 - val_loss: 0.0259 - val_mse: 0.0108\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0108 - val_loss: 0.0245 - val_mse: 0.0095\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0115 - val_loss: 0.0246 - val_mse: 0.0097\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0114 - val_loss: 0.0244 - val_mse: 0.0096\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0109 - val_loss: 0.0259 - val_mse: 0.0111\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0109 - val_loss: 0.0257 - val_mse: 0.0110\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0112 - val_loss: 0.0243 - val_mse: 0.0097\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0257 - mse: 0.0111 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0110 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0109 - val_loss: 0.0275 - val_mse: 0.0131\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0111 - val_loss: 0.0241 - val_mse: 0.0097\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0110 - val_loss: 0.0237 - val_mse: 0.0094\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0113 - val_loss: 0.0237 - val_mse: 0.0095\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0108 - val_loss: 0.0255 - val_mse: 0.0113\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0263 - mse: 0.0121 - val_loss: 0.0239 - val_mse: 0.0098\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0252 - mse: 0.0111 - val_loss: 0.0241 - val_mse: 0.0101\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0110 - val_loss: 0.0237 - val_mse: 0.0097\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0105 - val_loss: 0.0234 - val_mse: 0.0095\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0253 - mse: 0.0114 - val_loss: 0.0241 - val_mse: 0.0102\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0244 - mse: 0.0106 - val_loss: 0.0235 - val_mse: 0.0097\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0243 - mse: 0.0105 - val_loss: 0.0245 - val_mse: 0.0108\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0110 - val_loss: 0.0230 - val_mse: 0.0094\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0104 - val_loss: 0.0232 - val_mse: 0.0096\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0109 - val_loss: 0.0231 - val_mse: 0.0096\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0112 - val_loss: 0.0247 - val_mse: 0.0112\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0110 - val_loss: 0.0231 - val_mse: 0.0097\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0112 - val_loss: 0.0273 - val_mse: 0.0139\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0108 - val_loss: 0.0291 - val_mse: 0.0158\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0108 - val_loss: 0.0225 - val_mse: 0.0093\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0108 - val_loss: 0.0228 - val_mse: 0.0096\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0106 - val_loss: 0.0284 - val_mse: 0.0153\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0108 - val_loss: 0.0225 - val_mse: 0.0094\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0116 - val_loss: 0.0237 - val_mse: 0.0107\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0117 - val_loss: 0.0222 - val_mse: 0.0093\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0107 - val_loss: 0.0221 - val_mse: 0.0092\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0236 - mse: 0.0107 - val_loss: 0.0243 - val_mse: 0.0114\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0106 - val_loss: 0.0227 - val_mse: 0.0099\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0107 - val_loss: 0.0303 - val_mse: 0.0176\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0106 - val_loss: 0.0220 - val_mse: 0.0093\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0109 - val_loss: 0.0221 - val_mse: 0.0094\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0103 - val_loss: 0.0223 - val_mse: 0.0097\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0240 - mse: 0.0115 - val_loss: 0.0217 - val_mse: 0.0092\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0101 - val_loss: 0.0216 - val_mse: 0.0092\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0100 - val_loss: 0.0224 - val_mse: 0.0100\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0109 - val_loss: 0.0222 - val_mse: 0.0098\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0112 - val_loss: 0.0215 - val_mse: 0.0091\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0112 - val_loss: 0.0221 - val_mse: 0.0098\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0105 - val_loss: 0.0219 - val_mse: 0.0097\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0107 - val_loss: 0.0255 - val_mse: 0.0134\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0113 - val_loss: 0.0217 - val_mse: 0.0096\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0113 - val_loss: 0.0211 - val_mse: 0.0091\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0108 - val_loss: 0.0218 - val_mse: 0.0097\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0106 - val_loss: 0.0237 - val_mse: 0.0117\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0105 - val_loss: 0.0210 - val_mse: 0.0091\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0101 - val_loss: 0.0228 - val_mse: 0.0110\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0108 - val_loss: 0.0216 - val_mse: 0.0098\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0106 - val_loss: 0.0223 - val_mse: 0.0105\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0225 - mse: 0.0108 - val_loss: 0.0235 - val_mse: 0.0117\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0105 - val_loss: 0.0234 - val_mse: 0.0117\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0109 - val_loss: 0.0217 - val_mse: 0.0100\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0103 - val_loss: 0.0205 - val_mse: 0.0089\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0109 - val_loss: 0.0239 - val_mse: 0.0123\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0108 - val_loss: 0.0210 - val_mse: 0.0095\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0108 - val_loss: 0.0208 - val_mse: 0.0093\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0109 - val_loss: 0.0205 - val_mse: 0.0091\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0107 - val_loss: 0.0212 - val_mse: 0.0098\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0220 - mse: 0.0107 - val_loss: 0.0203 - val_mse: 0.0089\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0099 - val_loss: 0.0202 - val_mse: 0.0089\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0102 - val_loss: 0.0203 - val_mse: 0.0090\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0106 - val_loss: 0.0221 - val_mse: 0.0109\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0108 - val_loss: 0.0200 - val_mse: 0.0088\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0105 - val_loss: 0.0228 - val_mse: 0.0117\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0103 - val_loss: 0.0232 - val_mse: 0.0121\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0105 - val_loss: 0.0214 - val_mse: 0.0104\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0107 - val_loss: 0.0222 - val_mse: 0.0112\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0106 - val_loss: 0.0197 - val_mse: 0.0088\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0106 - val_loss: 0.0207 - val_mse: 0.0098\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0107 - val_loss: 0.0200 - val_mse: 0.0091\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0109 - val_loss: 0.0198 - val_mse: 0.0090\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0106 - val_loss: 0.0255 - val_mse: 0.0148\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0101 - val_loss: 0.0195 - val_mse: 0.0088\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0098 - val_loss: 0.0217 - val_mse: 0.0110\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0106 - val_loss: 0.0195 - val_mse: 0.0089\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0104 - val_loss: 0.0197 - val_mse: 0.0091\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0105 - val_loss: 0.0194 - val_mse: 0.0089\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0205 - mse: 0.0100 - val_loss: 0.0208 - val_mse: 0.0102\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0103 - val_loss: 0.0195 - val_mse: 0.0090\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0100 - val_loss: 0.0206 - val_mse: 0.0102\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0210 - mse: 0.0106 - val_loss: 0.0193 - val_mse: 0.0089\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0105 - val_loss: 0.0196 - val_mse: 0.0092\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0103 - val_loss: 0.0196 - val_mse: 0.0093\n",
      "Epoch 308: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 15.2477 - mse: 0.5893 - val_loss: 0.1861 - val_mse: 0.0578\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.0957 - val_loss: 0.0806 - val_mse: 0.0553\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1193 - mse: 0.0957 - val_loss: 0.1092 - val_mse: 0.0925\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1207 - mse: 0.0973 - val_loss: 0.1093 - val_mse: 0.0925\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.0947 - val_loss: 0.0809 - val_mse: 0.0568\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1192 - mse: 0.0957 - val_loss: 0.0914 - val_mse: 0.0716\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.0990 - val_loss: 0.0811 - val_mse: 0.0573\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.0972 - val_loss: 0.1109 - val_mse: 0.0944\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1235 - mse: 0.1003 - val_loss: 0.0886 - val_mse: 0.0583\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.0950 - val_loss: 0.1173 - val_mse: 0.1016\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1235 - mse: 0.1002 - val_loss: 0.0805 - val_mse: 0.0554\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1199 - mse: 0.0965 - val_loss: 0.0805 - val_mse: 0.0556\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1202 - mse: 0.0966 - val_loss: 0.1120 - val_mse: 0.0956\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.0945 - val_loss: 0.1040 - val_mse: 0.0865\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1199 - mse: 0.0967 - val_loss: 0.0805 - val_mse: 0.0550\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1216 - mse: 0.0981 - val_loss: 0.0853 - val_mse: 0.0638\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1203 - mse: 0.0968 - val_loss: 0.0854 - val_mse: 0.0640\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.0989 - val_loss: 0.0817 - val_mse: 0.0585\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1196 - mse: 0.0963 - val_loss: 0.0822 - val_mse: 0.0548\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1216 - mse: 0.0980 - val_loss: 0.1030 - val_mse: 0.0854\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1219 - mse: 0.0986 - val_loss: 0.0839 - val_mse: 0.0618\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1204 - mse: 0.0969 - val_loss: 0.0835 - val_mse: 0.0613\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1184 - mse: 0.0951 - val_loss: 0.0807 - val_mse: 0.0563\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1211 - mse: 0.0977 - val_loss: 0.1032 - val_mse: 0.0856\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1211 - mse: 0.0976 - val_loss: 0.0921 - val_mse: 0.0725\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1192 - mse: 0.0958 - val_loss: 0.0805 - val_mse: 0.0560\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1167 - mse: 0.0933 - val_loss: 0.0854 - val_mse: 0.0564\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1210 - mse: 0.0974 - val_loss: 0.0818 - val_mse: 0.0587\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.0990 - val_loss: 0.0804 - val_mse: 0.0554\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1233 - mse: 0.0997 - val_loss: 0.0815 - val_mse: 0.0580\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1203 - mse: 0.0969 - val_loss: 0.0827 - val_mse: 0.0601\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1219 - mse: 0.0983 - val_loss: 0.0828 - val_mse: 0.0602\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1185 - mse: 0.0952 - val_loss: 0.0806 - val_mse: 0.0561\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1203 - mse: 0.0967 - val_loss: 0.0820 - val_mse: 0.0590\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.0936 - val_loss: 0.0936 - val_mse: 0.0743\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.0973 - val_loss: 0.0966 - val_mse: 0.0779\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.0990 - val_loss: 0.0814 - val_mse: 0.0580\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1220 - mse: 0.0986 - val_loss: 0.0880 - val_mse: 0.0579\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.0978 - val_loss: 0.0926 - val_mse: 0.0731\n",
      "Epoch 39: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 8.5219 - mse: 1.6645 - val_loss: 4.9165 - val_mse: 0.0474\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6892 - mse: 0.0845 - val_loss: 2.5967 - val_mse: 0.0381\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.9656 - mse: 0.0676 - val_loss: 1.3796 - val_mse: 0.0273\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.0626 - mse: 0.0538 - val_loss: 0.7510 - val_mse: 0.0278\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6018 - mse: 0.0580 - val_loss: 0.4343 - val_mse: 0.0391\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3664 - mse: 0.0644 - val_loss: 0.2615 - val_mse: 0.0373\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2434 - mse: 0.0692 - val_loss: 0.1756 - val_mse: 0.0438\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1809 - mse: 0.0763 - val_loss: 0.1394 - val_mse: 0.0591\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1501 - mse: 0.0853 - val_loss: 0.0995 - val_mse: 0.0478\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1276 - mse: 0.0858 - val_loss: 0.0838 - val_mse: 0.0500\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.0932 - val_loss: 0.0864 - val_mse: 0.0646\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1105 - mse: 0.0922 - val_loss: 0.0681 - val_mse: 0.0530\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1085 - mse: 0.0962 - val_loss: 0.0880 - val_mse: 0.0785\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1048 - mse: 0.0963 - val_loss: 0.0620 - val_mse: 0.0548\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1027 - mse: 0.0966 - val_loss: 0.0622 - val_mse: 0.0569\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0997 - mse: 0.0950 - val_loss: 0.0596 - val_mse: 0.0551\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0987 - mse: 0.0949 - val_loss: 0.0582 - val_mse: 0.0545\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1023 - mse: 0.0990 - val_loss: 0.0650 - val_mse: 0.0621\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0987 - mse: 0.0957 - val_loss: 0.0609 - val_mse: 0.0575\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1015 - mse: 0.0986 - val_loss: 0.0621 - val_mse: 0.0595\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0942 - val_loss: 0.0794 - val_mse: 0.0774\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0956 - val_loss: 0.0659 - val_mse: 0.0636\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0980 - mse: 0.0954 - val_loss: 0.0746 - val_mse: 0.0725\n",
      "Epoch 23: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.0006 - mse: 0.1166 - val_loss: 0.9307 - val_mse: 0.0758\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.9130 - mse: 0.0846 - val_loss: 0.8381 - val_mse: 0.0364\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.8397 - mse: 0.0628 - val_loss: 0.7916 - val_mse: 0.0394\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7717 - mse: 0.0428 - val_loss: 0.7333 - val_mse: 0.0276\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7209 - mse: 0.0370 - val_loss: 0.6864 - val_mse: 0.0243\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.6723 - mse: 0.0307 - val_loss: 0.6784 - val_mse: 0.0574\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.6319 - mse: 0.0299 - val_loss: 0.6222 - val_mse: 0.0395\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5919 - mse: 0.0270 - val_loss: 0.5657 - val_mse: 0.0187\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5558 - mse: 0.0257 - val_loss: 0.5321 - val_mse: 0.0189\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5212 - mse: 0.0236 - val_loss: 0.4990 - val_mse: 0.0172\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4895 - mse: 0.0224 - val_loss: 0.4712 - val_mse: 0.0189\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4601 - mse: 0.0216 - val_loss: 0.4492 - val_mse: 0.0245\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4332 - mse: 0.0214 - val_loss: 0.4179 - val_mse: 0.0190\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4077 - mse: 0.0210 - val_loss: 0.3946 - val_mse: 0.0200\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3834 - mse: 0.0202 - val_loss: 0.3669 - val_mse: 0.0150\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3638 - mse: 0.0226 - val_loss: 0.3458 - val_mse: 0.0151\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3401 - mse: 0.0193 - val_loss: 0.3255 - val_mse: 0.0147\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3222 - mse: 0.0208 - val_loss: 0.3096 - val_mse: 0.0175\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3033 - mse: 0.0200 - val_loss: 0.3137 - val_mse: 0.0392\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2872 - mse: 0.0208 - val_loss: 0.2741 - val_mse: 0.0159\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2709 - mse: 0.0204 - val_loss: 0.2582 - val_mse: 0.0152\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2555 - mse: 0.0198 - val_loss: 0.2448 - val_mse: 0.0162\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2411 - mse: 0.0192 - val_loss: 0.2314 - val_mse: 0.0162\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2287 - mse: 0.0198 - val_loss: 0.2168 - val_mse: 0.0143\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2156 - mse: 0.0189 - val_loss: 0.2098 - val_mse: 0.0189\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2052 - mse: 0.0199 - val_loss: 0.1941 - val_mse: 0.0143\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1941 - mse: 0.0194 - val_loss: 0.1894 - val_mse: 0.0199\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1843 - mse: 0.0196 - val_loss: 0.1746 - val_mse: 0.0148\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1749 - mse: 0.0195 - val_loss: 0.1671 - val_mse: 0.0162\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1666 - mse: 0.0199 - val_loss: 0.1582 - val_mse: 0.0158\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1577 - mse: 0.0191 - val_loss: 0.1516 - val_mse: 0.0172\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1514 - mse: 0.0206 - val_loss: 0.1431 - val_mse: 0.0160\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1440 - mse: 0.0203 - val_loss: 0.1448 - val_mse: 0.0245\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1377 - mse: 0.0207 - val_loss: 0.1296 - val_mse: 0.0158\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1313 - mse: 0.0206 - val_loss: 0.1229 - val_mse: 0.0152\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1243 - mse: 0.0194 - val_loss: 0.1184 - val_mse: 0.0162\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1198 - mse: 0.0202 - val_loss: 0.1140 - val_mse: 0.0171\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1139 - mse: 0.0194 - val_loss: 0.1144 - val_mse: 0.0223\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1088 - mse: 0.0191 - val_loss: 0.1023 - val_mse: 0.0152\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1047 - mse: 0.0196 - val_loss: 0.0997 - val_mse: 0.0166\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1017 - mse: 0.0207 - val_loss: 0.0948 - val_mse: 0.0158\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0966 - mse: 0.0195 - val_loss: 0.0901 - val_mse: 0.0149\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0931 - mse: 0.0196 - val_loss: 0.0918 - val_mse: 0.0200\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0898 - mse: 0.0197 - val_loss: 0.0854 - val_mse: 0.0169\n",
      "Epoch 44: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 5ms/step - loss: 0.2336 - mse: 0.1687 - val_loss: 0.1231 - val_mse: 0.0584\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1206 - mse: 0.0562 - val_loss: 0.0854 - val_mse: 0.0211\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0912 - mse: 0.0272 - val_loss: 0.0918 - val_mse: 0.0280\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0866 - mse: 0.0230 - val_loss: 0.0851 - val_mse: 0.0217\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0229 - val_loss: 0.0824 - val_mse: 0.0195\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0218 - val_loss: 0.0798 - val_mse: 0.0174\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0832 - mse: 0.0210 - val_loss: 0.0782 - val_mse: 0.0162\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0813 - mse: 0.0195 - val_loss: 0.0772 - val_mse: 0.0156\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0833 - mse: 0.0220 - val_loss: 0.0743 - val_mse: 0.0132\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0790 - mse: 0.0181 - val_loss: 0.0929 - val_mse: 0.0322\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0795 - mse: 0.0190 - val_loss: 0.0742 - val_mse: 0.0139\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0165 - val_loss: 0.0849 - val_mse: 0.0250\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0775 - mse: 0.0178 - val_loss: 0.0725 - val_mse: 0.0129\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0753 - mse: 0.0160 - val_loss: 0.0720 - val_mse: 0.0129\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0751 - mse: 0.0162 - val_loss: 0.0711 - val_mse: 0.0124\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0173 - val_loss: 0.0707 - val_mse: 0.0123\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0159 - val_loss: 0.0761 - val_mse: 0.0181\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0747 - mse: 0.0169 - val_loss: 0.0691 - val_mse: 0.0115\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0728 - mse: 0.0154 - val_loss: 0.0710 - val_mse: 0.0137\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0161 - val_loss: 0.0682 - val_mse: 0.0113\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0146 - val_loss: 0.0678 - val_mse: 0.0112\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0711 - mse: 0.0147 - val_loss: 0.0682 - val_mse: 0.0120\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0149 - val_loss: 0.0692 - val_mse: 0.0134\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0161 - val_loss: 0.0662 - val_mse: 0.0107\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0135 - val_loss: 0.0671 - val_mse: 0.0119\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0138 - val_loss: 0.0652 - val_mse: 0.0104\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0140 - val_loss: 0.0666 - val_mse: 0.0121\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0132 - val_loss: 0.0644 - val_mse: 0.0103\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0120 - val_loss: 0.0650 - val_mse: 0.0112\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0119 - val_loss: 0.0646 - val_mse: 0.0110\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0127 - val_loss: 0.0633 - val_mse: 0.0101\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0127 - val_loss: 0.0646 - val_mse: 0.0118\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0130 - val_loss: 0.0642 - val_mse: 0.0116\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0117 - val_loss: 0.0619 - val_mse: 0.0096\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0119 - val_loss: 0.0641 - val_mse: 0.0121\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0111 - val_loss: 0.0617 - val_mse: 0.0101\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0117 - val_loss: 0.0616 - val_mse: 0.0102\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0113 - val_loss: 0.0609 - val_mse: 0.0099\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0113 - val_loss: 0.0604 - val_mse: 0.0097\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0121 - val_loss: 0.0600 - val_mse: 0.0096\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0112 - val_loss: 0.0597 - val_mse: 0.0095\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0108 - val_loss: 0.0590 - val_mse: 0.0092\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0104 - val_loss: 0.0596 - val_mse: 0.0101\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0108 - val_loss: 0.0685 - val_mse: 0.0193\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0113 - val_loss: 0.0620 - val_mse: 0.0130\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0108 - val_loss: 0.0583 - val_mse: 0.0096\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0104 - val_loss: 0.0608 - val_mse: 0.0124\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0109 - val_loss: 0.0582 - val_mse: 0.0100\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0098 - val_loss: 0.0623 - val_mse: 0.0145\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0102 - val_loss: 0.0563 - val_mse: 0.0088\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0099 - val_loss: 0.0580 - val_mse: 0.0107\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0100 - val_loss: 0.0608 - val_mse: 0.0138\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0105 - val_loss: 0.0558 - val_mse: 0.0091\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0101 - val_loss: 0.0555 - val_mse: 0.0090\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0097 - val_loss: 0.0551 - val_mse: 0.0089\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0099 - val_loss: 0.0562 - val_mse: 0.0102\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0106 - val_loss: 0.0549 - val_mse: 0.0093\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0090 - val_loss: 0.0594 - val_mse: 0.0140\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0113 - val_loss: 0.0549 - val_mse: 0.0097\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0101 - val_loss: 0.0569 - val_mse: 0.0120\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0112 - val_loss: 0.0534 - val_mse: 0.0087\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0544 - mse: 0.0098 - val_loss: 0.0534 - val_mse: 0.0090\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0097 - val_loss: 0.0547 - val_mse: 0.0105\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0098 - val_loss: 0.0614 - val_mse: 0.0175\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0102 - val_loss: 0.0544 - val_mse: 0.0107\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0101 - val_loss: 0.0552 - val_mse: 0.0118\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0100 - val_loss: 0.0531 - val_mse: 0.0100\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0095 - val_loss: 0.0525 - val_mse: 0.0096\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0100 - val_loss: 0.0513 - val_mse: 0.0086\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0100 - val_loss: 0.0513 - val_mse: 0.0089\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0101 - val_loss: 0.0509 - val_mse: 0.0088\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0090 - val_loss: 0.0548 - val_mse: 0.0129\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0091 - val_loss: 0.0504 - val_mse: 0.0088\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0104 - val_loss: 0.0499 - val_mse: 0.0085\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0103 - val_loss: 0.0575 - val_mse: 0.0163\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0507 - mse: 0.0096 - val_loss: 0.0498 - val_mse: 0.0088\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0104 - val_loss: 0.0549 - val_mse: 0.0141\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0103 - val_loss: 0.0519 - val_mse: 0.0114\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0098 - val_loss: 0.0495 - val_mse: 0.0091\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0103 - val_loss: 0.0490 - val_mse: 0.0090\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0094 - val_loss: 0.0497 - val_mse: 0.0099\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0099 - val_loss: 0.0500 - val_mse: 0.0104\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0093 - val_loss: 0.0486 - val_mse: 0.0092\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0098 - val_loss: 0.0479 - val_mse: 0.0087\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0094 - val_loss: 0.0490 - val_mse: 0.0100\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0097 - val_loss: 0.0472 - val_mse: 0.0085\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0477 - mse: 0.0091 - val_loss: 0.0470 - val_mse: 0.0085\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0101 - val_loss: 0.0468 - val_mse: 0.0085\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0092 - val_loss: 0.0465 - val_mse: 0.0085\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0098 - val_loss: 0.0469 - val_mse: 0.0090\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0095 - val_loss: 0.0497 - val_mse: 0.0120\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0096 - val_loss: 0.0460 - val_mse: 0.0086\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0089 - val_loss: 0.0469 - val_mse: 0.0097\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0087 - val_loss: 0.0452 - val_mse: 0.0082\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0100 - val_loss: 0.0495 - val_mse: 0.0127\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0459 - mse: 0.0091 - val_loss: 0.0448 - val_mse: 0.0082\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0088 - val_loss: 0.0447 - val_mse: 0.0083\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0455 - mse: 0.0092 - val_loss: 0.0462 - val_mse: 0.0100\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0454 - mse: 0.0093 - val_loss: 0.0444 - val_mse: 0.0084\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0449 - mse: 0.0090 - val_loss: 0.0442 - val_mse: 0.0084\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0096 - val_loss: 0.0445 - val_mse: 0.0090\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0095 - val_loss: 0.0444 - val_mse: 0.0090\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0107 - val_loss: 0.0477 - val_mse: 0.0125\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0094 - val_loss: 0.0463 - val_mse: 0.0113\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0094 - val_loss: 0.0429 - val_mse: 0.0081\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0092 - val_loss: 0.0428 - val_mse: 0.0082\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0093 - val_loss: 0.0439 - val_mse: 0.0095\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0090 - val_loss: 0.0515 - val_mse: 0.0173\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0091 - val_loss: 0.0426 - val_mse: 0.0085\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0093 - val_loss: 0.0422 - val_mse: 0.0083\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0092 - val_loss: 0.0431 - val_mse: 0.0094\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0429 - mse: 0.0093 - val_loss: 0.0419 - val_mse: 0.0084\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0091 - val_loss: 0.0436 - val_mse: 0.0103\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0099 - val_loss: 0.0509 - val_mse: 0.0177\n",
      "Epoch 114: early stopping\n",
      "0 0.0103 0.0093 308 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "1 0.0094 0.0094 184 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "2 0.0227 0.0159 95 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "3 0.0197 0.0169 44 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "4 0.0099 0.0177 114 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "5 0.0161 0.0178 52 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "6 0.0961 0.0549 24 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "7 0.0951 0.0589 36 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "8 0.0954 0.0725 23 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "9 0.0978 0.0731 39 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "10 0.0929 0.0781 21 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "11 0.0945 0.0788 21 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_noise_low = add_gaussian_noise(X_train, std=0.05)\n",
    "y_train_noise_low = add_gaussian_noise(y_train, std=0.05)\n",
    "\n",
    "X_val_noise_low = add_gaussian_noise(X_val, std=0.05)\n",
    "y_val_noise_low = add_gaussian_noise(y_val, std=0.05)\n",
    "\n",
    "noise_low_eval_grid = grid_search(param_dict, X_train_noise_low, y_train_noise_low, X_val_noise_low, y_val_noise_low)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0103 0.0093 308 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "1 0.0094 0.0094 184 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "2 0.0227 0.0159 95 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "3 0.0197 0.0169 44 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "4 0.0099 0.0177 114 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "5 0.0161 0.0178 52 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "6 0.0961 0.0549 24 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "7 0.0951 0.0589 36 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "8 0.0954 0.0725 23 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "9 0.0978 0.0731 39 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "10 0.0929 0.0781 21 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "11 0.0945 0.0788 21 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (param, model, history, final_train_mse, final_val_mse, epoch) in enumerate(noise_low_eval_grid):\n",
    "    config = param[\"regularizer\"].get_config()\n",
    "    print(i, final_train_mse, final_val_mse, epoch, config, param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 7.0436 - mse: 0.1775 - val_loss: 0.1754 - val_mse: 0.0754\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1690 - mse: 0.1202 - val_loss: 0.1221 - val_mse: 0.0754\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1603 - mse: 0.1197 - val_loss: 0.1270 - val_mse: 0.0919\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1628 - mse: 0.1223 - val_loss: 0.1203 - val_mse: 0.0781\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1604 - mse: 0.1199 - val_loss: 0.1218 - val_mse: 0.0829\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1591 - mse: 0.1186 - val_loss: 0.1220 - val_mse: 0.0833\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1609 - mse: 0.1204 - val_loss: 0.1204 - val_mse: 0.0792\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1583 - mse: 0.1177 - val_loss: 0.1325 - val_mse: 0.0997\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1604 - mse: 0.1200 - val_loss: 0.1300 - val_mse: 0.0963\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1617 - mse: 0.1214 - val_loss: 0.1207 - val_mse: 0.0802\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1592 - mse: 0.1185 - val_loss: 0.1210 - val_mse: 0.0809\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1589 - mse: 0.1185 - val_loss: 0.1213 - val_mse: 0.0756\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1592 - mse: 0.1187 - val_loss: 0.1205 - val_mse: 0.0792\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1594 - mse: 0.1189 - val_loss: 0.1207 - val_mse: 0.0762\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1599 - mse: 0.1191 - val_loss: 0.1413 - val_mse: 0.1113\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1585 - mse: 0.1186 - val_loss: 0.1244 - val_mse: 0.0756\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.1187 - val_loss: 0.1204 - val_mse: 0.0791\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1602 - mse: 0.1197 - val_loss: 0.1277 - val_mse: 0.0929\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1605 - mse: 0.1199 - val_loss: 0.1257 - val_mse: 0.0897\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1607 - mse: 0.1200 - val_loss: 0.1608 - val_mse: 0.1351\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1607 - mse: 0.1207 - val_loss: 0.1243 - val_mse: 0.0756\n",
      "Epoch 21: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 3.5507 - mse: 0.2750 - val_loss: 2.3980 - val_mse: 0.0724\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.8359 - mse: 0.1139 - val_loss: 1.2958 - val_mse: 0.0735\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0182 - mse: 0.1120 - val_loss: 0.7170 - val_mse: 0.0729\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5918 - mse: 0.1130 - val_loss: 0.4272 - val_mse: 0.0860\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3687 - mse: 0.1130 - val_loss: 0.2611 - val_mse: 0.0774\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2526 - mse: 0.1138 - val_loss: 0.1746 - val_mse: 0.0731\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1919 - mse: 0.1149 - val_loss: 0.1363 - val_mse: 0.0782\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1582 - mse: 0.1141 - val_loss: 0.1082 - val_mse: 0.0748\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1436 - mse: 0.1172 - val_loss: 0.0953 - val_mse: 0.0745\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1349 - mse: 0.1182 - val_loss: 0.0901 - val_mse: 0.0768\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1281 - mse: 0.1168 - val_loss: 0.0854 - val_mse: 0.0759\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1258 - mse: 0.1174 - val_loss: 0.1052 - val_mse: 0.0991\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.1195 - val_loss: 0.0908 - val_mse: 0.0854\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1238 - mse: 0.1181 - val_loss: 0.0866 - val_mse: 0.0817\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1226 - mse: 0.1174 - val_loss: 0.0811 - val_mse: 0.0761\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1256 - mse: 0.1207 - val_loss: 0.0836 - val_mse: 0.0791\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1220 - mse: 0.1173 - val_loss: 0.0809 - val_mse: 0.0762\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1245 - mse: 0.1198 - val_loss: 0.0815 - val_mse: 0.0763\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1226 - mse: 0.1180 - val_loss: 0.0809 - val_mse: 0.0758\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1194 - val_loss: 0.1005 - val_mse: 0.0971\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1220 - mse: 0.1175 - val_loss: 0.1087 - val_mse: 0.1055\n",
      "Epoch 21: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.6031 - mse: 0.2821 - val_loss: 0.3881 - val_mse: 0.0813\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4114 - mse: 0.1151 - val_loss: 0.3893 - val_mse: 0.1036\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3822 - mse: 0.1061 - val_loss: 0.3767 - val_mse: 0.1105\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3499 - mse: 0.0925 - val_loss: 0.3199 - val_mse: 0.0716\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3210 - mse: 0.0809 - val_loss: 0.2905 - val_mse: 0.0588\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2959 - mse: 0.0718 - val_loss: 0.2706 - val_mse: 0.0540\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2786 - mse: 0.0690 - val_loss: 0.2589 - val_mse: 0.0561\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2645 - mse: 0.0683 - val_loss: 0.2653 - val_mse: 0.0754\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2477 - mse: 0.0637 - val_loss: 0.2352 - val_mse: 0.0571\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2337 - mse: 0.0610 - val_loss: 0.2261 - val_mse: 0.0590\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2261 - mse: 0.0641 - val_loss: 0.2091 - val_mse: 0.0522\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2158 - mse: 0.0636 - val_loss: 0.1987 - val_mse: 0.0512\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2059 - mse: 0.0629 - val_loss: 0.1885 - val_mse: 0.0500\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1967 - mse: 0.0623 - val_loss: 0.1824 - val_mse: 0.0522\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1886 - mse: 0.0623 - val_loss: 0.1745 - val_mse: 0.0520\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1785 - mse: 0.0597 - val_loss: 0.1719 - val_mse: 0.0568\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1742 - mse: 0.0623 - val_loss: 0.1708 - val_mse: 0.0624\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1667 - mse: 0.0615 - val_loss: 0.1641 - val_mse: 0.0620\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1593 - mse: 0.0603 - val_loss: 0.1567 - val_mse: 0.0607\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1537 - mse: 0.0605 - val_loss: 0.1407 - val_mse: 0.0503\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1459 - mse: 0.0581 - val_loss: 0.1451 - val_mse: 0.0598\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.0602 - val_loss: 0.1461 - val_mse: 0.0656\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1385 - mse: 0.0604 - val_loss: 0.1276 - val_mse: 0.0518\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1349 - mse: 0.0613 - val_loss: 0.1239 - val_mse: 0.0526\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1274 - mse: 0.0580 - val_loss: 0.1175 - val_mse: 0.0503\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1237 - mse: 0.0583 - val_loss: 0.1133 - val_mse: 0.0497\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1200 - mse: 0.0581 - val_loss: 0.1097 - val_mse: 0.0497\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.0586 - val_loss: 0.1202 - val_mse: 0.0633\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1124 - mse: 0.0571 - val_loss: 0.1086 - val_mse: 0.0548\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1100 - mse: 0.0577 - val_loss: 0.1009 - val_mse: 0.0501\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1086 - mse: 0.0591 - val_loss: 0.0991 - val_mse: 0.0509\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1038 - mse: 0.0569 - val_loss: 0.0959 - val_mse: 0.0502\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1015 - mse: 0.0570 - val_loss: 0.0970 - val_mse: 0.0537\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0980 - mse: 0.0558 - val_loss: 0.0965 - val_mse: 0.0552\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0977 - mse: 0.0574 - val_loss: 0.1005 - val_mse: 0.0610\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0941 - mse: 0.0557 - val_loss: 0.0937 - val_mse: 0.0561\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0954 - mse: 0.0586 - val_loss: 0.0979 - val_mse: 0.0620\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0571 - val_loss: 0.1000 - val_mse: 0.0658\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0927 - mse: 0.0591 - val_loss: 0.0994 - val_mse: 0.0663\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0905 - mse: 0.0582 - val_loss: 0.0928 - val_mse: 0.0609\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0874 - mse: 0.0561 - val_loss: 0.0826 - val_mse: 0.0520\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0560 - val_loss: 0.0850 - val_mse: 0.0555\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0570 - val_loss: 0.0790 - val_mse: 0.0506\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0564 - val_loss: 0.0800 - val_mse: 0.0525\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0838 - mse: 0.0566 - val_loss: 0.1112 - val_mse: 0.0847\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0834 - mse: 0.0572 - val_loss: 0.0940 - val_mse: 0.0680\n",
      "Epoch 46: early stopping\n",
      "{'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 3\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.9120 - mse: 0.8529 - val_loss: 0.1280 - val_mse: 0.0691\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1609 - mse: 0.1022 - val_loss: 0.1217 - val_mse: 0.0631\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1461 - mse: 0.0877 - val_loss: 0.1257 - val_mse: 0.0675\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1421 - mse: 0.0840 - val_loss: 0.1479 - val_mse: 0.0900\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1410 - mse: 0.0834 - val_loss: 0.1236 - val_mse: 0.0661\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1364 - mse: 0.0791 - val_loss: 0.1400 - val_mse: 0.0829\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1360 - mse: 0.0791 - val_loss: 0.1330 - val_mse: 0.0762\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1337 - mse: 0.0772 - val_loss: 0.1216 - val_mse: 0.0652\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1334 - mse: 0.0772 - val_loss: 0.1190 - val_mse: 0.0630\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.0777 - val_loss: 0.1255 - val_mse: 0.0699\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1302 - mse: 0.0748 - val_loss: 0.1194 - val_mse: 0.0641\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1289 - mse: 0.0738 - val_loss: 0.1267 - val_mse: 0.0718\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1288 - mse: 0.0741 - val_loss: 0.1195 - val_mse: 0.0649\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 0.0755 - val_loss: 0.1424 - val_mse: 0.0883\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1272 - mse: 0.0733 - val_loss: 0.1163 - val_mse: 0.0625\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.0712 - val_loss: 0.1157 - val_mse: 0.0622\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1242 - mse: 0.0710 - val_loss: 0.1144 - val_mse: 0.0613\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1227 - mse: 0.0698 - val_loss: 0.1158 - val_mse: 0.0631\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1219 - mse: 0.0693 - val_loss: 0.1179 - val_mse: 0.0655\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1230 - mse: 0.0708 - val_loss: 0.1354 - val_mse: 0.0834\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1213 - mse: 0.0695 - val_loss: 0.1157 - val_mse: 0.0640\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1210 - mse: 0.0695 - val_loss: 0.1111 - val_mse: 0.0598\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1210 - mse: 0.0698 - val_loss: 0.1270 - val_mse: 0.0760\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.0673 - val_loss: 0.1088 - val_mse: 0.0581\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1168 - mse: 0.0663 - val_loss: 0.1091 - val_mse: 0.0588\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1160 - mse: 0.0658 - val_loss: 0.1089 - val_mse: 0.0589\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1167 - mse: 0.0669 - val_loss: 0.1077 - val_mse: 0.0581\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1186 - mse: 0.0691 - val_loss: 0.1095 - val_mse: 0.0602\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1158 - mse: 0.0667 - val_loss: 0.1074 - val_mse: 0.0584\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1153 - mse: 0.0665 - val_loss: 0.1071 - val_mse: 0.0585\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.0659 - val_loss: 0.1110 - val_mse: 0.0627\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1140 - mse: 0.0659 - val_loss: 0.1059 - val_mse: 0.0579\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1116 - mse: 0.0638 - val_loss: 0.1065 - val_mse: 0.0588\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1123 - mse: 0.0647 - val_loss: 0.1063 - val_mse: 0.0589\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1131 - mse: 0.0659 - val_loss: 0.1245 - val_mse: 0.0774\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1115 - mse: 0.0646 - val_loss: 0.1103 - val_mse: 0.0636\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.0633 - val_loss: 0.1012 - val_mse: 0.0548\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1083 - mse: 0.0620 - val_loss: 0.1120 - val_mse: 0.0658\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.0619 - val_loss: 0.1089 - val_mse: 0.0631\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.0625 - val_loss: 0.1168 - val_mse: 0.0713\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0611 - val_loss: 0.1045 - val_mse: 0.0593\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1073 - mse: 0.0622 - val_loss: 0.1004 - val_mse: 0.0555\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0626 - val_loss: 0.1005 - val_mse: 0.0559\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1076 - mse: 0.0631 - val_loss: 0.0989 - val_mse: 0.0546\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1039 - mse: 0.0597 - val_loss: 0.0987 - val_mse: 0.0546\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1068 - mse: 0.0629 - val_loss: 0.1134 - val_mse: 0.0697\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1070 - mse: 0.0634 - val_loss: 0.0978 - val_mse: 0.0543\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1061 - mse: 0.0628 - val_loss: 0.0991 - val_mse: 0.0559\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1039 - mse: 0.0609 - val_loss: 0.1012 - val_mse: 0.0583\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1021 - mse: 0.0593 - val_loss: 0.1023 - val_mse: 0.0597\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1010 - mse: 0.0585 - val_loss: 0.0956 - val_mse: 0.0532\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1060 - mse: 0.0638 - val_loss: 0.0971 - val_mse: 0.0550\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1034 - mse: 0.0615 - val_loss: 0.0959 - val_mse: 0.0541\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1022 - mse: 0.0605 - val_loss: 0.0967 - val_mse: 0.0551\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1009 - mse: 0.0595 - val_loss: 0.1009 - val_mse: 0.0596\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.0625 - val_loss: 0.0934 - val_mse: 0.0524\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0989 - mse: 0.0581 - val_loss: 0.1132 - val_mse: 0.0724\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.0596 - val_loss: 0.1011 - val_mse: 0.0606\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0587 - val_loss: 0.0966 - val_mse: 0.0564\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1012 - mse: 0.0611 - val_loss: 0.0928 - val_mse: 0.0529\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0592 - val_loss: 0.0926 - val_mse: 0.0529\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0602 - val_loss: 0.0919 - val_mse: 0.0525\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0605 - val_loss: 0.0928 - val_mse: 0.0536\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0984 - mse: 0.0594 - val_loss: 0.0976 - val_mse: 0.0586\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0577 - val_loss: 0.0928 - val_mse: 0.0542\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0579 - val_loss: 0.1187 - val_mse: 0.0803\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0978 - mse: 0.0595 - val_loss: 0.1017 - val_mse: 0.0635\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0970 - mse: 0.0590 - val_loss: 0.1100 - val_mse: 0.0721\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1009 - mse: 0.0631 - val_loss: 0.0908 - val_mse: 0.0531\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0959 - mse: 0.0584 - val_loss: 0.0902 - val_mse: 0.0527\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0972 - mse: 0.0599 - val_loss: 0.0903 - val_mse: 0.0531\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0967 - mse: 0.0596 - val_loss: 0.0901 - val_mse: 0.0532\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0962 - mse: 0.0593 - val_loss: 0.0878 - val_mse: 0.0511\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0956 - mse: 0.0590 - val_loss: 0.0998 - val_mse: 0.0633\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0959 - mse: 0.0595 - val_loss: 0.0933 - val_mse: 0.0570\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0948 - mse: 0.0586 - val_loss: 0.0948 - val_mse: 0.0588\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0568 - val_loss: 0.1145 - val_mse: 0.0787\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0979 - mse: 0.0622 - val_loss: 0.0921 - val_mse: 0.0565\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0948 - mse: 0.0594 - val_loss: 0.0868 - val_mse: 0.0514\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0592 - val_loss: 0.0861 - val_mse: 0.0510\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0589 - val_loss: 0.0941 - val_mse: 0.0592\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0925 - mse: 0.0577 - val_loss: 0.0867 - val_mse: 0.0520\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0572 - val_loss: 0.0858 - val_mse: 0.0513\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0941 - mse: 0.0597 - val_loss: 0.1010 - val_mse: 0.0667\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0930 - mse: 0.0589 - val_loss: 0.1156 - val_mse: 0.0815\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0913 - mse: 0.0574 - val_loss: 0.0861 - val_mse: 0.0522\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0921 - mse: 0.0584 - val_loss: 0.1051 - val_mse: 0.0715\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0572 - val_loss: 0.0901 - val_mse: 0.0567\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0919 - mse: 0.0586 - val_loss: 0.0899 - val_mse: 0.0567\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0899 - mse: 0.0568 - val_loss: 0.0851 - val_mse: 0.0522\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0903 - mse: 0.0575 - val_loss: 0.0862 - val_mse: 0.0534\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0905 - mse: 0.0578 - val_loss: 0.0830 - val_mse: 0.0504\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0887 - mse: 0.0563 - val_loss: 0.0832 - val_mse: 0.0508\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0918 - mse: 0.0596 - val_loss: 0.0833 - val_mse: 0.0511\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0890 - mse: 0.0570 - val_loss: 0.1268 - val_mse: 0.0949\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0906 - mse: 0.0587 - val_loss: 0.0879 - val_mse: 0.0562\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0878 - mse: 0.0562 - val_loss: 0.0828 - val_mse: 0.0512\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0890 - mse: 0.0575 - val_loss: 0.0851 - val_mse: 0.0537\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0882 - mse: 0.0569 - val_loss: 0.0828 - val_mse: 0.0516\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0879 - mse: 0.0568 - val_loss: 0.0870 - val_mse: 0.0561\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0899 - mse: 0.0591 - val_loss: 0.0807 - val_mse: 0.0500\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0875 - mse: 0.0569 - val_loss: 0.0819 - val_mse: 0.0514\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0566 - val_loss: 0.0908 - val_mse: 0.0605\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0580 - val_loss: 0.0945 - val_mse: 0.0643\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0875 - mse: 0.0574 - val_loss: 0.0801 - val_mse: 0.0501\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0864 - mse: 0.0565 - val_loss: 0.0883 - val_mse: 0.0585\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0867 - mse: 0.0570 - val_loss: 0.1047 - val_mse: 0.0751\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0881 - mse: 0.0585 - val_loss: 0.0857 - val_mse: 0.0563\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0581 - val_loss: 0.0911 - val_mse: 0.0619\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0867 - mse: 0.0575 - val_loss: 0.0827 - val_mse: 0.0537\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0873 - mse: 0.0583 - val_loss: 0.0816 - val_mse: 0.0527\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0855 - mse: 0.0567 - val_loss: 0.0789 - val_mse: 0.0502\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0856 - mse: 0.0569 - val_loss: 0.0874 - val_mse: 0.0588\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0853 - mse: 0.0569 - val_loss: 0.0809 - val_mse: 0.0526\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0592 - val_loss: 0.0797 - val_mse: 0.0515\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0855 - mse: 0.0574 - val_loss: 0.0805 - val_mse: 0.0525\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0865 - mse: 0.0586 - val_loss: 0.0856 - val_mse: 0.0577\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0863 - mse: 0.0585 - val_loss: 0.1100 - val_mse: 0.0823\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0859 - mse: 0.0583 - val_loss: 0.0865 - val_mse: 0.0590\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0830 - mse: 0.0556 - val_loss: 0.0926 - val_mse: 0.0653\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0598 - val_loss: 0.0797 - val_mse: 0.0525\n",
      "Epoch 121: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 11.1667 - mse: 0.2561 - val_loss: 0.1886 - val_mse: 0.0761\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.1213 - val_loss: 0.1151 - val_mse: 0.0898\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1491 - mse: 0.1196 - val_loss: 0.1093 - val_mse: 0.0754\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1489 - mse: 0.1195 - val_loss: 0.1079 - val_mse: 0.0755\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1534 - mse: 0.1239 - val_loss: 0.1417 - val_mse: 0.0970\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1510 - mse: 0.1214 - val_loss: 0.1386 - val_mse: 0.0945\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1490 - mse: 0.1194 - val_loss: 0.1221 - val_mse: 0.0990\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1470 - mse: 0.1177 - val_loss: 0.1130 - val_mse: 0.0768\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1517 - mse: 0.1222 - val_loss: 0.1194 - val_mse: 0.0807\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1517 - mse: 0.1220 - val_loss: 0.1455 - val_mse: 0.1265\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1526 - mse: 0.1234 - val_loss: 0.1088 - val_mse: 0.0754\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1496 - mse: 0.1202 - val_loss: 0.1207 - val_mse: 0.0815\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1491 - mse: 0.1194 - val_loss: 0.1131 - val_mse: 0.0871\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1489 - mse: 0.1196 - val_loss: 0.1082 - val_mse: 0.0754\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1516 - mse: 0.1221 - val_loss: 0.1170 - val_mse: 0.0791\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1490 - mse: 0.1195 - val_loss: 0.1090 - val_mse: 0.0754\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1508 - mse: 0.1212 - val_loss: 0.1080 - val_mse: 0.0786\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1496 - mse: 0.1203 - val_loss: 0.1085 - val_mse: 0.0754\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1499 - mse: 0.1202 - val_loss: 0.1075 - val_mse: 0.0767\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1528 - mse: 0.1233 - val_loss: 0.1224 - val_mse: 0.0992\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1542 - mse: 0.1247 - val_loss: 0.1081 - val_mse: 0.0789\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1483 - mse: 0.1190 - val_loss: 0.1137 - val_mse: 0.0880\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1497 - mse: 0.1202 - val_loss: 0.1078 - val_mse: 0.0782\n",
      "Epoch 23: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 4.9322 - mse: 0.2916 - val_loss: 3.3700 - val_mse: 0.0721\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.5552 - mse: 0.1073 - val_loss: 1.8108 - val_mse: 0.0674\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.4016 - mse: 0.1058 - val_loss: 0.9953 - val_mse: 0.0682\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7957 - mse: 0.1045 - val_loss: 0.5769 - val_mse: 0.0812\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4773 - mse: 0.1048 - val_loss: 0.3452 - val_mse: 0.0768\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3154 - mse: 0.1123 - val_loss: 0.2237 - val_mse: 0.0750\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2236 - mse: 0.1110 - val_loss: 0.1589 - val_mse: 0.0759\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1784 - mse: 0.1141 - val_loss: 0.1216 - val_mse: 0.0731\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1537 - mse: 0.1160 - val_loss: 0.1030 - val_mse: 0.0739\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1380 - mse: 0.1150 - val_loss: 0.0929 - val_mse: 0.0747\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1318 - mse: 0.1173 - val_loss: 0.0876 - val_mse: 0.0760\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1295 - mse: 0.1198 - val_loss: 0.0853 - val_mse: 0.0774\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1252 - mse: 0.1183 - val_loss: 0.0833 - val_mse: 0.0775\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1232 - mse: 0.1179 - val_loss: 0.1041 - val_mse: 0.1001\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1232 - mse: 0.1187 - val_loss: 0.0814 - val_mse: 0.0774\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1245 - mse: 0.1206 - val_loss: 0.0842 - val_mse: 0.0798\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1222 - mse: 0.1186 - val_loss: 0.1055 - val_mse: 0.1029\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1205 - val_loss: 0.0796 - val_mse: 0.0763\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1229 - mse: 0.1195 - val_loss: 0.0807 - val_mse: 0.0775\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.1198 - val_loss: 0.0976 - val_mse: 0.0950\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.1191 - val_loss: 0.0808 - val_mse: 0.0776\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1207 - mse: 0.1174 - val_loss: 0.0791 - val_mse: 0.0755\n",
      "Epoch 22: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.4669 - mse: 0.8613 - val_loss: 0.6605 - val_mse: 0.0756\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6549 - mse: 0.0886 - val_loss: 0.6143 - val_mse: 0.0663\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6125 - mse: 0.0816 - val_loss: 0.5798 - val_mse: 0.0659\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5765 - mse: 0.0787 - val_loss: 0.5576 - val_mse: 0.0758\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5413 - mse: 0.0745 - val_loss: 0.5210 - val_mse: 0.0689\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5078 - mse: 0.0697 - val_loss: 0.4860 - val_mse: 0.0620\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4773 - mse: 0.0663 - val_loss: 0.4620 - val_mse: 0.0642\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4503 - mse: 0.0646 - val_loss: 0.4355 - val_mse: 0.0619\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4246 - mse: 0.0625 - val_loss: 0.4117 - val_mse: 0.0613\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4015 - mse: 0.0616 - val_loss: 0.3869 - val_mse: 0.0578\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3804 - mse: 0.0613 - val_loss: 0.3659 - val_mse: 0.0570\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3592 - mse: 0.0596 - val_loss: 0.3467 - val_mse: 0.0566\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3393 - mse: 0.0579 - val_loss: 0.3284 - val_mse: 0.0559\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3219 - mse: 0.0577 - val_loss: 0.3159 - val_mse: 0.0599\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3057 - mse: 0.0574 - val_loss: 0.3084 - val_mse: 0.0679\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2922 - mse: 0.0589 - val_loss: 0.2819 - val_mse: 0.0558\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2748 - mse: 0.0555 - val_loss: 0.2806 - val_mse: 0.0683\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2634 - mse: 0.0573 - val_loss: 0.2522 - val_mse: 0.0523\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2493 - mse: 0.0554 - val_loss: 0.2463 - val_mse: 0.0582\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2395 - mse: 0.0570 - val_loss: 0.2288 - val_mse: 0.0519\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2282 - mse: 0.0565 - val_loss: 0.2170 - val_mse: 0.0506\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2163 - mse: 0.0547 - val_loss: 0.2102 - val_mse: 0.0536\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2085 - mse: 0.0563 - val_loss: 0.2010 - val_mse: 0.0533\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1983 - mse: 0.0549 - val_loss: 0.2042 - val_mse: 0.0649\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1897 - mse: 0.0545 - val_loss: 0.1825 - val_mse: 0.0514\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1831 - mse: 0.0557 - val_loss: 0.1757 - val_mse: 0.0519\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1741 - mse: 0.0539 - val_loss: 0.1683 - val_mse: 0.0514\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1679 - mse: 0.0544 - val_loss: 0.1699 - val_mse: 0.0598\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1613 - mse: 0.0542 - val_loss: 0.1564 - val_mse: 0.0524\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1569 - mse: 0.0556 - val_loss: 0.1481 - val_mse: 0.0498\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1520 - mse: 0.0563 - val_loss: 0.1482 - val_mse: 0.0552\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1456 - mse: 0.0551 - val_loss: 0.1393 - val_mse: 0.0514\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1431 - mse: 0.0575 - val_loss: 0.1453 - val_mse: 0.0622\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1362 - mse: 0.0552 - val_loss: 0.1295 - val_mse: 0.0505\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1326 - mse: 0.0557 - val_loss: 0.1254 - val_mse: 0.0505\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1291 - mse: 0.0561 - val_loss: 0.1247 - val_mse: 0.0537\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1244 - mse: 0.0551 - val_loss: 0.1189 - val_mse: 0.0514\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1217 - mse: 0.0560 - val_loss: 0.1169 - val_mse: 0.0529\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1183 - mse: 0.0558 - val_loss: 0.1177 - val_mse: 0.0568\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1158 - mse: 0.0563 - val_loss: 0.1084 - val_mse: 0.0504\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1128 - mse: 0.0560 - val_loss: 0.1057 - val_mse: 0.0503\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.0563 - val_loss: 0.1046 - val_mse: 0.0519\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1070 - mse: 0.0554 - val_loss: 0.1087 - val_mse: 0.0582\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0585 - val_loss: 0.0998 - val_mse: 0.0516\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1033 - mse: 0.0561 - val_loss: 0.0967 - val_mse: 0.0506\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1020 - mse: 0.0570 - val_loss: 0.0981 - val_mse: 0.0538\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1004 - mse: 0.0571 - val_loss: 0.0949 - val_mse: 0.0524\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0565 - val_loss: 0.0929 - val_mse: 0.0523\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0962 - mse: 0.0564 - val_loss: 0.0898 - val_mse: 0.0506\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0951 - mse: 0.0566 - val_loss: 0.0885 - val_mse: 0.0508\n",
      "Epoch 50: early stopping\n",
      "{'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 6\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.5781 - mse: 1.5042 - val_loss: 0.1594 - val_mse: 0.0859\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2112 - mse: 0.1380 - val_loss: 0.1491 - val_mse: 0.0760\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2097 - mse: 0.1369 - val_loss: 0.1545 - val_mse: 0.0819\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2042 - mse: 0.1318 - val_loss: 0.1639 - val_mse: 0.0918\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2032 - mse: 0.1313 - val_loss: 0.1465 - val_mse: 0.0748\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2013 - mse: 0.1299 - val_loss: 0.1989 - val_mse: 0.1277\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1964 - mse: 0.1255 - val_loss: 0.2574 - val_mse: 0.1867\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1997 - mse: 0.1292 - val_loss: 0.1653 - val_mse: 0.0950\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1986 - mse: 0.1285 - val_loss: 0.1443 - val_mse: 0.0744\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1967 - mse: 0.1271 - val_loss: 0.1629 - val_mse: 0.0935\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1991 - mse: 0.1299 - val_loss: 0.1439 - val_mse: 0.0750\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1983 - mse: 0.1296 - val_loss: 0.1436 - val_mse: 0.0751\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1968 - mse: 0.1285 - val_loss: 0.1664 - val_mse: 0.0984\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1912 - mse: 0.1234 - val_loss: 0.1497 - val_mse: 0.0822\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1937 - mse: 0.1263 - val_loss: 0.1828 - val_mse: 0.1157\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1893 - mse: 0.1224 - val_loss: 0.1523 - val_mse: 0.0856\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1938 - mse: 0.1273 - val_loss: 0.1491 - val_mse: 0.0828\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1981 - mse: 0.1321 - val_loss: 0.1812 - val_mse: 0.1153\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1934 - mse: 0.1278 - val_loss: 0.1824 - val_mse: 0.1170\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1950 - mse: 0.1298 - val_loss: 0.1407 - val_mse: 0.0757\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1964 - mse: 0.1317 - val_loss: 0.1936 - val_mse: 0.1291\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1900 - mse: 0.1256 - val_loss: 0.1431 - val_mse: 0.0789\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1774 - mse: 0.1135 - val_loss: 0.1759 - val_mse: 0.1122\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1799 - mse: 0.1164 - val_loss: 0.1685 - val_mse: 0.1052\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1869 - mse: 0.1238 - val_loss: 0.1716 - val_mse: 0.1088\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1755 - mse: 0.1128 - val_loss: 0.1316 - val_mse: 0.0691\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1562 - mse: 0.0939 - val_loss: 0.1319 - val_mse: 0.0698\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.1007 - val_loss: 0.1324 - val_mse: 0.0706\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1536 - mse: 0.0920 - val_loss: 0.1267 - val_mse: 0.0654\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1476 - mse: 0.0865 - val_loss: 0.1215 - val_mse: 0.0606\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1459 - mse: 0.0851 - val_loss: 0.1519 - val_mse: 0.0913\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1412 - mse: 0.0808 - val_loss: 0.1221 - val_mse: 0.0620\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1446 - mse: 0.0846 - val_loss: 0.1247 - val_mse: 0.0649\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1379 - mse: 0.0783 - val_loss: 0.1525 - val_mse: 0.0931\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1348 - mse: 0.0756 - val_loss: 0.1292 - val_mse: 0.0702\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1296 - mse: 0.0707 - val_loss: 0.1361 - val_mse: 0.0774\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.0679 - val_loss: 0.1123 - val_mse: 0.0540\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1267 - mse: 0.0686 - val_loss: 0.1315 - val_mse: 0.0736\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1256 - mse: 0.0679 - val_loss: 0.1120 - val_mse: 0.0545\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1241 - mse: 0.0667 - val_loss: 0.1084 - val_mse: 0.0513\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1254 - mse: 0.0685 - val_loss: 0.1165 - val_mse: 0.0597\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1226 - mse: 0.0660 - val_loss: 0.1155 - val_mse: 0.0591\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1238 - mse: 0.0676 - val_loss: 0.1497 - val_mse: 0.0937\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1237 - mse: 0.0679 - val_loss: 0.1057 - val_mse: 0.0501\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1198 - mse: 0.0644 - val_loss: 0.1060 - val_mse: 0.0507\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.0674 - val_loss: 0.1062 - val_mse: 0.0512\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1182 - mse: 0.0635 - val_loss: 0.1170 - val_mse: 0.0624\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1168 - mse: 0.0624 - val_loss: 0.1182 - val_mse: 0.0639\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.0628 - val_loss: 0.1132 - val_mse: 0.0593\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1166 - mse: 0.0629 - val_loss: 0.1069 - val_mse: 0.0534\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1150 - mse: 0.0617 - val_loss: 0.1027 - val_mse: 0.0495\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1115 - mse: 0.0585 - val_loss: 0.1182 - val_mse: 0.0654\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1151 - mse: 0.0625 - val_loss: 0.1065 - val_mse: 0.0540\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1115 - mse: 0.0591 - val_loss: 0.1426 - val_mse: 0.0904\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1154 - mse: 0.0635 - val_loss: 0.1391 - val_mse: 0.0873\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1134 - mse: 0.0618 - val_loss: 0.1057 - val_mse: 0.0542\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1152 - mse: 0.0639 - val_loss: 0.1049 - val_mse: 0.0538\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1134 - mse: 0.0624 - val_loss: 0.1098 - val_mse: 0.0590\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1158 - mse: 0.0651 - val_loss: 0.1122 - val_mse: 0.0617\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1102 - mse: 0.0599 - val_loss: 0.1093 - val_mse: 0.0591\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1100 - mse: 0.0600 - val_loss: 0.1017 - val_mse: 0.0518\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1102 - mse: 0.0605 - val_loss: 0.1165 - val_mse: 0.0670\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0571 - val_loss: 0.1227 - val_mse: 0.0735\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1055 - mse: 0.0564 - val_loss: 0.1242 - val_mse: 0.0754\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.0588 - val_loss: 0.1350 - val_mse: 0.0864\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1119 - mse: 0.0635 - val_loss: 0.0993 - val_mse: 0.0511\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0591 - val_loss: 0.0979 - val_mse: 0.0500\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1104 - mse: 0.0627 - val_loss: 0.0976 - val_mse: 0.0500\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1060 - mse: 0.0585 - val_loss: 0.1296 - val_mse: 0.0823\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0602 - val_loss: 0.1019 - val_mse: 0.0549\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1037 - mse: 0.0568 - val_loss: 0.1270 - val_mse: 0.0803\n",
      "Epoch 71: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 15.8056 - mse: 0.3584 - val_loss: 0.2098 - val_mse: 0.0765\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1623 - mse: 0.1224 - val_loss: 0.1018 - val_mse: 0.0793\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1461 - mse: 0.1228 - val_loss: 0.1102 - val_mse: 0.0909\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1461 - mse: 0.1231 - val_loss: 0.1006 - val_mse: 0.0755\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1499 - mse: 0.1264 - val_loss: 0.1141 - val_mse: 0.0957\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1484 - mse: 0.1252 - val_loss: 0.1040 - val_mse: 0.0828\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1421 - mse: 0.1191 - val_loss: 0.1011 - val_mse: 0.0782\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1452 - mse: 0.1219 - val_loss: 0.1017 - val_mse: 0.0755\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1485 - mse: 0.1252 - val_loss: 0.1046 - val_mse: 0.0837\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1477 - mse: 0.1244 - val_loss: 0.1014 - val_mse: 0.0789\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1456 - mse: 0.1224 - val_loss: 0.1011 - val_mse: 0.0782\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1500 - mse: 0.1269 - val_loss: 0.1017 - val_mse: 0.0793\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1453 - mse: 0.1221 - val_loss: 0.1007 - val_mse: 0.0755\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1472 - mse: 0.1240 - val_loss: 0.1080 - val_mse: 0.0789\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1423 - mse: 0.1191 - val_loss: 0.1123 - val_mse: 0.0936\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1451 - mse: 0.1220 - val_loss: 0.1043 - val_mse: 0.0832\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1437 - mse: 0.1205 - val_loss: 0.1003 - val_mse: 0.0762\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1437 - mse: 0.1204 - val_loss: 0.1428 - val_mse: 0.1283\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1444 - mse: 0.1214 - val_loss: 0.1006 - val_mse: 0.0755\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1425 - mse: 0.1193 - val_loss: 0.1033 - val_mse: 0.0819\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1455 - mse: 0.1223 - val_loss: 0.1020 - val_mse: 0.0755\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1455 - mse: 0.1222 - val_loss: 0.1138 - val_mse: 0.0954\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1436 - mse: 0.1206 - val_loss: 0.1205 - val_mse: 0.0881\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1490 - mse: 0.1257 - val_loss: 0.1159 - val_mse: 0.0846\n",
      "Epoch 24: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 5.9986 - mse: 0.2174 - val_loss: 4.1661 - val_mse: 0.0778\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.1491 - mse: 0.1232 - val_loss: 2.2486 - val_mse: 0.1001\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.7026 - mse: 0.1102 - val_loss: 1.2049 - val_mse: 0.0702\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.9548 - mse: 0.1078 - val_loss: 0.6840 - val_mse: 0.0762\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.5592 - mse: 0.1025 - val_loss: 0.3996 - val_mse: 0.0682\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3608 - mse: 0.1101 - val_loss: 0.2724 - val_mse: 0.0896\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2531 - mse: 0.1132 - val_loss: 0.1752 - val_mse: 0.0714\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1981 - mse: 0.1182 - val_loss: 0.1380 - val_mse: 0.0782\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1632 - mse: 0.1163 - val_loss: 0.1124 - val_mse: 0.0762\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1468 - mse: 0.1186 - val_loss: 0.0961 - val_mse: 0.0742\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1363 - mse: 0.1188 - val_loss: 0.0886 - val_mse: 0.0747\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1177 - val_loss: 0.0963 - val_mse: 0.0877\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1303 - mse: 0.1226 - val_loss: 0.1046 - val_mse: 0.0988\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1274 - mse: 0.1218 - val_loss: 0.0820 - val_mse: 0.0772\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.1212 - val_loss: 0.0915 - val_mse: 0.0880\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1295 - mse: 0.1257 - val_loss: 0.0839 - val_mse: 0.0806\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1233 - mse: 0.1200 - val_loss: 0.0815 - val_mse: 0.0779\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1204 - mse: 0.1173 - val_loss: 0.1180 - val_mse: 0.1160\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1284 - mse: 0.1255 - val_loss: 0.0788 - val_mse: 0.0759\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1259 - mse: 0.1230 - val_loss: 0.1259 - val_mse: 0.1215\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1312 - mse: 0.1283 - val_loss: 0.0977 - val_mse: 0.0938\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1260 - mse: 0.1232 - val_loss: 0.0889 - val_mse: 0.0854\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1268 - mse: 0.1240 - val_loss: 0.0783 - val_mse: 0.0754\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.1220 - val_loss: 0.0904 - val_mse: 0.0880\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.1234 - val_loss: 0.0783 - val_mse: 0.0754\n",
      "Epoch 25: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 1.1527 - mse: 0.2239 - val_loss: 0.9826 - val_mse: 0.0849\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.9467 - mse: 0.0775 - val_loss: 0.9479 - val_mse: 0.1076\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.8870 - mse: 0.0732 - val_loss: 0.8483 - val_mse: 0.0611\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.8296 - mse: 0.0673 - val_loss: 0.7984 - val_mse: 0.0610\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.7831 - mse: 0.0688 - val_loss: 0.7584 - val_mse: 0.0675\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.7353 - mse: 0.0663 - val_loss: 0.7035 - val_mse: 0.0562\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6923 - mse: 0.0652 - val_loss: 0.6724 - val_mse: 0.0659\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6493 - mse: 0.0617 - val_loss: 0.6214 - val_mse: 0.0529\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6175 - mse: 0.0669 - val_loss: 0.5941 - val_mse: 0.0611\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5761 - mse: 0.0597 - val_loss: 0.5574 - val_mse: 0.0577\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5479 - mse: 0.0637 - val_loss: 0.5328 - val_mse: 0.0641\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5123 - mse: 0.0581 - val_loss: 0.4975 - val_mse: 0.0579\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4839 - mse: 0.0579 - val_loss: 0.4800 - val_mse: 0.0675\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.0591 - val_loss: 0.4399 - val_mse: 0.0530\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4324 - mse: 0.0574 - val_loss: 0.4238 - val_mse: 0.0605\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4107 - mse: 0.0587 - val_loss: 0.3940 - val_mse: 0.0531\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3846 - mse: 0.0540 - val_loss: 0.3769 - val_mse: 0.0567\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3664 - mse: 0.0559 - val_loss: 0.3567 - val_mse: 0.0559\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3482 - mse: 0.0567 - val_loss: 0.3360 - val_mse: 0.0534\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3280 - mse: 0.0538 - val_loss: 0.3176 - val_mse: 0.0520\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3119 - mse: 0.0543 - val_loss: 0.3007 - val_mse: 0.0509\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2963 - mse: 0.0539 - val_loss: 0.2939 - val_mse: 0.0588\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2810 - mse: 0.0530 - val_loss: 0.2733 - val_mse: 0.0522\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2690 - mse: 0.0544 - val_loss: 0.2582 - val_mse: 0.0502\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2547 - mse: 0.0526 - val_loss: 0.2745 - val_mse: 0.0784\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2469 - mse: 0.0565 - val_loss: 0.2344 - val_mse: 0.0496\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2325 - mse: 0.0530 - val_loss: 0.2385 - val_mse: 0.0642\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2227 - mse: 0.0533 - val_loss: 0.2142 - val_mse: 0.0499\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2126 - mse: 0.0529 - val_loss: 0.2047 - val_mse: 0.0494\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2051 - mse: 0.0541 - val_loss: 0.1990 - val_mse: 0.0525\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1967 - mse: 0.0542 - val_loss: 0.1937 - val_mse: 0.0550\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1860 - mse: 0.0512 - val_loss: 0.1812 - val_mse: 0.0504\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1826 - mse: 0.0552 - val_loss: 0.1746 - val_mse: 0.0508\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1752 - mse: 0.0547 - val_loss: 0.1656 - val_mse: 0.0486\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1656 - mse: 0.0517 - val_loss: 0.1631 - val_mse: 0.0520\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1608 - mse: 0.0525 - val_loss: 0.1560 - val_mse: 0.0509\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1566 - mse: 0.0543 - val_loss: 0.1542 - val_mse: 0.0545\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1514 - mse: 0.0543 - val_loss: 0.1466 - val_mse: 0.0520\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1473 - mse: 0.0552 - val_loss: 0.1385 - val_mse: 0.0488\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1427 - mse: 0.0552 - val_loss: 0.1359 - val_mse: 0.0506\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1388 - mse: 0.0557 - val_loss: 0.1415 - val_mse: 0.0603\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1327 - mse: 0.0536 - val_loss: 0.1357 - val_mse: 0.0585\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1278 - mse: 0.0525 - val_loss: 0.1231 - val_mse: 0.0497\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1244 - mse: 0.0528 - val_loss: 0.1268 - val_mse: 0.0566\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.0546 - val_loss: 0.1163 - val_mse: 0.0497\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.0561 - val_loss: 0.1187 - val_mse: 0.0551\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1153 - mse: 0.0531 - val_loss: 0.1190 - val_mse: 0.0583\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1121 - mse: 0.0527 - val_loss: 0.1068 - val_mse: 0.0488\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1105 - mse: 0.0537 - val_loss: 0.1064 - val_mse: 0.0508\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1080 - mse: 0.0536 - val_loss: 0.1026 - val_mse: 0.0493\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1061 - mse: 0.0539 - val_loss: 0.0999 - val_mse: 0.0489\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.0552 - val_loss: 0.1071 - val_mse: 0.0582\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1012 - mse: 0.0533 - val_loss: 0.1056 - val_mse: 0.0586\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.0542 - val_loss: 0.0955 - val_mse: 0.0505\n",
      "Epoch 54: early stopping\n",
      "{'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "New input layer: input_shape 5 nodes 5\n",
      "New hidden layer: nodes 9\n",
      "New output layer: output_shape 1\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 3.5121 - mse: 3.3875 - val_loss: 0.2708 - val_mse: 0.1455\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2691 - mse: 0.1442 - val_loss: 0.2491 - val_mse: 0.1246\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2734 - mse: 0.1493 - val_loss: 0.1997 - val_mse: 0.0760\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2666 - mse: 0.1433 - val_loss: 0.2496 - val_mse: 0.1267\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2535 - mse: 0.1310 - val_loss: 0.2031 - val_mse: 0.0810\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2518 - mse: 0.1300 - val_loss: 0.1983 - val_mse: 0.0769\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2563 - mse: 0.1353 - val_loss: 0.2051 - val_mse: 0.0845\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2773 - mse: 0.1571 - val_loss: 0.2087 - val_mse: 0.0889\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2638 - mse: 0.1443 - val_loss: 0.3220 - val_mse: 0.2030\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2553 - mse: 0.1366 - val_loss: 0.3484 - val_mse: 0.2301\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2510 - mse: 0.1330 - val_loss: 0.1930 - val_mse: 0.0754\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2614 - mse: 0.1442 - val_loss: 0.1940 - val_mse: 0.0771\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2579 - mse: 0.1414 - val_loss: 0.2164 - val_mse: 0.1003\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2582 - mse: 0.1425 - val_loss: 0.2469 - val_mse: 0.1316\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2585 - mse: 0.1435 - val_loss: 0.1961 - val_mse: 0.0815\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2577 - mse: 0.1435 - val_loss: 0.2334 - val_mse: 0.1195\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2763 - mse: 0.1628 - val_loss: 0.3617 - val_mse: 0.2486\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2581 - mse: 0.1453 - val_loss: 0.2303 - val_mse: 0.1178\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2549 - mse: 0.1428 - val_loss: 0.2044 - val_mse: 0.0926\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2513 - mse: 0.1399 - val_loss: 0.1985 - val_mse: 0.0874\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2552 - mse: 0.1445 - val_loss: 0.1857 - val_mse: 0.0754\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2567 - mse: 0.1467 - val_loss: 0.1886 - val_mse: 0.0789\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2464 - mse: 0.1371 - val_loss: 0.1932 - val_mse: 0.0843\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2444 - mse: 0.1357 - val_loss: 0.1856 - val_mse: 0.0774\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2530 - mse: 0.1451 - val_loss: 0.2204 - val_mse: 0.1128\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2465 - mse: 0.1392 - val_loss: 0.1846 - val_mse: 0.0778\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2492 - mse: 0.1427 - val_loss: 0.2239 - val_mse: 0.1177\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2421 - mse: 0.1362 - val_loss: 0.2704 - val_mse: 0.1648\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2545 - mse: 0.1493 - val_loss: 0.2458 - val_mse: 0.1409\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.1355 - val_loss: 0.2588 - val_mse: 0.1546\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2551 - mse: 0.1512 - val_loss: 0.2160 - val_mse: 0.1125\n",
      "Epoch 31: early stopping\n",
      "0 0.0542 0.0505 54 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "1 0.0566 0.0508 50 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "2 0.0598 0.0525 121 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "3 0.0572 0.068 46 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "4 0.1234 0.0754 25 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "5 0.1174 0.0755 22 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "6 0.1207 0.0756 21 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "7 0.1202 0.0782 23 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "8 0.0568 0.0803 71 {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "9 0.1257 0.0846 24 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "10 0.1175 0.1055 21 {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "11 0.1512 0.1125 31 {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_noise_high = add_gaussian_noise(X_train, std=0.15)\n",
    "y_train_noise_high = add_gaussian_noise(y_train, std=0.15)\n",
    "\n",
    "X_val_noise_high = add_gaussian_noise(X_val, std=0.15)\n",
    "y_val_noise_high = add_gaussian_noise(y_val, std=0.15)\n",
    "\n",
    "noise_high_eval_grid = grid_search(param_dict, X_train_noise_high, y_train_noise_high, X_val_noise_high, y_val_noise_high)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0542 0.0505 54 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "1 0.0566 0.0508 50 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "2 0.0598 0.0525 121 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "3 0.0572 0.068 46 {'l2': 0.0010000000474974513} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679A340>}\n",
      "4 0.1234 0.0754 25 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "5 0.1174 0.0755 22 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "6 0.1207 0.0756 21 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "7 0.1202 0.0782 23 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "8 0.0568 0.0803 71 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 6], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n",
      "9 0.1257 0.0846 24 {'l2': 0.10000000149011612} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD67CDD00>}\n",
      "10 0.1175 0.1055 21 {'l2': 0.009999999776482582} {'hidden_layer_nodes': [5, 3], 'regularizer': <keras.regularizers.L2 object at 0x000001AB357F38B0>}\n",
      "11 0.1512 0.1125 31 {'l2': 9.999999747378752e-05} {'hidden_layer_nodes': [5, 9], 'regularizer': <keras.regularizers.L2 object at 0x000001AAD679AC70>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (param, model, history, final_train_mse, final_val_mse, epoch) in enumerate(noise_high_eval_grid):\n",
    "    config = param[\"regularizer\"].get_config()\n",
    "    print(i, final_train_mse, final_val_mse, epoch, config, param)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_low = noise_low_eval_grid[0][1].predict(X_test)\n",
    "y_pred_high = noise_high_eval_grid[0][1].predict(X_test)\n",
    "Xrange = range(len(y_pred_best))\n",
    "\n",
    "plt.plot(Xrange, y_pred_high, label=\"pred high noise\")\n",
    "plt.plot(Xrange, y_pred_low, label=\"pred low noise\")\n",
    "plt.plot(Xrange, y_test, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}